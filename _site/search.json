[
  {
    "objectID": "mapchallenges/cases2021/index.html",
    "href": "mapchallenges/cases2021/index.html",
    "title": "30DayMapChallenge 2021",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "mapchallenges/cases2023/index.html",
    "href": "mapchallenges/cases2023/index.html",
    "title": "30DayMapChallenge 2023",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "mapchallenges/cases2022/index.html",
    "href": "mapchallenges/cases2022/index.html",
    "title": "30DayMapChallenge 2022",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chartchallenges/cases2021/index.html",
    "href": "chartchallenges/cases2021/index.html",
    "title": "30DayChartChallenge 2021",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chartchallenges/cases2023/index.html",
    "href": "chartchallenges/cases2023/index.html",
    "title": "30DayChartChallenge 2023",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "chartchallenges/cases2022/index.html",
    "href": "chartchallenges/cases2022/index.html",
    "title": "30DayChartChallenge 2022",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Unlocking the Power of Data Visualization with R",
    "section": "",
    "text": "Welcome to \"Unlocking the Power of Data Visualization with R\" where I am proudly showcasing the vibrant contributions to #R4DS community to the #TidyTuesday, #30DayChartChallenge, and #30DayMapChallenge spanning 2021, 2022, and 2023. This platform serves as your gateway to exploring an engaging journey of data exploration, featuring a diverse collection of visualizations created using the R programming language. Dive into the digital gallery to discover insights, find inspiration, and learn from detailed explanations and code for each submission.\n\nWhether you’re a seasoned data professional or just starting out, join me in unraveling the art and impact of data visualization."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to this data visualization website, where I am proudly spotlight the my contributions of our #R4DS community to the #TidyTuesday, #30DayChartChallenge, and #30DayMapChallenge contributions spanning 2021, 2022, and 2023.\nMy name is Federica Gazzelloni, and I am a passionate data enthusiast and a skilled storyteller who believes in the power of data visualization to communicate complex insights. With a keen eye for detail and a knack for making data accessible, I curated this unique collection of visualizations that tell stories beyond the numbers. Committed to sharing expertise for helping others to unlock the potential of data visualization, stay tuned for more exciting updates and insights as we continue this journey of discovery together."
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w46_afrilearndata/w46_afrilearndata.html",
    "href": "tidytuesday/cases2021/posts2021/w46_afrilearndata/w46_afrilearndata.html",
    "title": "Learning with afrilearndata",
    "section": "",
    "text": "library(tidyverse)\nlibrary(afriadmin)\nlibrary(afrihealthsites)\nlibrary(afrilearndata)\nlibrary(tmap)\n\n\nafriadmin::afcountries\n#afriadmin::afcountrynames(afcountries$name)\n\ncountries<- afriadmin::afcountries$name\n\nafrilearndata::africapitals\nafrilearndata::afrihighway\nafrilearndata::afripop2000\nafrilearndata::afripop2020  \nafrilearndata::africountries\nafriadmin::sf_af_gadm0\nafrihealthsites::sf_healthsites_af\n\n\nsf::st_crs(africountries)=st_crs(4326)\nsf::st_crs(afrihighway)=st_crs(4326)\nsf::st_crs(africapitals)=st_crs(4326)\n\n\ntmap_mode(\"plot\")\n\npop_00 <- tmap::tm_shape(africountries) +\n  tm_polygons(col = \"#42ecf5\") +\n  \n  tm_shape(afripop2000)+\n  tm_raster(title=\"Population density\",\n            palette = rev(viridisLite::inferno(5)),\n            breaks = c(0,2,20,200,2000,25000)) +\n  \n  tm_shape(afrihighway) +\n  tm_lines(col=\"#f5b342\") +\n  \n  tm_shape(africountries)+\n  tm_borders() +\n  tm_text(text =\"iso_a3\", \n          fontface = \"bold\",\n          col=\"midnightblue\",\n          size = \"pop_est\",\n          title.size = \"\",\n          legend.size.show = TRUE,\n          sizes.legend.text = \"Pop\"\n          ) +\n  \n  tm_shape(africapitals) +\n  tm_symbols(col=\"midnightblue\",scale = 0.2) +\n  \n  tm_layout(title=\"2000\",\n            title.position = c(0.8,0.9),\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"bottom\"),\n            legend.bg.color = NA\n            )\n  \n    \npop_20 <- tmap::tm_shape(africountries) +\n  tm_polygons(col = \"#42ecf5\") +\n  \n  tm_shape(afripop2020)+\n  tm_raster(title=\"Population density\",\n            palette = rev(viridisLite::inferno(5)),\n            breaks = c(0,2,20,200,2000,25000)) +\n  \n  tm_shape(afrihighway) +\n  tm_lines(col=\"#f5b342\") +\n  \n  tm_shape(africountries)+\n  tm_borders() +\n   tm_text(text =\"iso_a3\", \n          fontface = \"bold\",\n          col=\"midnightblue\",\n          size = \"pop_est\",\n          title.size = \"\",\n          legend.size.show = TRUE,\n          sizes.legend.text = \"Pop\"\n          ) +\n  \n  tm_shape(africapitals) +\n  tm_symbols(col=\"midnightblue\",scale = 0.2) +\n  \n  tm_layout(title=\"2020\",\n            title.position = c(0.8,0.9),\n            legend.title.size = 1,\n            legend.text.size = 0.5,\n            legend.position = c(\"left\",\"bottom\"),\n            legend.bg.color = NA\n            )  \n  \nmy_raster<-tmap_arrange(pop_00,pop_20,ncol = 2)\n\n\n# save final plot\nragg::agg_png(here::here(\"day10_raster/raster.png\"),\n              res = 320, width = 8, height = 6, units = \"in\")\nmy_raster\ndev.off()\n\n\nlibrary(showtext)\nlibrary(extrafont)\nsysfonts::font_info_google(\"Josefin Sans\")\n#fonts()\n#loadfonts()\nfont_add_google(\"Josefin Sans\",\"josefin\")\nshowtext_opts(dpi = 320)\nshowtext_auto(enable = T)\n\n\n# final touches\nlibrary(cowplot)\nlibrary(magick)\n\nraster_image<- magick::image_read(here::here(\"day10_raster/raster.png\"))\n\ng <- grid::circleGrob(gp = grid::gpar(fill = NA,color=\"black\"))\n\n\nfinal <- cowplot::ggdraw()+\n  draw_image(raster_image,x = 0.1, y = 0,width = 0.7)+\n  draw_label(label=\"Africa\",x=0.3,y=0.2,fontfamily=\"josefin\",size=40) +\n  draw_label(label=\"density increased\\nin some areas\\nmore than others\",x=0.52,y=0.35,fontfamily=\"josefin\",size=8) +\n  draw_label(label=\"Population density transition 2000-2020\", x=0.45, y=0.95, size=30, fontfamily=\"josefin\") +\n  \n  draw_line(x = c(0.52, 0.5),y = c(0.38, 0.48),color = \"black\", size = 0.2)+\n  \n  draw_line(x = c(0.52, 0.6),y = c(0.38, 0.5),color = \"black\", size = 0.2)+\n  \n  draw_text(\"Datasource: afrilearndata\\n#TidyTuesdat week46 and #30DayMapChallenge day10 Raster\\nInfographics: Federica Gazzelloni\",x=0.5,y=0.05,family=\"josefin\",size=11)+\n  draw_grob(g, scale = 0.2,x = 0,y = 0.03)\n\n# save final plot\nragg::agg_png(here::here(\"day10_raster/raster2.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w15_global_deforestation/w15_global_deforestation.html",
    "href": "tidytuesday/cases2021/posts2021/w15_global_deforestation/w15_global_deforestation.html",
    "title": "Global deforestation",
    "section": "",
    "text": "Libraries, fonts and colors\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(extrafont)\n# fonts()\n\nmy_col <- \"#720000\"\nmy_col2 <- \"#9900bfbf\"\n\nLoad data and wrangling\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 15)\n\nforest <- tuesdata$forest\nforest_area <- tuesdata$forest_area\nbrazil_loss <- tuesdata$brazil_loss\nsoybean_use <- tuesdata$soybean_use\nvegetable_oil <- tuesdata$vegetable_oil\n\n\nbrazil_loss <- tuesdata$brazil_loss\n\nslopes <- brazil_loss%>%\n  pivot_longer(cols=c(5,6,11,12,13),names_to=\"Predictors\",values_to=\"values\")\n\nslopes <- slopes %>% select(year,fire,Predictors,values)\n\nSlope plot\n\nslope_plot <- ggplot(slopes, aes(x = fire, y = values, color = Predictors) ) +\n  geom_point() +\n  geom_smooth(method = \"lm\", alpha = .15, aes(fill = Predictors)) +\n  theme_minimal() +\n  \n  scale_y_continuous(name=\"Predictors\", labels = scales::label_number_si(), limits=c(0,92000)) +\n  scale_x_continuous(name=\"Fire (hectares)\", labels = scales::label_number_si(), limits=c(26000,537000)) +\n  \n  \n  annotate(\"curve\", x = 400000, xend = 450000, y = 50000, yend = 75000, \n           color = \"red\", curvature = -0.5) +\n  annotate(\"text\", x=500000, y= 75000, label=\"driving down: tree plantations \\ndriving up: natural disturbances\", colour=my_col) +\n  \n  labs(x=\"Fire\",\n       y=\"Predictors\",\n       title = \"Brazil Fire due to predictors\",\n       subtitle = \"flooding, mining, disturbances, plantations, infrastructures...\",\n       caption = \"Viz @fgazzelloni | DataSource: @ourworldindata | Brazil Fire predictors\") +\n  \n  theme(legend.position = \"bottom\",\n        legend.text = element_text(family=\"Trebuchet MS\"),\n        legend.background = element_blank(),\n        legend.title = element_text(family=\"Trebuchet MS\"),\n        legend.key = element_rect(fill = \"white\", colour = NA),\n        \n        plot.title = element_text(family=\"Trebuchet MS\", size =32,face=\"bold\", hjust=0 ),\n        plot.subtitle = element_text(family=\"Trebuchet MS\", size =20),\n        \n        axis.title = element_text(family=\"Trebuchet MS\", size =12),\n        \n        strip.background = element_rect(colour = \"black\", fill = \"white\"),\n        strip.text.x = element_text(colour = \"white\", face = \"bold\"),\n        panel.spacing = unit(5, \"lines\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        plot.background = element_rect(fill = \"azure\", color = NA),\n        panel.background = element_rect(fill = \"azure\")\n       ) +\n  annotate(\"text\", x = 280000, y = 80000, \n           family=\"Trebuchet MS\",\n           label = \"researchers at *Global Forest Watch* estimate that global deforestation \\nin 2019 was around 5.4 million hectares. \\n95% of this was in the tropics 33.12% in Brazil\")\n\nSave final plot\n\nragg::agg_png(here::here(\"w15\", \"tidytuesday_slope.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nslope_plot\n\ndev.off()\n\nRead the image, attach the Tidytuesday logo and save it\n\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\ntidy_slope <- image_read(\"tidytuesday_slope.png\")\n\nattached_logo <- image_composite(tidy_slope, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_slope.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w34_star_trek/w34_star_trek.html",
    "href": "tidytuesday/cases2021/posts2021/w34_star_trek/w34_star_trek.html",
    "title": "StarTrek",
    "section": "",
    "text": "library(tidyverse)\ntuesdata <- tidytuesdayR::tt_load(2021, week = 34)\ntidytuesdayR::readme(tuesdata)"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w34_star_trek/w34_star_trek.html#designing-speech-interactions-from-the-imagined-ideal-of-star-trek",
    "href": "tidytuesday/cases2021/posts2021/w34_star_trek/w34_star_trek.html#designing-speech-interactions-from-the-imagined-ideal-of-star-trek",
    "title": "StarTrek",
    "section": "Designing Speech Interactions from the Imagined Ideal of Star Trek",
    "text": "Designing Speech Interactions from the Imagined Ideal of Star Trek\nvoice user interfaces (VUIs) like Alexa reveals mismatches between current designs and user expectations The analysis study voice interactions with the Enterprise’s computer and compare them to current interactions\n\ncomputer <- tuesdata$computer\nhead(computer,3)\nDataExplorer::profile_missing(computer)\n\n\ndf <- computer %>%\n  select(char,line,type,pri_type,nv_resp:error) %>% #count(char)\n  mutate(char=if_else(str_detect(char,\"Computer\"),\"Computer\",char),\n         type=if_else(str_detect(type,\"command\"),\"Command\",type),\n         type=if_else(str_detect(type,\"question\"),\"Question\",type))\n\n\ndf %>% \n  group_by(char) %>%\n  summarize(type,nv_resp) %>%\n  ungroup() %>%\n  ggplot(aes(y=char,x=type,z=nv_resp)) +\n  stat_summary_hex(alpha=0.8,bins=50)+\n  scale_fill_viridis_c()+\n  labs(fill = \"char\",title = \"type\")+\n  theme(axis.text.x = element_text(angle=90,size=6))\n\n\nlibrary(extrafont)\nloadfonts()\n\n\nfinal <- df %>% #count(type,nv_resp,sort=TRUE)%>%\n  ggplot(aes(x=fct_reorder(sort(type,decreasing = TRUE),nv_resp),group=nv_resp)) +\n  geom_histogram(aes(fill=nv_resp),stat=\"count\",position =\"stack\")+ #position_dodge(width=0))+\n  coord_flip()+\n  scale_fill_viridis_d()+\n  labs(title=\"Type of words when the computer completes the query but without speaking a response\", \n       subtitle=\"False or True?\",\n       caption=\"Infographic: @fgazzelloni\\n DataSource: TidyTuesday Week34:Star Trek Voice Commands,SpeechInteraction.org\",\n       fill=\"Response\",\n       y=\"N°\",x=\"Word type\") +\n  ggthemes::theme_solarized()+\n  theme(text = element_text(family=\"Impact\"),\n        axis.text.x = element_text(angle=0,size=10),\n        axis.text.y = element_text(angle=0,size=10),\n        axis.title.x = element_text(size=14),\n        axis.title.y = element_text(size=14),\n        plot.title.position = \"plot\",\n        plot.title = element_text(face=\"bold\",size=20),\n        plot.subtitle = element_text(face=\"bold\",size=14),\n        plot.caption = element_text(size=10),\n        plot.caption.position = \"plot\")\n\n\nragg::agg_png(\"w34_star_trek.png\",\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\nlibrary(scales)\nlibrary(ggbump)\nlibrary(extrafont)\nlibrary(showtext)\nlibrary(cowplot)\nlibrary(ggstream)\nlibrary(colorspace) \nlibrary(ggpubr)\nlibrary(ggbump)\nlibrary(ggimage)\nlibrary(magick)\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\nimg <-image_read(\"1200px-Star_Trek_TNG_logo.svg.png\")\n\n\ntidy_final <- image_read(\"w34_star_trek.png\")\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"southwest\") \nimage_write(attached_logo, path = \"w34_star_trek.png\", format = \"png\") \ntidy_final2 <- image_read(\"w34_star_trek.png\")\n\nattached_logo2 <- image_composite(tidy_final2, img,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") \nimage_write(attached_logo, path = \"w34_star_trek.png\", format = \"png\") \n\n\nlibrary(\"ggmosaic\")\n\n\nfinal2 <- df %>% \n  select(type,char_type) %>%\n  ggplot() +\n  geom_mosaic(aes(x = product(type, char_type), fill = type)) +\n  labs(title=\"Type of request by count Person or Computer?\",\n       x=\"\",fill=\"Type of interaction\",\n       caption=\"Infographic: @fgazzelloni\\n DataSource: TidyTuesday Week34:Star Trek Voice Commands,SpeechInteraction.org\")+\n  theme(text=element_text(family=\"Roboto Condensed\"),\n  axis.text.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.title.y = element_blank(),\n  axis.text.x = element_text(color=\"white\",size=10),\n  axis.ticks.x = element_line(color=\"white\",size=1),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  plot.background = element_rect(color=\"darkgrey\",fill=\"black\"),\n  plot.title = element_text(color=\"white\",size=30),\n  legend.position = \"left\",\n  legend.text = element_text(color=\"white\"),\n  legend.background = element_rect(color=\"darkgrey\",fill=\"black\"),\n  plot.caption = element_text(color=\"white\")\n)\n\n\nragg::agg_png(\"w34_star_trek2.png\",\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal2\n\ndev.off()\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\ntidy_final <- image_read(\"w34_star_trek2.png\")\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"southwest\") \nimage_write(attached_logo, path = \"w34_star_trek2.png\", format = \"png\") \n\n\nimg <-image_read(\"white_startrek.png\")\n\ntidy_final2 <- image_read(\"w34_star_trek2.png\")\n\nattached_logo2 <- image_composite(tidy_final2, img,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") \nimage_write(attached_logo2, path = \"w34_star_trek2.png\", format = \"png\") \n\n\nlibrary(tidymodels)\ntidymodels_prefer()\n\ndummy\n\ndf %>% select(char,type,nv_resp) %>%\n  #mutate(nv_resp=factor(nv_resp)) %>%\n  recipe(char~.) %>%\n  step_dummy(all_nominal_predictors(),one_hot = TRUE)%>%\n  prep() %>%\n  bake(df) %>%\n  group_by(char,nv_resp) %>%\n  summarise_all(.funs = sum) %>%\n  ungroup() %>%\n  pivot_longer(cols=type_Alert:type_Wake.Word,names_to=\"type\",values_to=\"values\") %>%\n  mutate(type=gsub(\"^type_\",\"\",type)) %>%\n  group_by(char,nv_resp,type) %>%\n  summarize(tot=sum(values)) %>%\n  ungroup() %>%\n  \n  ggplot() +\n  geom_mosaic(aes(x = product(type, char), fill = nv_resp)) +\n  #geom_text(aes(x=nv_resp,y=type,label=type))+\n  theme(\n  axis.text.y = element_blank(),\n  axis.ticks.y = element_blank(),\n  axis.title.y = element_blank(),\n  panel.background = element_blank(),\n  panel.border = element_blank(),\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  plot.background = element_blank(),\n  legend.position = \"left\"\n)"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w24_great_lakes_fish/w24_great_lakes_fish.html",
    "href": "tidytuesday/cases2021/posts2021/w24_great_lakes_fish/w24_great_lakes_fish.html",
    "title": "Great Lakes Fish",
    "section": "",
    "text": "TidyTuesday week 24\nData Source: Great Lakes Fish, Great Lakes Database, Detroit Free Press database of all fish stocked from artificial propagation into the Great Lakes\nlibraries\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(patchwork)\n\n# load data ##############################\ntuesdata <- tidytuesdayR::tt_load(2021, week = 24)\n\n\nstocked <- tuesdata$stocked\nfishing <- tuesdata$fishing\n\n# check #################################\nhead(stocked);dim(stocked)\nhead(fishing);dim(fishing)\n\nlibrary(DataExplorer)\nprofile_missing(fishing)\n\nfishing$grand_total[is.na(fishing$grand_total)]<-0\nfishing$values[is.na(fishing$values)]<-0\n\n# wrangling ###########################\nmy_df <- fishing%>%\n  arrange(year)%>%\n  mutate(\n    species=case_when(species==\"Amercian Eel\"~\"American Eel\",\n              species==\"Bullhead\"~\"Bullheads\",\n              species==\"Channel catfish\"~\"Channel Catfish\",\n              species==\"Cisco and chubs\"~\"Cisco and Chubs\",\n              species==\"Cisco and Chub\"~\"Cisco and Chubs\",\n              species==\"Crappie\"~\"Crappies\",\n              species==\"Drum\"~\"Freshwater Drum\",\n              species==\"Lake Trout - siscowet\"~\"Lake Trout\",\n              species==\"Pacific salmon\"~\"Pacific Salmon\",\n              species==\"White bass\"~\"White Bass\",\n              TRUE~species))\n\n\n# plotting #################################\n\nfig1 <- my_df %>%\n  filter(!str_detect(species,\"and\")) %>%\n  arrange(year)%>%\n  mutate(text = fct_reorder(species, year )) %>%\n  ggplot( aes(y=text, x=year,fill=species)) +\n  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +\n  scale_fill_viridis(discrete=TRUE) +\n  scale_x_continuous(breaks=seq(1867, 2015, 8))+\n  labs(title=\"All Fisheries from the Great Lakes Fishery Commission\",\n       subtitle=\"from 1867 to 2015\",\n       tag = \"Fig1\")+\n  xlab(\"\") +\n  ylab(\"Assigned Probability (%)\")+\n  theme_ft_rc()+\n  theme(axis.text.x = element_text(angle=90),\n    legend.position=\"none\",\n    plot.title.position = \"plot\",\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    panel.spacing = unit(0.1, \"lines\"),\n    strip.text.x = element_text(size = 8))\n\n\nfig2 <- my_df%>%\n  filter(!str_detect(species,\"and\")) %>%\n  group_by(year,species)%>%\n  summarize(total_number=sum(grand_total),total_production=sum(values))%>%\n  ungroup()%>%\n  arrange(total_number)%>%\n  filter(!total_number==0)%>%\n  mutate(percent=total_production/total_number)%>%\n  filter(!percent>1)%>%\n  arrange(year,percent)%>%\n  filter(str_detect(species,(\"Lake\")))%>%\n  ggplot(aes(x=year,y=reorder(species,-total_production),group=species,color=species))+\n  geom_line(aes(size=total_production))+\n  labs(title=\"Lake Fisheries by Year\",\n       subtitle=\"sized by total value of production\",\n       tag=\"Fig2\",\n       size=\"Total value of production in $\",\n       x=\"\",\n       y=\"Species\"\n       #color=\"Species\",#size=\"Percent\",\n       #caption=\"Viz @fgazzelloni, DataSource: TidyTuesday Week24 - Great Lakes Fish,Great Lakes Database,Detroit Free Press\"\n       )+\n scale_color_viridis(discrete = TRUE)+\n  guides(color = FALSE)+\n   scale_x_continuous(breaks=seq(1867, 2015, 18))+\n  theme_ft_rc()+\n  theme(axis.text.x = element_text(angle=0),\n        legend.position = \"top\",\n        panel.grid = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_blank())\n\nfig3 <- my_df%>%\n  filter(!str_detect(species,\"and\")) %>%\n  arrange(year)%>%\n  filter(str_detect(species,(\"Lake\")))%>%\n  ggplot(aes(x=species, y=values, fill=species)) +\n  geom_boxplot() +\n  scale_fill_viridis(discrete = TRUE, alpha=0.6) +\n  geom_jitter(aes(colour=values), size=0.3, alpha=0.5) +\n  scale_colour_viridis_c()+\n  labs(tag = \"Fig3\",\n       x=\"\",y=\"Values\",\n       caption=\"Viz @fgazzelloni, DataSource: TidyTuesday Week24 - Great Lakes Fish,Great Lakes Database,Detroit Free Press\")+\n  theme_ft_rc() +\n  theme(\n    legend.position=\"none\",\n    panel.background = element_blank(),\n    panel.grid = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank())\n\n\n\n\n\n\n\nfinal <- fig1+(fig2/fig3)\n\nfinal\n\n\n\n\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w24\",\"w24_fisheries.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"w24/w24_fisheries.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"w24/w24_fisheries.png\",\n            format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w41_nurses/w41_nurses.html",
    "href": "tidytuesday/cases2021/posts2021/w41_nurses/w41_nurses.html",
    "title": "Registered Nurses",
    "section": "",
    "text": "TidyTuesday week 41 Nurses\n\n# load libraries\nlibrary(ggExtra)\nlibrary(xkcd)\nlibrary(ggstatsplot)\nlibrary(extrafont)\nlibrary(extrafont)\nfonts()\n\noptions(scipen = 999)\nlibrary(tidyverse)\n\n\nnurses <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-05/nurses.csv')\n\n\ndf <- nurses %>%\n  janitor::clean_names() %>%\n  filter(!is.na(employed_standard_error_percent),!is.na(wage_salary_standard_error_percent))\n\nmy_df <- df %>%\n  mutate(salary_level = case_when(annual_salary_median < 35000 ~ \"low\",\n                                 annual_salary_median >= 35000 & annual_salary_median < 55000 ~ \"medium\",\n                                 annual_salary_median >= 55000 & annual_salary_median <= 80000 ~ \"high\",\n                                 TRUE ~ \"top high\"),\n         .after = year) %>%\n  mutate(salary_level_class = case_when(annual_salary_median < 35000 ~ \"<35\",\n                                       annual_salary_median >= 35000 & annual_salary_median < 55000 ~ \"35 to 55\",\n                                       annual_salary_median >= 55000 & annual_salary_median <= 80000 ~ \"56 to 80\",\n                                       TRUE ~ \"<80\"),\n         .after = salary_level) %>%\n  mutate(salary_leg = paste(salary_level,\"-\",salary_level_class),\n         .after = salary_level,\n         salary_leg = as.factor(salary_leg))\n\nunique(my_df$salary_leg)\nlegend_ord <- levels(with(my_df, reorder(annual_salary_median,year)))\nmy_df$salary_level <- factor(my_df$salary_level, # Relevel group factor\n                             levels = c(\"low\",\"medium\",\"high\",\"top high\"))\n\n\ntheme_nurses <- xkcd::theme_xkcd() +\n  theme(text = element_text(color = \"grey80\",family = \"Comic Sans MS\"),\n        plot.title = element_text(hjust = 0.5,size = 24,face = \"bold\"),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(family = \"Comic Sans MS\"),\n        plot.subtitle = element_text(hjust = 0.5),\n        plot.caption.position = \"plot\",\n        legend.background = element_blank(),\n        legend.box.background = element_blank(),\n        legend.key = element_blank(),\n        legend.title = element_text(size = 11,family = \"Comic Sans MS\",face = \"bold\"),\n        legend.text = element_text(size = 9,family = \"Comic Sans MS\"),\n        axis.ticks = element_line(size = 2,color = \"orange\"),\n        axis.line.x = element_line(color = \"grey80\"),\n        axis.title.x = element_text(size = 12,face = \"bold\"),\n        axis.title.y = element_text(size = 12,face = \"bold\"),\n        axis.text.y = element_text(color = \"grey80\"),\n        axis.text.x = element_text(color = \"grey80\"),\n        panel.grid.major.y = element_line(color = \"grey80\"),\n        panel.background = element_rect(color = \"grey40\",fill = \"grey40\"),\n        plot.background = element_rect(color = \"grey40\",fill = \"grey40\"))\n\n\nstair_sal <- my_df %>%\n  ggplot(aes(factor(year), y = annual_salary_median, group = salary_level, fill = salary_level)) +\n  geom_col(width = 1) +\n  labs(fill = \"Salary level\",\n       x = \"Years\",y = \"Cumulate annual median salaries by salary level\",\n       title = \"How much should salary increase per year?\",\n       subtitle = \"Nurses' annual median salary values by 4 levels\n        \") +\n  scale_x_discrete(breaks = seq(1998,2020,3)) +\n  scale_y_continuous(labels = scales::number_format(scale = 1/1000000,suffix = \"M\",accuracy = 1)) +\n  scale_fill_manual(limits = c(\"low\", \"medium\",\"high\",\"top high\"),\n                    labels = c(\"high\" = \"high from 56,000 to 80,000\",\n                             \"low\" = \"low less than 35,000\",\n                             \"medium\" = \"medium from 35,000 to 55,000\",\n                             \"top high\" = \"top high greater than 80,000\"),\n                    values = RColorBrewer::brewer.pal(4,\"Spectral\")) +\n  guides(fill = guide_legend(ncol = 4,title.position = \"left\")) +\n  theme_nurses +\n  theme(legend.position = c(0.5,0.99)) +\n  annotate(\"text\", x = 5, y = 1100000,label = \"Medium Salary from 35,000 to 60,000\",family = \"xkcd\" ) +\n  annotate(\"text\", x = 20, y = 300000,label = \"Top High up to 118,500\",family = \"xkcd\" ) +\n  annotate(\"text\", x = 20, y = 160000,label = \"started in 2008\",family = \"xkcd\" ) +\n  annotate(\"text\", x = 16, y = 2000000,label = \"High Salaries between 56,000 and 80,000\",family = \"xkcd\" ) +\n  annotate(\"curve\", x = 3, xend = 5, y = 3600000, yend = 2600000,color = \"grey85\", curvature = 0.5,\n           arrow = arrow(angle = 30, length = unit(0.2, \"inches\"),ends = \"last\", type = \"open\")) +\n  annotate(\"text\", x = 4, y = 3700000,label = \"Low salaries below 30,000\",family = \"xkcd\" ,color = \"red\") +\n  annotate(\"text\", x = 8, y = 3500000,label = \"stopped in 2011\\nto reach 35,000\",family = \"xkcd\",color = \"red\" ) +\n  annotate(\"curve\", x = 9, xend = 13, y = 3500000, yend = 3400000,color = \"grey85\", curvature = -0.5,\n         arrow = arrow(angle = 30, length = unit(0.2, \"inches\"),ends = \"last\", type = \"open\"))\n\n\n\nsalaries_by_year <- my_df %>%\n  group_by(year,salary_level) %>%\n  summarize(total = sum(annual_salary_median),.groups = \"drop\") %>%\n  pivot_wider(names_from = year,values_from = total,values_fill = 0)\n\nfacet_sal <- salaries_by_year %>%\n  pivot_longer(cols = \"1998\":\"2020\",names_to = \"years\",values_to = \"tot salary by level\") %>%\n  ggplot(aes(`tot salary by level`,salary_level,group = years)) +\n  geom_col(aes(fill = salary_level)) +\n  labs(x = \"Total amount of annual median salaries by level\",\n       y = \"Salary levels - $10thous.\",\n       fill = \"Salary level\",\n       caption = \"(values are in $,10thous.,M = millions of $)\\nDataSource: Registered Nurses,DataWorld,BLS\\nTidyTuesday Week41 DataViz: Federica Gazzelloni\") +\n  scale_x_continuous(labels = scales::number_format(scale = 1/100000,accuracy = 1)) +\n  scale_fill_manual(limits = c(\"low\", \"medium\",\"high\",\"top high\"),\n                    labels = c(\"high\" = \"high from 56,000 to 80,000\",\n                             \"low\" = \"low less than 35,000\",\n                             \"medium\" = \"medium from 35,000 to 55,000\",\n                             \"top high\" = \"top high greater than 80,000\"),\n                    values = RColorBrewer::brewer.pal(4,\"Spectral\")) +\n  guides(fill = guide_legend(ncol = 2,title.position = \"top\", title.hjust = 0.5)) +\n  facet_wrap(~years,scale = \"free_x\") +\n  theme_nurses +\n  theme(legend.position = c(0.80,0.07),\n        strip.background = element_rect(color = \"grey40\",fill = \"grey40\"),\n        strip.text = element_text(color = \"grey80\",face = \"bold\"))\n\n\nimg_nurse <- image_read(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w41/nurse.png\"))\nimg_dataworld <- image_read(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w41/dataworld.png\"))\nimg_bls <- image_read(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w41/bls.png\"))\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\nlibrary(cowplot)\nfinal <- ggdraw() +\n  draw_plot(stair_sal/facet_sal) +\n  draw_image(img_nurse, x = 0.1, y = 0.45,width = 0.08) +\n  draw_image(img_dataworld, x = 0.13, y = -0.46,width = 0.05) +\n  draw_image(img_bls, x = 0.18, y = -0.46,width = 0.05) +\n  draw_image(tidy_logo, x = 0.04, y = -0.46,width = 0.09) \n\n\n# save final plot\nragg::agg_png(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w41/w41_nurses.png\"),\n              res = 320, width = 12, height = 14, units = \"in\")\n#stair_sal/facet_sal\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w18_ceo_departures/w18_ceo_departures.html",
    "href": "tidytuesday/cases2021/posts2021/w18_ceo_departures/w18_ceo_departures.html",
    "title": "Ceo Departures",
    "section": "",
    "text": "Tidytuesday week 28——— & future day28 ————–\n\n# inspired by http://applied-r.com/plotting-forecast-data-objects-ggplot/\n\n\nlibrary(tidyverse)\nlibrary(tidytuesdayR)\nlibrary(DataExplorer)\nlibrary(lubridate)\nlibrary(tsibble)\nlibrary(ggrepel)\nlibrary(corrplot)\nlibrary(forecast)\nlibrary(patchwork)\nlibrary(cowplot)\nlibrary(ragg)\nlibrary(RColorBrewer)\n\n\n# load data ###############################\ndepartures <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-27/departures.csv')\n\n# check and wrangling #####################\nhead(departures)\nglimpse(departures)\nprofile_missing(departures)\n\n\ndf <- departures%>%\n  select(2,4,6,7,8,11,12,13)%>%\n  arrange(leftofc)%>%\n  mutate(diff=fyear_gone-fyear)%>%\n  drop_na()%>%\n  select(coname,exec_fullname,fyear,fyear_gone,diff,leftofc,departure_code,ceo_dismissal,max_tenure_ceodb)%>%\n  filter(abs(diff)<6)%>%filter(!diff<0)\n\nrange(df$fyear_gone)\n\n# first plot to see the pattern ###############\n# excluded raws with more than 6 years difference between fyear and fyear_gone\nggplot(df) + \n  geom_point(aes(x=factor(fyear),y=factor(fyear_gone),color=ifelse(abs(diff)<6 ,\"in bound\",\"out of bound\")) )+\n  labs(color=\"\")+\n  theme(axis.text.x = element_text(angle=90))\n  \n# selecting data for main plot ############################\ntot_dismissal <- df %>%\n  mutate(y_month=yearmonth(leftofc),month=month(leftofc))%>%\n  group_by(y_month,month)%>%\n  summarize(tot_dism=sum(ceo_dismissal),tot_posit=sum(max_tenure_ceodb))%>%\n  ungroup()\n\n\n# set the theme and modifications as it is needed --------------------\nlibrary(ggthemes)\n\n# theme for forecast data objects\ntheme.fxdat <- theme_gdocs() +\n  theme(plot.title = element_text(size = 25,color=\"grey45\"),\n        plot.subtitle = element_text(size = 11),\n        plot.caption = element_text(size = 9, hjust = 0, vjust = 0, colour = \"grey50\"),\n        axis.title.y = element_text(face = \"bold\", color = \"gray30\"),\n        axis.title.x = element_text(face = \"bold\", color = \"gray30\", vjust = -1),\n        axis.text.x = element_text(angle=90),\n        panel.background = element_rect(fill = \"grey95\", colour = \"grey75\"),\n        panel.border = element_rect(colour = \"grey75\"),\n        panel.grid.major.y = element_line(colour = \"white\"),\n        panel.grid.minor.y = element_line(colour = \"white\", linetype = \"dotted\"),\n        panel.grid.major.x = element_line(colour = \"white\"),\n        panel.grid.minor.x = element_line(colour = \"white\", linetype = \"dotted\"),\n        strip.background = element_rect(size = 1, fill = \"white\", colour = \"grey75\"),\n        strip.text.y = element_text(face = \"bold\"),\n        axis.line = element_line(colour = \"grey75\"),\n        legend.position = \"top\",\n        legend.box = \"horizontal\",\n        legend.box.just = \"bottom\")\n\ntot_dismissal$y_month[80]\ntot_dismissal$tot_dism+rnorm(tot_dismissal$tot_dism)[1]\n\n# plotting ########################################\nlibrary(zoo)\nset.seed(345)\nplot1 <- ggplot(tot_dismissal,aes(x=y_month,y=tot_dism+rnorm(tot_dism))) + \n  geom_point(aes(color=\"Number of dismissal\"),fill=\"black\")+\n  geom_line(aes(color=\"Dismissal Trend\"),size=0.2) +\n  geom_smooth(aes(color=\"Smoothed conditional means\"))+\n  geom_line(aes(y_month,rollmedian(tot_dism, k = 15, fill = NA, align = \"center\"),color=\"Rolling median\"),size=0.8)+\n  labs(x=\"Time(Year-Month)\",\n       y=\"Normalized total n. of dismissal\",\n       title=\"33 Years trend CEO Departures\",\n       subtitle=\"1988 - 2021\\n Rolling median, smooth variation line and trend\",\n       caption=\"\",\n       color=\"\"\n       )+\n  scale_color_brewer(palette = \"Dark2\")+\n  theme.fxdat \n\n\n\n# future ----------------------------\nx<-tot_dismissal$tot_dism\n\n# create time series data object (ts) using tot_dism\nres.gen <- ts(x, frequency = 12, start = c(1992, 6))\n\nxx<-tot_dismissal%>%\n  pivot_wider(names_from=\"month\",values_from=\"tot_dism\",values_fill=0)%>%select(-tot_posit,-y_month)\n\n########################\nfit.y <- tslm(res.gen ~ trend + season)\nfx.y <- forecast(fit.y, h = 17, level = c(80, 95, 99))\n\n\nsource(\"plot_fx.R\")\n\nplot2 <- plot_fx(fx.y,\n        PI = TRUE,\n        line.cols = NA,\n        shade.cols = NA,\n        show.gap = TRUE,\n        date.breaks = \"15 months\",\n        date.format = \"%b-%y\",\n        main.title = \"CEO Departures forecast\",\n        sub.title = \"Transformed 33 years trend in Linear trend with seasonal dummy variables\",\n        caption = \"Viz. @fgazzelloni | DataSource: Gentry et al. & investors.com | TidyTuesday week18\",\n        x.title = \"CEO Departures by Year and Month\",\n        y.title = \"Total numbers of CEO Departures\")\n\n\nfinal<-plot1+plot2\n\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"w18\", \"tidytuesday_Departures.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################ \nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"W18/tidytuesday_Departures.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_Departures.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w48_dr_who/w48_dr_who.html",
    "href": "tidytuesday/cases2021/posts2021/w48_dr_who/w48_dr_who.html",
    "title": "Dr. Who",
    "section": "",
    "text": "rm(list=ls())\n\nlibrary(tidyverse)\nlibrary(\"datardis\")\n\ndirectors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-23/directors.csv')\nepisodes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-23/episodes.csv')\nwriters <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-23/writers.csv')\n\nmy_df <- directors%>%\n  full_join(episodes,by=\"story_number\")%>%\n  full_join(writers,by=\"story_number\")\n\n# my_df%>%head\n\nuk_viewers<- my_df$uk_viewers\nuk_viewers[is.na(uk_viewers)]<- 0\n\n\n# https://www.r-graph-gallery.com/59-nifty-graph.html\nmoxbuller = function(uk_viewers) {   \n  u = runif(uk_viewers)   \n  v = runif(uk_viewers)   \n  x = cos(2*pi*u)*sqrt(-2*log(v))  \n  y = sin(2*pi*v)*sqrt(-2*log(u))\n  r = list(x=x, y=y)\n  return(r) \n}\nr = moxbuller(5000) \n\n\n# https://github.com/coolbutuseless/threed\nlibrary(threed)\ncamera_to_world <- threed::look_at_matrix(eye = c(4, 2, 5), \n                                          at = c(0, 0, 0))\nobj <- threed::mesh3dobj$cube %>%\n  transform_by(invert_matrix(camera_to_world)) %>%\n  perspective_projection()\n\n\nplot<-  data.frame(r)%>%\n  ggplot(aes(x=x,y=y,z=0))+\n  geom_point(shape=\".\",col=\"blue\")+\n  geom_polygon(data=obj,aes(x = x*25, y = y*25, group = zorder,\n                            linetype = hidden,  size = hidden), #zorder the drawing order of the elements from back to front\n               fill = NA, colour = 'blue', size = 0.7,\n               show.legend = F) +\n  geom_rect(mapping=aes(xmin=-30,xmax=0.7,ymin=0.2,ymax=0.8),\n            fill=NA)+  \n  theme_void() +\n  theme(plot.background = element_rect(color=\"black\",\n                                       fill=\"black\"))\n \n\nlibrary(showtext)\n\n# Import fonts\nfont_add_google(\"Luckiest Guy\", \"Luckiest\")\nfont_add_google(\"Poiret One\", \"Poiret\")\nshowtext_auto()\nshowtext_opts(dpi = 320)\n\n\nplot2<-my_df%>%\nggplot(aes(x=uk_viewers,y=rating))+\n  geom_jitter(aes(color=duration),show.legend = T)+\n  geom_smooth()+\n  theme_void()+\n  labs(x=\"rating\",y=\"viewers\",color=\"\")+\n  scale_color_viridis_c()+\n  theme(plot.background = element_rect(color=NA,\n                                       fill=NA),\n        text = element_text(family=\"Luckiest\",color=\"blue\"),\n        legend.position = c(0.5,-0.4),\n        legend.direction = \"horizontal\",\n        legend.title = element_blank())\n\n\n\nmy_df%>%\n  mutate(year=lubridate::year(first_aired))%>%\n  group_by(year)%>%\n  summarize(tot_view=sum(uk_viewers))%>%\n  arrange(-tot_view)#,rating,director)%>%arrange(-uk_viewers,-rating)\n\n######################################\nlibrary(prophet)\ndf<-my_df%>%select(ds=first_aired,y=uk_viewers)\nm <-prophet(df)\nfuture <- prophet::make_future_dataframe(m, periods=365)\nforecast <- predict(m,future)\n\n#### PROPHET PLOT COMPONENTS ###############################################\nplot3<-prophet_plot_components(m, forecast)\n######################################\ntrend <- forecast%>%\n  ggplot(aes(x=ds,y=trend))+\n  geom_line(color=\"blue\")+\n  theme_void()+\n  labs(x=\"rating\",y=\"viewers\")+\n  theme(plot.background = element_rect(color=NA,\n                                       fill=NA),\n        text = element_text(family=\"Luckiest\",color=\"blue\"),\n        axis.text.x = element_text(color=\"blue\",family = \"Luckiest\"))\n######################################\ntrend\n######################################\nweekly<- forecast%>%\n  mutate(day=lubridate::wday(ds,label = T,abbr = F,\n                             week_start = getOption(\"lubridate.week.start\", 7),\n                             locale = Sys.getlocale(\"LC_TIME\")),\n         .after=ds) %>%\n  select(ds,day,weekly,yearly,trend) %>%\n  \n  ggplot(aes(x=day,y=weekly,group = 1))+\n  geom_line(color=\"blue\")+\n  #geom_text(aes(label=day),color=\"blue\",family=\"Luckiest\")+\n  theme_void()+\n  labs(x=\"rating\",y=\"viewers\")+\n  theme(plot.background = element_rect(color=NA,\n                                       fill=NA),\n        text = element_text(family=\"Luckiest\",color=\"blue\"),\n        axis.text.x = element_text(color=\"blue\",\n                                   family = \"Luckiest\",\n                                   angle=15,size=8))\n######################################\nweekly # m$changepoints\n######################################\n\nlibrary(patchwork)\nplot3<-trend/weekly\n\n\nlibrary(cowplot)\nfinal <- ggdraw()+\n  draw_plot(plot)+\n  draw_plot(plot2,x = 0.02, y = 0,scale = 0.3)+\n  draw_plot(trend,x = -0.4, y = 0.2,scale = 0.25,height = 0.7,width=1.2)+\n  draw_plot(weekly,x = -0.4, y = -0.06,scale = 0.25,height = 0.7,width=1.2)+\n  draw_text(\"Dr. WHO - UK Viewers\", x=0.4,y=0.93,\n            color=\"blue\",size=42,family=\"Luckiest\")+\n  draw_text(\"Favorite months for watching are April, June and September\n            While the Years with the highest numbers of views \n            are 2010 and 2008\",\n            x=0.34,y=0.8,size=18,family=\"Luckiest\",color=\"blue\")+\n  draw_text(\"General trend declined after 2010 \n            favorite days of the week for watching are Tuesday to Friday\",\n            x=0.4,y=0.1,size=18,family=\"Luckiest\",color=\"blue\")+\n  draw_text(\"Trend\",x=0.04,y=0.56,angle=90,color=\"blue\",family = \"Luckiest\")+\n  draw_text(\"Weekly\",x=0.05,y=0.3,angle=90,color=\"blue\",family = \"Luckiest\")+\n  draw_text(\"Ratings\",x=0.365,y=0.53,angle=90,color=\"blue\",family = \"Luckiest\")+\n  draw_text(\"Viewers\",x=0.5,y=0.35,angle=0,color=\"blue\",family = \"Luckiest\")+\n  draw_text(\"Duration\",x=0.43,y=0.25,angle=0,color=\"blue\",family = \"Luckiest\",size=12)+\n  draw_text(\"Nifty UK Viewers density\",x=0.94,y=0.73,angle=88,\n            color=\"blue\",size=12,\n            family=\"Luckiest\")+\n  draw_text(\"#TidyTuesday week48 Dr.Who - DataViz: Federica Gazzelloni\", \n            x=0.4,y=0.03,color=\"blue\",size=14,family=\"Luckiest\")+\n  draw_image(\"/Users/federica/Documents/R/R_general_resources/TidyTuesday/TidyTuesday/w48/drwho.png\",\n             x=-0.14,y=0.17,scale=0.15)+\n  draw_image(\"/Users/federica/Documents/R/R_general_resources/TidyTuesday/TidyTuesday/w48/tardis.jpg\",\n             x=-0.42,y=0.42,scale=0.12)\n\nragg::agg_png(here::here(\"/Users/federica/Documents/R/R_general_resources/TidyTuesday/TidyTuesday/w48/dr_who2.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w39_emmy_awards/w39_emmy_awards.html",
    "href": "tidytuesday/cases2021/posts2021/w39_emmy_awards/w39_emmy_awards.html",
    "title": "Emmy Awards",
    "section": "",
    "text": "TidyTuesday\n\n\nweek 39 nominees EMMYS’\n\n\nload libraries ————–\n\nlibrary(tidyverse)\n\nlibrary(extrafont)\nlibrary(showtext)\n#font_families_google()\nfont_add_google(\"Roboto Condensed\",\"Roboto Condensed\")\n\nlibrary(patchwork)\nlibrary(cowplot)\n\n# load the data ------\n\nnominees <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-21/nominees.csv')\nhead(nominees)\n\n# data wrangling -------\n# arrange the set to have the count of the types\n# add a column with the icons for types\n\nmy_df <-\n  nominees %>%\n  filter(year>=2015) %>%\n  filter(distributor==c(\"HBO\")) %>%\n  count(year,distributor,type,sort=T) %>%\n  mutate(distributor_lab=paste0(\"HBO_\",year))%>%\n  mutate(img = if_else(\n      type == \"Winner\",\n      \"<img src='w39/emmy_winner.png' width='12'/>\",\n      \"<img src='w39/emmy_nom.png' width='12'/>\"\n    ))\n\n\n\n# set a special vector for the facet strip names with the type counts\n\ntype_c <- c(\"HBO_2015\"= \"219 to 140\",\n            \"HBO_2016\"= \"198 to 75\",\n            \"HBO_2017\"= \"216 to 118\",\n            \"HBO_2018\"= \"302 to 96\",\n            \"HBO_2019\"= \"297 to 146\",\n            \"HBO_2020\"= \"217 to 124\",\n            \"HBO_2021\"= \"261 to 66\") \n\n\n# make the plot -------\n\nlibrary(waffle)\nlibrary(ggtext)\nlibrary(ggthemes)\n\n\nplot <- ggplot(my_df, aes(fill = type, values = n,label = img)) +\n  facet_wrap(distributor_lab~year, nrow = 1, strip.position = \"bottom\",\n             labeller = labeller(distributor_lab  = as_labeller(type_c))) +\n  stat_waffle(geom = \"richtext\", fill = NA, label.color = NA, flip = TRUE, n_rows = 10) +\n  scale_x_discrete() + \n  scale_y_continuous(labels = function(x) x * 10, expand = c(0,0)) +\n  ggthemes::scale_fill_fivethirtyeight(name=NULL) +\n  coord_equal() +\n  labs(title=\"\\n\",subtitle=\"\\n\",\n    caption=\"Source: The data this week comes from emmys.com\") +\n  theme_minimal(base_family = \"Roboto Condensed\") +\n  theme(text=element_text(family = \"Roboto Condensed\"),\n        axis.ticks.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.text.x = element_blank(),\n        strip.text = element_text(family = \"Roboto Condensed\",size=22,face=\"bold\"),\n        legend.position = \"top\",\n        panel.grid.major.x = element_line(color=\"grey50\",size=10),\n        panel.grid.minor.x = element_line(color=\"grey50\",size=10),\n        plot.margin = margin(5,5,1,5,unit = \"pt\"),\n        plot.background = element_rect(color=\"#F0F8FF\", fill=\"#F0F8FF\"),\n        plot.caption.position = \"panel\",\n        plot.caption = element_text(family = \"Roboto Condensed\",color= \"grey40\", face=\"bold\",size=30, hjust=0,vjust=-1)) \n\n\n#------------finish touches\n\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\n\n\nlibrary(ggpubr)\n\ngraphics <- ggarrange(plot) +\n  theme(plot.background = element_rect(fill = \"#F0F8FF\", color = \"#F0F8FF\"))\n\n\n# annotate the plot\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"EMMY AWARD WINNERS AND NOMINEES\",\n                                              color = c(\"grey28\"), face = \"bold\", size = 34,\n                                              family = \"Roboto Condensed\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: TidyTuesday week39\",\n                                                 color = \"grey28\",family = \"Roboto Condensed\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 24),\n                              left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size = 12),\n                              right = text_grob(bquote(\"\"), color = c(\"#778899\"),rot = 90,size = 10),\n                              fig.lab = \"\", fig.lab.face = \"bold.italic\",fig.lab.size = 8,\n                              fig.lab.pos = \"bottom.right\"\n)\n\nfinal_plot <-\n  final_plot +\n\n  annotate(geom = 'segment',y = 0.78, yend = 0.93, x = 0.1,xend = 0.1, color=\"#8A2BE2\", size = 9) +\n\n  annotate(geom = \"text\", label = \"HBO RECORD AT THE EMMYS \\nAWARDS AND NOMINEES\",\n           x = 0.44, y = 0.875,colour = \"black\",size = 16,family = \"Roboto Condensed\",fontface=\"bold\") +\n\n  annotate(geom = \"text\", label = \"Number of Emmy nominations and wins for HBO\",\n           x = 0.44, y = 0.79,colour = \"grey40\",size = 10,family = \"Roboto Condensed\") +\n  \n  annotate(geom = \"text\", label = \"Winner\",\n         x = 0.5, y = 0.1,colour = \"grey50\",size = 8,family = \"Roboto Condensed\") +\n  annotate(geom = \"text\", label = \"Nominee\",\n         x = 0.32, y = 0.1,colour = \"grey50\",size = 8,family = \"Roboto Condensed\") \n\n\n# add the images for the legend keys \n\nimgWin <- image_read(here::here(\"w39/emmy_winner.png\"))\nimgNom <- image_read(here::here(\"w39/emmy_nom.png\"))\nimgHBO <- image_read(here::here(\"w39/hbo.png\"))\n\nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(imgWin, x = 0.55, y = -0.4,width = 0.06)+\n  draw_image(imgNom, x = 0.37, y = -0.4,width = 0.06)+\n  draw_image(imgHBO, x = 0.1, y = -0.1,width = 0.12)\n\n\n\n## save final plot ----\n\nragg::agg_png(here::here(\"w39/w39_nominees.png\"),\n              res = 320, width = 12, height = 14, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\n\n\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\ntidy_final <- image_read(here::here(\"w39/w39_nominees.png\"))\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator = \"atop\",\n                                 gravity = \"southeast\")\n\nimage_write(attached_logo, path = \"w39_nominees.png\", format = \"png\")"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w21_ask_a_manager_survey/w21_ask_a_manager_survey.html",
    "href": "tidytuesday/cases2021/posts2021/w21_ask_a_manager_survey/w21_ask_a_manager_survey.html",
    "title": "Ask a Manager Survey",
    "section": "",
    "text": "Ask a Manager Survey\n\nrm(list=ls())\n\nlibrary(tidyverse)\nlibrary(DataExplorer)\noptions(scipen=999)\n\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 21)\nsurvey <- tuesdata$survey\n\n\nhead(survey)\nprofile_missing(survey)\n\nmy_df<-survey%>%select(2,4,6,8,14,15)\n\n\narrange(plyr::count(my_df$currency),freq)\n\nmy_currency<-c(\"EUR\",\"GBP\",\"USD\")\n\ncountry_df<-data.frame(country_name=c(\"Europe\",\"UK\",\"USA\"),\n                       currency=c(\"EUR\",\"GBP\",\"USD\"))\n\nmy_df_curr<-my_df%>%\n  filter(currency%in%my_currency,annual_salary<3000000)%>%\n  inner_join(country_df,by=\"currency\")\n\nstr(my_df_curr)\nnames(my_df)\n\n\nmy_df_curr<-my_df_curr%>%\n  mutate(how_old_are_you=case_when(\n    how_old_are_you==\"65 or over\"~\"65+\",\n    how_old_are_you==\"under 18\"~\"<18\",\n    TRUE~how_old_are_you),\n    years_of_experience_in_field=case_when(\n      years_of_experience_in_field==\"1 year or less\"~\"0-1\",\n      years_of_experience_in_field==\"41 years or more\"~\"41+\",\n      TRUE~sub(\" years$\",\"\",years_of_experience_in_field)),\n    overall_years_of_professional_experience=case_when(\n      overall_years_of_professional_experience==\"1 year or less\"~\"0-1\",\n      overall_years_of_professional_experience==\"41 years or more\"~\"41+\",\n      TRUE~sub(\" years$\",\"\",overall_years_of_professional_experience)),\n    overall_years_of_professional_experience = as.factor(overall_years_of_professional_experience),\n    how_old_are_you = as.factor(how_old_are_you),\n    years_of_experience_in_field = as.factor(years_of_experience_in_field))%>%\n  arrange(desc(how_old_are_you))\n\n\nmy_df_curr<- my_df_curr%>%\n  mutate(years_of_experience_in_field=case_when(\n    TRUE~gsub(\" \",\"\",years_of_experience_in_field)),\n    overall_years_of_professional_experience=case_when(\n      TRUE~gsub(\" \",\"\",overall_years_of_professional_experience))\n  )\n\n\nnames(my_df_curr)<-c(\"age\",\"job_title\",\"annual_salary\",\"currency\" ,\"yr_prof_exp\",\"yr_exp\",\"country_name\")\n\n######### PLOTTING ####################\n\n\nlibrary(viridis)\nlibrary(hrbrthemes)\nlibrary(ggthemes)\n\nscr_df<-data.frame(country_name=c(\"Europe\",\"UK\",\"USA\"),\n                   scr=c(1/1.22,1/1.41,1))\n\nmy_df_curr<-my_df_curr%>%inner_join(scr_df,by=\"country_name\")%>%\n  mutate(salaryUSD=annual_salary*scr)\n\nlibrary(extrafont)\nfonts()\nleg_lab<-c(\"0-1\",\"2-4\",\"5-7\",\"8-10\",\"11-20\",\"21-30\",\"31-40\",\"40+\")\nnewcolors<-c(\"#004586\",\"#ffd320\",\"#314004\",\"#aecf00\",\"#ff420e\",\n             \"#579d1c\",\"#7e0021\",\"#83caff\")\n\n\nsurvey_plot<-ggplot(my_df_curr, aes(x=age, y=salaryUSD)) +\n  geom_line(aes(group=age))+\n  geom_point(aes(group=yr_exp,col=yr_exp),\n            alpha=0.5) +\n  geom_text(aes(label=job_title,size=salaryUSD),hjust = 0, nudge_x = 0.05,\n            check_overlap = TRUE,family=\"World of Water\") +\n  scale_y_continuous(labels = dollar_format(prefix=\"$\"), limits = c(0,NA))+\n  scale_color_manual(labels = leg_lab,values = newcolors)+\n  labs(title=\"Who is the Richest?\",\n       subtitle=\"Industry job title pyramid annual Salary(USD) by age - Ask a Manager Salary Survey \",\n       caption=\"Viz. @fgazzelloni | DataSource: Ask a Manager Salary Survey | TidyTuesday Week21\",\n       x=\"Age\", y=\"Salary(USD)\",\n       col=\"Years of experience in the field\",\n       size=\"\")+\n  scale_size(guide=FALSE)+\n  theme_calc() +\n  theme(plot.margin=unit(c(c(1, 1, 0.5, 0.5)), units=\"line\"),\n        legend.position = c(0.83,0.7),\n        #legend.justification = c(\"right\", \"top\"),\n        #legend.box.just = \"right\",\n        legend.margin = margin(6, 6, 6, 6),\n        legend.direction = \"horizontal\",\n        legend.title = element_text(family=\"World of Water\"),\n        legend.text = element_text(family=\"World of Water\"),\n        legend.background = element_rect(color = \"#4b1f6f\"),\n        plot.title = element_text(family=\"World of Water\",size=rel(4)),\n        plot.subtitle = element_text(family=\"World of Water\",size=20),\n        plot.caption = element_text(family=\"World of Water\",size=10,hjust = 0.5),\n        axis.title = element_text(family=\"World of Water\"),\n        axis.text = element_text(family=\"World of Water\"),\n        axis.line = element_line(size = 3, colour = \"grey80\"),\n        axis.ticks = element_line(size=2,color=\"#4b1f6f\"))\n\n\n\n################################################################################\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"tidytuesday_Ask_a_manager_survey.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nsurvey_plot\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"tidytuesday_Ask_a_manager_survey.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_Ask_a_manager_survey.png\",\n            format = \"png\") # save final plot\n\n\n\n##############################################################"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w17_netflix/w17_netflix.html",
    "href": "tidytuesday/cases2021/posts2021/w17_netflix/w17_netflix.html",
    "title": "NETFLIX & Upwards",
    "section": "",
    "text": "library(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(extrafont)\nlibrary(showtext)\n\nshowtext_opts(dpi = 320)\n\n\nshowtext_auto(enable = TRUE)\nmy_family = \"Roboto Condensed\"\n\n#tuesdata <- tidytuesdayR::tt_load(2021, week = 17)\n\nnetflix <- tuesdata$netflix\n\nhead(netflix)\ndim(netflix)\n\nset.seed(73)\nNETFLIX_plot <- ggplot(data=netflix, aes(x=release_year, y=sample(7787),fill=release_year)) +\n  geom_col() +\n  scale_fill_gradient(low = \"#333333\",high = \"red\") + \n  labs(title=\"NETFLIX\",\n       subtitle=\"Show released years from 1925 to 20121\",\n       caption=\"Viz Federica Gazzelloni | DataSource: Kaggle - 'NETFIX titles'| Tidytuesday week 17 & Upwards Day 20\",\n       x=\"Time(Year)\",\n       y=\"\",\n       fill=\"Release Year\")+\n  theme_void() +\n  theme(plot.title=element_text(family=my_family,size=50,face=\"bold\",color=\"red\"),\n        plot.subtitle = element_text(family=my_family,size=15,face=\"bold\"),\n        plot.caption = element_text(family=my_family,size=10,face=\"bold\"),\n        \n        panel.background = element_rect(fill = \"#333333\") ,\n        plot.margin = margin(10,10,10,10),\n        panel.grid = element_line(color = \"white\",size=2),\n        panel.grid.major = element_line(color = \"white\",size=1.5),\n        panel.grid.minor =element_line(color = \"white\",size=2), \n        axis.line = element_line(colour = \"white\"),\n        axis.line.x = element_line(color=\"white\"),\n        axis.line.y = element_blank(),\n        axis.text.x = element_text(family=my_family,size=10,face=\"bold\"),\n        legend.text = element_text(family=my_family,size=10,face=\"bold\"),\n        legend.title = element_text(family=my_family,size=10,face=\"bold\"),\n        legend.position = \"bottom\")\n\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"w17\", \"tidytuesday_NETFLIX.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nNETFLIX_plot\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################ \nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\ntidy_NETFLIX_plot <- image_read(\"W17/tidytuesday_NETFLIX.png\")\n\nattached_logo <- image_composite(tidy_NETFLIX_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_NETFLIX.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w28_independence_days/w28_independence_days.html",
    "href": "tidytuesday/cases2021/posts2021/w28_independence_days/w28_independence_days.html",
    "title": "International Independence Days",
    "section": "",
    "text": "library(tidyverse)\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 28)\n\nholidays <- tuesdata$holidays\nnames(holidays)\n\n\nlibrary(maps)\nlibrary(sf)\n\nmaps::map(\"world\")\n\n\nworld <- sf::st_as_sf(map(\"world\",plot=FALSE,fill=TRUE))\nworld <- cbind(world, sf::st_coordinates(sf::st_centroid(world)))\n\n\nholidays_map <- holidays %>%\n  filter(str_detect(name_of_holiday,\"(?i)inde\"))%>%\n  left_join(world, by=c(\"country\"=\"ID\")) %>%\n  select(country,date_parsed,name_of_holiday,independence_from,X,Y)%>%\n  mutate(country=as.factor(country))\n\n\nlibrary(showtext)\nlibrary(extrafont)\nshowtext.auto(enable=FALSE)\n\n“#EEE9E9”\n\nmapdata <- ggplot2::map_data(\"world\") %>%\n  filter(!region==c(\"Antartica\",\"Greenland\",\"French Southern and Antartic Lands\")) %>%\n  mutate(region=recode(region, \n                       USA=\"United States\",\n                       UK=\"United Kingdom\"))\n           \n\nfinal_plot <- ggplot() +\n  geom_map(data=mapdata,map = mapdata,aes(map_id=region),fill= \"#F0F8FF\",color= \"#FAEBD7\")+\n  geom_point(data=world,aes(x=X,y=Y),size=1,color=\"grey\",alpha=0.3)+\n  geom_point(data=holidays_map,aes(x=X,y=Y),size=0.5,color=\"black\")+\n  geom_text(data=holidays_map,aes(x=X,y=Y,label=country),family=\"Andalus\",\n                            check_overlap = TRUE,size=1.5,color=\"#363636\",hjust=0,vjust=0)+ #\n  geom_text(data=holidays_map,aes(x=X,y=Y,label=date_parsed),\n            family=\"Andalus\", check_overlap = TRUE,size=0.8,\n            color=\"#CD1076\",vjust=0.8,hjust=-1)+\n  expand_limits(x=mapdata$long,y=mapdata$lat)+\n  coord_map(projection = \"mercator\",xlim=c(-180,180)) +\n  labs(title=\"Date parsed: Independent Days celebrating Countries\",\n       caption= \"DataViz: @fgazzelloni, DataSource: International Independence Days,    Wikipedia,WorldAtlas.com - #TidyTuesday w28\")+\n  guides(fill=\"none\") +\n  ggthemes::theme_map()+\n    theme(axis.text = element_blank(),\n          plot.background = element_rect(fill=\"#C5E5F0\",color=\"#E0EEEE\"),\n          plot.title = element_text(color=\"#363636\",family=\"Andalus\",size=18,face=\"bold\"),\n          plot.caption = element_text(size=10))\n\n\n\nfinal_plot\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w28\",\"w28_independence_days.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()\n\n##################################################"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html",
    "href": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html",
    "title": "Olympic Medals",
    "section": "",
    "text": "35 Years of Olympic Games\nConverting “region” vector into country code “iso2c” with {countrycodes} to be able to use {ggflags}\nsome values were not matched unambiguously:\nI could do a dataset with only “Individual Olympic Athletes” and eventually use it to add some info in a geom_\nAfter a quick look at the “ambiguous_country_codes”, just one is relevant with a “Gold medal”, then will see how to use it.\nUpdate “my_olympics” with countrycode():\n35 Years: 1896 to 2016\nAge: 11 to 71 (61 different ages)"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html#section-age-sex",
    "href": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html#section-age-sex",
    "title": "Olympic Medals",
    "section": "Section Age & Sex",
    "text": "Section Age & Sex\n\nage_sex_plot <- my_olympics %>% \n  group_by(sex) %>%\n  summarize(age,height,weight,year) %>% # count(age)\n  ungroup() %>% \n  ggplot(aes(x=factor(age),fill=factor(sex))) + \n  geom_bar(position=\"stack\") +\n  scale_fill_fivethirtyeight() +\n  labs(title=\"Distribution of age by sex\",\n       subtitle=\"61 different age years form 11 to 71 years old gamers\",\n       fill=\"Sex\") + \n  theme_fivethirtyeight() +\n  theme(axis.text.x = element_text(angle=20),\n        legend.position = \"bottom\",\n        plot.title = element_text(size=16,vjust=-0.5),\n        panel.grid.major.x = element_blank())\n\nage_sex_plot\n\nComposition of plots and background\n\nlibrary(magick)\nlibrary(ggimage)\nlibrary(ggpubr)\nlibrary(cowplot)\nlibrary(extrafont)\nlibrary(showtext)\nfonts()\nolympics_family<-\"Roboto Condensed\"\n#library(ggflags)\nlibrary(countrycode)\n\n\nolympics_plot <- ggplot() +\n  geom_blank() + \n  theme_void() +\n  theme()\n\n\nimg_olympics<-\"olympics.png\"\n\nplot <- ggbackground(age_sex_plot, img_olympics,alpha=.4, color=\"#CD919E\")\n\n\nplot +\n  theme(plot.background = element_rect())#fill=\"#FFEFDB\"))\n\nThen add a secon plot on the right corner"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html#section-medals",
    "href": "tidytuesday/cases2021/posts2021/w31_olympic_medals/w31_olympic_medals.html#section-medals",
    "title": "Olympic Medals",
    "section": "Section medals",
    "text": "Section medals\n“At the 1968 Summer Olympics in Mexico City, 29 events in swimming were contested. There was a total of 468 participants from 51 countries competing. The United States dominated the competition, winning 52 of 87 possible medals. 15-year-old phenom Debbie Meyer from Maryland won three gold medals.”\nsource: Swimming at the 1968 Summer Olympics\n\nmy_olympics_with_country_codes<- my_olympics%>%\n  mutate(country_code = countrycode(region, \n            origin = 'country.name', \n            destination = 'iso2c'),\n         country_code=tolower(country_code)) %>%\n  select(year,sport,medal,country_code) %>%\n  filter(medal==\"Gold\") %>%\n  count(year,sport,country_code) %>%\n  arrange(year) \n  \n\n\nmy_olympics_with_country_codes\n\n\nmy_favourites <- c(\"Athletics\",\"Wrestling\",\"Swimming\",\"Shooting\",\"Rowing\",\n                   \"Boxing\",\"Canoeing\",\"Cycling\")\n\n\nmy_favourite_sports <- my_olympics_with_country_codes%>%\n  filter(sport %in%my_favourites)\n\n\nlibrary(ggflags)\n\n\ntop_golden_sports <- ggplot(data=my_favourite_sports,\n       aes(x=factor(year),y=fct_reorder(sport,-year))) +\n  geom_point(shape = 21, colour = \"gold\", fill = NA, size = 7, stroke = 1) +\n  ggflags::geom_flag(aes(country=country_code), size=4.5) +\n  ggflags::scale_country() +\n  guides(country=\"none\") +\n  labs(title=\"Top 8 Gold medal sport winners\",\n       x=\"\",y=\"\") +\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=90),\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_line(color=\"#CD919E\"),\n        plot.title.position = \"plot\",\n        plot.background = element_blank(),\n        panel.background = element_blank())\n\n# top_golden_sports\n\n\n#png(\"top_golden_sports.png\")\nggsave(\"top_golden_sports.png\", width = 8, height = 6)\n\nprint(top_golden_sports)\ndev.off()\n\n\nlibrary(cowplot)\n\n\nimg <- \"top_golden_sports.png\"\n\ninset.plot <- ggdraw() +\n  draw_image(img,  x = 0.22, y = -0.2,  scale = .70) \n\ninset.plot <- inset.plot + theme(legend.position = \"none\",\n                                    plot.background = element_blank(),\n                                    panel.background = element_blank())\ninset.plot2 <- age_sex_plot + theme(legend.position = \"none\",\n                                    plot.background = element_blank(),\n                                    panel.background = element_blank())\n\ndouble_plot <- ggdraw() +\n  draw_plot(inset.plot2, x = 0, y = 0, width = 1, height = 1) +\n  draw_plot(inset.plot, x = -0.35, y = .18, width = 1.5, height = 0.9) \n\n\ndouble_plot\n\n\nimg_olympics<-\"olympics.png\"\nplot <- ggbackground(double_plot, img_olympics,alpha=.2, color=\"#CD919E\")\n\n\nplot +\n  theme(plot.background = element_rect(fill=\"#FFEFDB\"))\n\n\ngraphics <- ggarrange(plot) \n\nannotation_plot <- annotate_figure(graphics,\n               top = text_grob(\"Olympics outlook 1896 - 2016  \",color =c(\"#FF4040\", \"#FFFFFF\", \"#FFFFFF\"), \n                               face = \"bold\", size = 40,family=olympics_family),\n               bottom = text_grob(\"DataViz: @fgazzelloni DataSource: \\n TidyTuesday week31, Olympic Medals, Kaggle, Financial Times & FiveThirtyEight\",\n                                  color = c(\"black\"),family=olympics_family,\n                                  hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n               left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size=1),\n               right = text_grob(bquote(\"\"), color=c(\"#778899\"),rot = 90,size=1),\n               fig.lab = \"TidyTuesday week31\\n\", fig.lab.face = \"bold.italic\",fig.lab.size=7,\n               fig.lab.pos=\"bottom.right\"\n)\n\nfinal_plot <- annotation_plot +\n  annotate(geom = \"text\", label=\"The historical dataset on the modern Olympic Games,\\n including all the Games from Athens 1896 to Rio 2016\",x = 0.7, y = 0.81, \n           colour = \"black\", size = 6,family=olympics_family) \n  \n\nfinal_plot\n\nAttach the Olympic logo at the sides of the title\n\nimg_olympics<-\"olympics.png\"\n\nfinal <- ggdraw() +\n  draw_image(img_olympics,  x = -0.35, y = 0.45, scale = .10) +\n  draw_image(img_olympics,  x = 0.32, y = 0.45, scale = .10) +\n  draw_plot(final_plot)\n\nSaving:\n\nragg::agg_png(here::here(\"w31\", \"w31_olympics.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w23_survivors/w23_survivors.html",
    "href": "tidytuesday/cases2021/posts2021/w23_survivors/w23_survivors.html",
    "title": "Survivors",
    "section": "",
    "text": "TidyTuesdat Week 23\n\n# Survivor TV Show \n# survivoR Package\n# https://github.com/doehm/survivoR\n\n# http://gradientdescending.com/survivor-data-from-the-tv-series-in-r/\n\n\n# install.packages(\"survivoR\")\n\n\n# source of inspiration: \n# https://github.com/TIvanDijk/TidyTuesday/blob/main/Week%2023/survivors.R\n# https://cran.r-project.org/web/packages/ggtext/vignettes/plotting_text.html\n\nlibrary(survivoR)\n\nlibrary(tidytuesdayR)\ntuesdata <- tidytuesdayR::tt_load(2021, week = 23)\n\nchallenges <- tuesdata$challenges\nhead(challenges);dim(challenges)\nviewers <- tuesdata$viewers\nhead(viewers);dim(viewers)\njury_votes <- tuesdata$jury_votes\ncastaways <- tuesdata$castaways\nsummary <- tuesdata$summary\nhead(summary);dim(summary)\n\n#########################\n\n\nhead(castaways);dim(castaways)\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(extrafont)\nlibrary(patchwork)\nlibrary(ggtext)\nlibrary(forcats)\nlibrary(ggrepel)\nlibrary(showtext)\nlibrary(cowplot)\nlibrary(magick)\n# fonts()\n\nfont_add_google(\"Roboto\", \"roboto\")\nfont_add_google(\"Roboto Condensed\", \"roboto condensed\")\n\n\n##############################################\n\nlabels <-\n  tibble(\n    labels = c(\n      \"**The 4 Cognitive Functions dealing with '*How Processing Information*'**\",\n      \"Extroverted Sensing = ESTP, ESFP, ISTP, and ISFP                   \",\n      \"Introverted Sensing = ISTJ, ISFJ, ESTJ, and ESFJ                   \",\n      \"Extroverted Intuition = ENTP, ENFP, INTP, and INFP                 \",\n      \"Introverted Intuition = INTJ, INFJ, ENTJ, and ENFJ                 \"\n      ),\n    x = rep(3.5, 5),\n    y = c(0.8,0.7,0.6,0.5,0.4)#rep(1, 5)\n    )\n\npersonality_codes <-ggplot(labels, aes(x, y)) +\n  annotate(\"text\", x = 3, y = 1.45,\n           label = \"Survivor personality code explained\",\n           size = 14,color=\"#A91727\",\n           fontface = \"bold\",\n           family =  \"Roboto Condensed\" ) +\n  geom_text(aes(x=2.8,y=1,family= \"Roboto Condensed\" ),\n            label=\"The Myers-Briggs Personality Type Indicator is a personality classification system that breaks personalities into 16 different categories. \\nEach personality type has specific preferences in how they 1.) perceive the world and how they 2.) make decisions\",\n            color = 'black', size = 4,face=\"bold\")+\n  geom_richtext(aes(label = labels,family= \"Roboto Condensed\"),\n                label.color = NA,\n                vjust = 0.8,hjust=0.2,color=\"#A91727\",size=4,fill=NA) +\n  annotate(geom = \"curve\", x = 1.8, y = 0.6, xend = 2.5, yend = 0.75, curvature = -.2, arrow = arrow(length = unit(2, \"mm\")))+\n  annotate(geom = \"rect\",xmin=0.2,ymin=0.35,xmax =1.8 ,ymax =0.81, color=\"#FEED01\",fill=\"#FEED01\")+\n  annotate(geom = \"text\",x=1,y=0.6,\n           label=\"Each personality type has four cognitive functions:\\n1. dominant\\n2. auxiliary or secondary\\n3. tertiary\\n4. inferior or least developed\",\n           size = 3,color=\"black\",\n           family =  \"Roboto Condensed\")+\n  annotate(\"text\",x=1,y=0.25,\n           label=\"Each of the 16 personality types will have a unique combination of 4 out of 8 cognitive functions\",\n           size = 3,color=\"black\",\n           family =  \"Roboto Condensed\")+\n  scale_x_continuous(limits = c(0, 6.1)) +\n  scale_y_continuous(limits =  c(0.2, 1.5)) +\n  labs(title=\"Survivor (American TV series)\")+\n  theme_void()+\n  theme(plot.title = element_text(hjust=1,vjust=-0.5,face=\"bold\",family = \"Roboto Condensed\"),\n        plot.background = element_rect(fill = \"#EFCC24\"),\n        panel.border = element_blank(),\n        plot.margin = unit(c(1,1,0,1), \"cm\"))\n\n\npersonality_plot <- castaways%>%\n  group_by(personality_type)%>%\n  summarize(avg_age=mean(age),n=n())%>%\n  ungroup()%>%\n  arrange(desc(n))%>%\n  drop_na()%>%\n  ggplot(aes(x=reorder(round(avg_age),avg_age),y=n,\n             color=personality_type,fill=personality_type))+\n  geom_col()+\n  geom_label(aes(y=n,label=paste(personality_type),fill=personality_type),\n            #direction = \"y\",\n            color=\"white\",\n            position= position_stack(vjust=0.5))+\n  scale_fill_survivor(12)+\n  scale_colour_survivor(12)+#8\n  labs(title=\"Personality type by Age group\",\n       x=\"Survivor's Age\",y=\"Group(n)\",\n       fill=\"Personality Type\",color=\"\",\n       caption = \"Viz @fgazzelloni Source: TidyTuesday week 23 & Survivor TV Show, more info @Daniel's Oehm's Website\")+\n  guides(color=FALSE)+\n theme_base()+\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(fill=\"#EFCC24\"),\n    plot.title = element_text(color=\"#784937\",family=\"Roboto Condensed\"),\n    plot.caption = element_text(color=\"#784937\",family=\"Roboto Condensed\",size=9,face=\"bold\"),\n    panel.background = element_blank(),\n    panel.border = element_blank(),\n    axis.line = element_line(),\n    axis.title = element_text(family=\"Roboto Condensed\"))\n\n\n\np<-personality_codes / personality_plot\n\n\nimg <- image_read(\"hex-torch.png\")\n\n# Set the canvas where you are going to draw the plot and the image\nfinal <-ggdraw() +\n  # Draw the plot in the canvas setting the x and y positions, which go from 0,0\n  # (lower left corner) to 1,1 (upper right corner) and set the width and height of\n  # the plot. It's advisable that x + width = 1 and y + height = 1, to avoid clipping \n  # the plot\n  draw_plot(p,x = 0, y = 0, width = 1, height = 1) +\n  # Draw image in the canvas using the same concept as for the plot. Might need to \n  # play with the x, y, width and height values to obtain the desired result\n  draw_image(img,x = -0.85, y = 0.8, width = 1.85, height = 0.2)\n\n\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w23\",\"w23_survivor.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"w23_survivor.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"w23_survivor.png\",\n            format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w30_drought/w30_drought.html",
    "href": "tidytuesday/cases2021/posts2021/w30_drought/w30_drought.html",
    "title": "US drought",
    "section": "",
    "text": "library(tidyverse)\n\nResources for this week:\n\nrfordatascience\nComprehensiveStatistics\nNYT\nCNN\nDrought Classification\ndrought Monitor\n\nFacts 2001 to 2021:\n\nSix states are now entirely in drought conditions\nThe drought has nearly doubled in size from this time last year\nAround 25% of the country was in drought conditions in July 2020\nMore than 94% of the West is in drought\nMore than 60% of the region is in ‘extreme’ or ‘exceptional’ drought\nSix states completely in drought conditions; California, Oregon, Nevada, Utah, Idaho and North Dakota\n\nData limitations:\n\nstatistics are limited to areas based on counties\npopulation changes over time\npopulation is distributed evenly across each county\nlimitation\n\nCaption: The U.S. Drought Monitor is jointly produced by the National Drought Mitigation Center at the University of Nebraska-Lincoln, the United States Department of Agriculture, and the National Oceanic and Atmospheric Administration. Map courtesy of NDMC.\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 30)\n\ndrought <- tuesdata$drought\n\n\nglimpse(drought)\n\n\ndrought%>%count(drought_lvl)\n\nIntensity and Impacts\n\nintensity_impacts<- c(\"D0\"=\"Abnormally Dry\",\n                      \"D1\"=\"Moderate Drought\",\n                      \"D2\"=\"Severe Drought\",\n                      \"D3\"= \"Extreme Drought\",\n                      \"D4\"=\"Exceptional Drought\")\n\n\nDataExplorer::profile_missing(drought)\n\n\ndrought_short <- drought %>%\n  dplyr::select(-map_date,-stat_fmt) %>%\n  filter(!drought_lvl==\"None\",!area_pct==0)\n\ndrought_short\n\n\nlibrary(sf)\nlibrary(raster)\nlibrary(spData)\nlibrary(spDataLarge)\n\nlibrary(maps)\nlibrary(viridis)\nlibrary(ggthemes)\n\n\nus_county_map <- map_data(\"county\")\n\ncounty_plot<-ggplot()+\n  geom_polygon(data=us_county_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\") +\n  theme_map()\n\ncounty_plot\n\n\nmy_states <- drought_short%>%count(state_abb)\n\n\nus_state_map <- map_data(\"state\")\n\nstate_plot<-ggplot()+\n  geom_polygon(data=us_state_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\") +\n  theme_map()\n\nstate_plot\n\n\nus_plot<-ggplot()+\n  geom_polygon(data=us_county_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\") +\n   geom_polygon(data=us_state_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"pink\") +\n  theme_map()\n\nus_plot\n\n\nlibrary(zipcodeR)\nzipcodeR::download_zip_data()\n\ngeo_codes<- zipcodeR::search_state(drought_short$state_abb)%>%\n  dplyr::select(major_city,county,state,lat,lng,\n         population,population_density,\n         land_area_in_sqmi,water_area_in_sqmi,\n         housing_units,occupied_housing_units,\n         median_home_value,median_household_income) %>%\n  drop_na()\n\ngeo_codes\n\n\nmy_geo_codes_df<-geo_codes%>%\n  dplyr::select(state,lat,lng)\n  \n\ndrought_short_map <- drought_short %>%\n  arrange(valid_start)%>%\n  mutate(year=lubridate::year(valid_start),\n         month=lubridate::month(valid_start))%>%\n  filter(str_detect(valid_start,\"2021\")) %>%\n  #filter(month==c(1,2,3)) %>%\n  group_by(month,state_abb,drought_lvl) %>%\n  summarize(med_area_pct=round(median(area_pct),2))%>%\n  ungroup() %>%\n  filter(!med_area_pct==0) %>%\n  left_join(my_geo_codes_df,by=c(\"state_abb\"=\"state\")) %>%\n  mutate(month = month.name[month])\n  \ndrought_short_map\n\n\nlibrary(extrafont)\nloadfonts()\nfonts()\n\ndroughts_family <- \"Roboto Condensed\"\n\n\ndrought_plot <- ggplot() +\n  geom_point(data=subset(drought_short_map,lat>25&lat<50),\n                         aes(x=lng,y=lat,color=drought_lvl),\n             alpha=0.5,size=.4) +\n  geom_polygon(data=us_county_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\",size=0.2) +\n   geom_polygon(data=us_state_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"pink\",size=0.4) +\n  facet_wrap(~factor(month, levels=c('January','February','March','April',\n                                     'May','June','July'))) +\n  labs(title=\"\",\n       subtitle=\"\",\n       caption=\"US Droughts map: available values by County\\n Jan to July 2021\",\n       #tag = \"Jan to July 2021\",\n       color=\"Level\") +\n  scale_color_viridis(labels = intensity_impacts,discrete = TRUE) +\n  guides(color = guide_legend(override.aes = list(size = 3))) +\n  ggthemes::theme_map() +\n  theme(legend.position = \"top\",\n        legend.title = element_text(family = droughts_family),\n        legend.text = element_text(size=8,family =droughts_family),\n        legend.background = element_blank(),\n        legend.box.background = element_blank(),\n        legend.key = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_text(family = droughts_family),\n        plot.title =element_text(size=15,face=\"bold\",family =droughts_family,color=\"black\"),\n        plot.subtitle =element_text(size=12,face=\"bold\",family =droughts_family),\n        plot.caption =element_text(size=9,family =droughts_family,hjust = 0),\n        #plot.tag = element_text(size=9,face=\"bold\",family =droughts_family,hjust = 0),\n        plot.caption.position = \"panel\",\n        plot.title.position = \"panel\")\n  \n\n\n# drought_plot \n\n\nlibrary(tidymodels)\ntidymodels_prefer()\n\n\ncooked_drought <- recipe(drought_lvl ~ med_area_pct+month + lat+lng +state_abb,drought_short_map) %>%\n  prep()%>%\n  bake(new_data=NULL)\n\ncooked_drought\n\n\ncooked_drought_plot <- cooked_drought%>%\n  group_by(drought_lvl,month) %>%\n  summarise(med_med_area_pct=median(med_area_pct)) %>%\n  mutate(month_f= case_when(month==\"January\"~1,\n                            month==\"February\"~2,\n                            month==\"March\"~3,\n                            month==\"April\"~4,\n                            month==\"May\"~5,\n                            month==\"June\"~6,\n                            month==\"July\"~7)) %>%\n\n  ggplot(aes(x=month_f,y=med_med_area_pct,fill=month)) +\n  geom_col()+\n  geom_text(aes(label=month),nudge_y = 1.5,size=1.5,family = droughts_family) +\n  geom_text(aes(label=med_med_area_pct),nudge_y = -1.5,size=1.5,color=\"white\") +\n  facet_wrap(~factor(drought_lvl,labels = intensity_impacts),\n             nrow = 1,ncol = 5,strip.position=\"bottom\",\n             scales = \"fixed\")+\n  scale_fill_viridis(discrete = TRUE) +\n  labs(y=\"\",\n       caption=\"Forecasted Droughts affected area pct median value by first 7 months of the year\")+\n  theme_void()+\n  theme(legend.position = \"none\",\n        plot.caption = element_text(family = droughts_family),\n        axis.text.x = element_blank(),\n        axis.ticks = element_blank(),\n        strip.placement = \"inside\",\n        strip.text = element_text(family = droughts_family,size=6),\n        plot.background = element_blank())\n\n\n  \n# cooked_drought_plot\n\n\nlibrary(cowplot)\n\n\ninset.plot <- cooked_drought_plot + theme(legend.position = \"none\")\n\ndouble_plot <- ggdraw() +\n  draw_plot(drought_plot,width = 1, height = 1) +\n  draw_plot(inset.plot, x = 0.39, y = .035, width = .55, height = .25)\n\n# double_plot\n\n\nlibrary(ggpubr)\nlibrary(ggimage)\n\n\ngraphics <- ggarrange(double_plot) \n\nannotation_plot <- annotate_figure(graphics,\n               top = text_grob(\"US droughts monitor condition outlook: \",color =c(\"#36648B\", \"#607B8B\", \"#668B8B\"), \n                               face = \"bold\", size = 30,family=droughts_family),\n               bottom = text_grob(\"DataViz: @fgazzelloni DataSource: \\n TidyTuesday week30, US Droughts,Drought Monitor,NYTimes & CNN\",\n                                  color = c(\"#36648B\", \"#607B8B\", \"#668B8B\"),family=droughts_family,\n                                  hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n               left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size=1),\n               right = text_grob(bquote(\"\"), color=c(\"#778899\"),rot = 90,size=1),\n               fig.lab = \"TidyTuesday week30\\n\", fig.lab.face = \"bold.italic\",fig.lab.size=7,\n               fig.lab.pos=\"bottom.right\"\n)\n\nfinal_plot <- annotation_plot +\n  annotate(geom = \"text\", label=\"map approximates drought-related impacts\",x = 0.7, y = 0.87, \n           colour = \"#BF3EFF\", size = 8,family=droughts_family) \n  \n\n# final_plot\n\n\nimg <- png::readPNG('NDMC-logo-usdm-opt.png')\nimg1 <- png::readPNG('DOC-logo-usdm.png')\nimg2 <- png::readPNG('NOAA-logo-usdm.png')\nimg3 <- png::readPNG('USDA-logo-usdm-opt.png')\n\n\nfinal <- ggdraw() +\n  draw_image(img,  x = -0.45, y = 0.44, scale = .10) +\n  draw_image(img1,  x = -0.38, y = 0.44, scale = .10) +\n  draw_image(img2,  x = 0.33, y = 0.44, scale = .10) +\n  draw_image(img3,  x = 0.42, y = 0.44, scale = .10) +\n  draw_plot(final_plot)\n\n# final\n\nSaving:\n\nragg::agg_png(here::here(\"w30\", \"w30_drought.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w26_public_park_access/w26_public_park_access.html",
    "href": "tidytuesday/cases2021/posts2021/w26_public_park_access/w26_public_park_access.html",
    "title": "US Public Parks",
    "section": "",
    "text": "Week 26 Public Parks\n\n\npoints for 14 measures across five categories: acreage, investment, amenities, access, and equity.\n\n\nOUTLIERS\n\n\nPARK INCLUSION CRITERIA\n\n# load libraries --------------\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(tidymodels)\ntidymodels_prefer()\n\nlibrary(forcats)\n\nlibrary(DataExplorer)\nlibrary(ggthemes)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(extrafont)\n\nlibrary(showtext)\n#font_families_google()\nfont_add_google(\"Montserrat\",\"Montserrat\")\nshowtext.auto(enable = TRUE)\n\nlibrary(RColorBrewer)\nlibrary(ggwordcloud)\n\nlibrary(patchwork)\nlibrary(cowplot)\n\n\n# load data ------------------\ntuesdata <- tidytuesdayR::tt_load(2021, week = 26)\n\nparks <- tuesdata$parks\n\n\nhead(parks)\n\n# questions ------------\n\n# - how parks evolved within the years\n# - how many parks have a playground/sports amenities/dogpark/splashgrounds/general amenities/restrooms/benches\n# - has the parks size changed within the years\n# - how has the residents spending evolved\n# - what is the rank by cities\n\n\n# check of the data and tidy manipilation --------------------\nnames(parks)\nstr(parks)\n\nplyr::count(parks$year)\n\n# selecting the columns iwth just points as a measure to have omogeneous data, some of them are\n# on a 50 max scale and other on a 100 max scale, so if I want to used them all I would need to rescale\n# one of the two\n\n  \nminneapolis<-parks%>%\n  filter(city==\"Minneapolis\")\n\nmissing<-profile_missing(minneapolis)\n#View(missing)\nkableExtra::kable(skimr::skim(minneapolis)) %>% kableExtra::scroll_box(width = '100%')\n\nstr(minneapolis)\n\nminneapolis_long<-minneapolis%>%\n  pivot_longer(cols=c(6,8,10),names_to=\"data\",values_to=\"percent\")\n\nminneapolis_long$data2 = factor(minneapolis_long$data, \n                           levels=c(\"spend_per_resident_data\",\"park_pct_city_data\",\"pct_near_park_data\"))\n\nnew_labels=c(\"spend_per_resident_data\"=\"Spending\",\"park_pct_city_data\"=\"Park points\",\"pct_near_park_data\"=\"Neighborhood\")\n\n# first plot ----------------------------\nfirst<-ggplot(data=minneapolis_long,aes(x=year,y=percent,group=data2,colour=data2))+\n  geom_point(aes(size=total_pct))+\n  geom_line()+\n  geom_text(aes(label=percent),stat=\"identity\",vjust=-1.5,show.legend = F,size=2)+\n  guides(colour = FALSE, size = FALSE)+\n  scale_color_viridis(discrete=TRUE)+\n  labs(title=\"\\nPark spending, points, neighborhood\\n\",\n       # subtitle=\"\\n2012 - 2020\\n\",\n       caption=\"\",\n       colour=\"\",\n       # tag=\"The \\nTrust \\nfor \\nPublic \\nLand\",\n       x=seq(2012,2020,1), y=\"\")+\n  facet_wrap(~data2,labeller = labeller(data2=new_labels))+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=90,family=\"Montserrat\"),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_text(color=\"black\",family=\"Montserrat\"),\n        plot.title = element_text(family=\"Montserrat\",hjust = 0.5,size=12),\n        plot.subtitle = element_text(family=\"Montserrat\",hjust = 0.1),\n        # plot.tag = element_text(family=\"Montserrat\",size=10),\n        # plot.tag.position = c(0.05, 0.9),\n        #panel.grid = element_blank(),\n        #panel.grid.major = element_blank(),\n        #panel.grid.minor = element_blank(),\n        plot.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        strip.text.y  = element_text(family=\"Montserrat\"),\n        plot.margin = margin(0,0,0,0,unit=\"pt\"))\n\n\n#####################\n\nsub_minneapolis <- minneapolis%>%\n  filter(year==c(2020,2019,2018))%>%\n  select(city,matches(c(\"year\",\"rank\",\"points\")),-total_points)%>%\n  mutate(med_park_size_points=med_park_size_points/50*100,\n         park_pct_city_points=park_pct_city_points/50*100)%>%\n    group_by(year,rank,amenities_points)%>%\n   mutate(total= rowMeans(across(where(is.numeric))))%>%\n    ungroup()%>%\n  rename(c(\"Basketball\"=\"basketball_points\",\"Dogpark\"=\"dogpark_points\",\n           \"Playground\"=\"playground_points\",\"Recreation and senior centers\"=\"rec_sr_points\",\n           \"Splashground\"=\"splashground_points\",\"Restroom\"=\"restroom_points\"))\n  \n######################  \nmin=1\nmax=100\n\namenities_per_year <-minneapolis%>%\n  filter(year==c(2020,2019,2018))%>%\n  select(city,matches(c(\"year\",\"rank\",\"points\")),-total_points)%>%\n  rename(c(\"Basketball\"=\"basketball_points\",\"Dogpark\"=\"dogpark_points\",\n           \"Playground\"=\"playground_points\",\"Recreation and senior centers\"=\"rec_sr_points\",\n           \"Splashground\"=\"splashground_points\",\"Restroom\"=\"restroom_points\"))%>%\n    janitor::clean_names()%>%\n  mutate(basketball=basketball/10000*10000,\n         dogpark=dogpark/100000*10000,\n         playground=playground/10000*10000,\n         recreation_and_senior_centers=recreation_and_senior_centers/20000*10000,\n         restroom=restroom/100000*10000,\n         splashground=splashground/100000*10000)%>%\n    #select(8:13)%>%\n  pivot_longer(cols=c(8:13),names_to=\"data_points\",values_to=\"points\")%>%\n  select(year,data_points,points,amenities_points)%>%\n  group_by(data_points)%>%\n  mutate(#normalized = ((points-min(points))/(max(points)-min(points)))*100,\n         normalized100 = ((points-min)/(max-min)))%>%ungroup()\n\n\nnormalized_per_year_plot <- ggplot(data=amenities_per_year) +\n  geom_col(aes(x=data_points,y=normalized100,fill=factor(year),color=factor(year))) + \n  scale_color_viridis(discrete=TRUE,option=\"G\")  +\n    guides(color=FALSE)+\n    scale_fill_viridis(discrete=TRUE,option=\"G\") +\n  scale_x_discrete(label=c(\"Basketball\",\"Dogpark\",\"Playground\",\"Recreation\",\"Splashground\",\"Restroom\"))+\n    #annotate(\"text\",label=\"improvements\",x=2019.5,y=700,family=\"Montserrat\")+\n    labs(title=\"Amenities points Normalized100\",\n         #subtitle=\" 2018 - 2020 \",\n         caption=\"\",\n         fill=\"\",\n         color=\"\",\n         tag=\"\")+\n    theme_fivethirtyeight()+\n    theme(axis.ticks.x = element_line(size=2,color=\"red\"),\n          axis.text.x = element_text(family=\"Montserrat\",angle=20,size=5),\n          axis.text.y = element_text(family=\"Montserrat\"),\n          axis.ticks.y = element_blank(),\n          plot.title = element_text(family=\"Montserrat\",size=8),\n          plot.subtitle = element_text(family=\"Montserrat\",vjust=-0.5,hjust=0.3,size=10),\n          plot.caption = element_text(family=\"Montserrat\"),\n          plot.tag = element_text(family=\"Montserrat\",size=10),\n          plot.tag.position = c(0.08, 0.9),\n          plot.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n          panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n          legend.title = element_text(family=\"Montserrat\",hjust=0),\n          legend.background = element_blank(),\n          legend.position = \"top\",\n          legend.key.size = unit(0.3, 'cm'),\n          legend.text = element_text(family=\"Montserrat\",size=8),\n          plot.margin = margin(30,30,30,30,unit=\"pt\"))\n\n##########################   \n\n# sub_minneapolis%>%pivot_longer(cols=c(8:13),names_to=\"data_points\",values_to=\"points\")\n  \n# Level of Minneapolis park feautures  \namenities_per_year_plot <- ggplot(data=amenities_per_year,aes(x=year,y=points)) +\n  geom_col(aes(color=data_points,fill=data_points)) +\n  geom_smooth(aes(y = amenities_points),color=\"red\",method=\"lm\",formula = y ~ splines::bs(x, 5)) +\n  scale_color_viridis(discrete=TRUE)  +\n  guides(color=FALSE)+\n  scale_fill_viridis(discrete=TRUE,label=c(\"Basketball\",\"Dogpark\",\"Playground\",\"Recreation\",\"Splashground\",\"Restroom\")) +\n  labs(title=\"Amenities points by year\",\n       #subtitle=\"three years of points increase\",\n       caption=\"Viz @fgazzelloni DataSource: TidyTuesday week26 Public Park Access,TPL,CityLab\",\n       fill=\"\",\n       color=\"\"\n       #tag=\"Amenities points 2018-2020\"\n       )+\n  theme_fivethirtyeight() +\n  theme(axis.ticks.x = element_line(size=2,color=\"red\"),\n        axis.text.x = element_text(family=\"Montserrat\"),\n        axis.text.y = element_text(family=\"Montserrat\"),\n        axis.ticks.y = element_blank(),\n        plot.title = element_text(family=\"Montserrat\",size=8),\n        plot.subtitle = element_text(family=\"Montserrat\",vjust=-0.5,hjust=0.3,size=10),\n        plot.caption = element_text(family=\"Montserrat\",face=\"bold\"),\n        plot.tag = element_text(family=\"Montserrat\",size=10),\n        plot.tag.position = c(0.08, 0.9),\n        plot.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        legend.title = element_text(family=\"Montserrat\",hjust=0),\n        legend.background = element_blank(),\n        legend.text = element_text(family=\"Montserrat\",size=8),\n        legend.key.size = unit(0.3, 'cm'),\n        legend.position = \"top\",\n        plot.margin = margin(30,30,30,30,unit=\"pt\"))\n  \nsecond <- normalized_per_year_plot | amenities_per_year_plot\n\n\nthird<- ggplot()+\n  geom_blank() +\n  labs(title=\"Minneapolis\")+\n  theme_fivethirtyeight()+\n  theme(plot.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        plot.title = element_text(family=\"Montserrat\",color=\"yellow\"))\n\nfourth <- parks%>%\n  filter(rank<=10)%>%\n  mutate(city=case_when(city==\"Washington, DC\"~\"Washington, D.C.\",\n                                 TRUE~city))%>%\n  count(city)%>%\n  ggplot(aes(label=city,color=city))+\ngeom_text_wordcloud(family=\"Montserrat\") +\n  labs(title=\"Minneapolis ranked the first best 7 times between 2012 - 2020\",\n       tag=\"The \\nTrust \\nfor \\nPublic \\nLand\")+\n  theme_fivethirtyeight()+\n  theme(plot.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n        plot.title = element_text(family=\"Montserrat\",size=12,hjust=0.5),\n        plot.tag = element_text(family=\"Montserrat\",size=10,color=\"white\"),\n        plot.tag.position = c(0.04, 0.9))\n \nlibrary(magick)\nlibrary(ggimage)\n\n\n\nimg = \"minneapolis_park.png\"\nthird<-ggbackground(third, img,alpha=.9)\n\none <-third/first \n\ntwo<-fourth/second\n\nfinal <-one|two\n\nbck_color <- \"#a1d99b\"\n\nfinal <- final + plot_annotation(\n  title = \"\\nMinneapolis Park improvment racing\\n\",\n  subtitle=\"'The Trust for Public Land creates parks and protects land for people, ensuring healthy, livable communities for generations to come' \",\n  theme = theme(\n    plot.margin = margin(10,10,10,10),\n    plot.background = element_rect(fill = bck_color, color = NA),\n    panel.background = element_rect(color=\"#a1d99b\",fill=\"#a1d99b\"),\n    plot.title = element_text(family = \"Montserrat\",vjust=-0.5,face=\"bold\"),\n    plot.subtitle = element_text(family = \"Montserrat\"),\n    plot.caption = element_text(family = \"Montserrat\", size = 9, color = bck_color, \n                                margin = margin(15,0,0,0), hjust = 0.95)\n  )\n)\n\nfinal_plot <- stamp(final,label=\"#TidyTuesday week 26\",color=\"red\",alpha = 1,\n      vjust = 1.8,\n      hjust = 1.2,\n      size = 14,\n      family = \"Montserrat\",\n      fontface = \"bold\",\n      clip = \"on\")\n\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w26\",\"w26_parks.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w22_mario_kart_world/w22_mario_kart_world.html",
    "href": "tidytuesday/cases2021/posts2021/w22_mario_kart_world/w22_mario_kart_world.html",
    "title": "Mario Kart World",
    "section": "",
    "text": "Mario Bross\n\n# https://mkwrs.com/\n# https://www.thegamer.com/mario-kart-64-speedrunner-is-the-first-to-hit-a-190000-trick-breaks-two-world-records-at-once/\n\n\nlibrary(ggcorrplot)\n\n\nlibrary(tidytuesdayR)\nlibrary(rtweet)\nlibrary(DataExplorer)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(viridis)\nlibrary(ggthemes)\nlibrary(extrafont)\nlibrary(hrbrthemes)\nlibrary(ggExtra)\nlibrary(ggtext)\nlibrary(ggrepel)\nlibrary(extrafont)\nlibrary(patchwork)\n# fonts()\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 22)\n\ndrivers <- tuesdata$drivers\nrecords <- tuesdata$records\n\ndriv_players<-plyr::count(drivers$player)\nplayers<-driv_players$x\n\nmy_df <- records%>%\n  arrange(player)%>%\n  filter(player%in%players)%>%\n  mutate(year=year(date))%>%\n  inner_join(drivers,by=c(\"player\",\"year\"))%>%\n  drop_na()\n\nsecond_plot\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\nplot<-ggplot(my_df,aes(x=date,y=records))+\n  geom_point(aes(group=track,color=system_played,size=record_duration),alpha=0.5)+\n  geom_smooth(color=\"purple\")+\n  scale_color_wsj()+\n  labs(title=\"How did the world records develop over time?\",\n       size=\"Record duration(days)\",\n       color=\"System played\")+\n  xlab(\"World record date(Year)\")+\n  ylab(\"Number of world records\")+\n  theme_wsj()+\n  theme(panel.background = element_blank(),\n        plot.background = element_blank(),\n        legend.title = element_text(size=12),\n        legend.background = element_blank(),\n        legend.key = element_rect(fill=NA),\n        legend.text = element_text(size=12,face=\"bold\"),\n        legend.box.margin = margin(6, 6, 6, 6),\n        plot.title.position = \"plot\",\n        plot.title = element_text(hjust=0,vjust=-1,size=28,color=\"darkblue\"),\n        axis.title = element_text(size=18,color=\"darkred\",face=\"bold\"),\n        panel.grid = element_line(color=\"white\"),\n        panel.grid.major.y = element_blank())\n\n\nplot<-ggMarginal(plot,\n           type=\"histogram\",color=\"blue\",xparams = list(bins=40),\n           fill = \"darkred\", yparams = list(bins=30))\n\n\n\nlabels <-\n  tibble(\n    labels = c(\n      \"<img src='super_mario_run_character_artwork.png'\n      +     width='120' /><br><b style='color:#d6182e'> </b><br><i style='color:#d6182e'> </i></b>\"),\n    x = 1:5,\n    y = rep(1, 5)\n    )\n\nlegend <-\n  ggplot(labels, aes(x, y)) +\n  geom_richtext(aes(label = labels),\n                fill = NA,\n                color = NA,\n                vjust = 0.5) +\n  annotate(\"text\", x = 3.5, y = 1.018,\n           label = \"Mario Kart World Records\",\n           size = 20,color=\"red\",\n           fontface = \"bold\",\n           family = \"Courier New\") +\n  scale_x_continuous(limits = c(0.6, 6.1)) +\n  scale_y_continuous(limits =  c(1, 1.02)) +\n  theme_void() +\n  theme(plot.background = element_rect(fill = \"#ebe046\"),\n        plot.margin = unit(c(1,1,0,1), \"cm\"))\n\ncaption <-\n  ggplot(data.frame(x = 1:2, y = 1:10)) +\n  labs(x = NULL, y = NULL,\n       caption = \"Viz @fgazzelloni| Source: Mario Kart World Records | TidyTuesday Week 22\")+\n  theme(line = element_blank(),\n        plot.caption = element_text(size=8, family=\"Courier New\",color=\"#460046\",face=\"bold\"),\n        panel.background = element_rect(fill = \"transparent\"),\n        plot.background = element_rect(fill = \"transparent\",color = \"transparent\"),\n        panel.border = element_rect(color = \"transparent\"),\n        axis.text = element_blank())\n\n\n \n\n###################### SAVING ############################\n\n\n\nfinal <- legend + plot  + caption + \n  plot_layout(ncol = 1,heights = c(0.3, 1, 0))\n\nragg::agg_png(here::here(\"w22\",\"w22_supermario.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"super_mario_w22.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"super_mario_w22.png\",\n            format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w20_us_broadband/w20_us_broadband.html",
    "href": "tidytuesday/cases2021/posts2021/w20_us_broadband/w20_us_broadband.html",
    "title": "US Broadband",
    "section": "",
    "text": "# Week 20 US Broadband\n# source of data:\n# https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-05-11/readme.md\n# https://github.com/microsoft/USBroadbandUsagePercentages\n\n# load libraries ------------------------------------\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(DataExplorer)\n\nlibrary(zipcodeR)\nlibrary(janitor)\nlibrary(stringr)\n\n\n# load data -----------------------------------\ntuesdata <- tidytuesdayR::tt_load(2021, week = 20)\n\nbroadband <- tuesdata$broadband\nbroadband_zipcode <- tuesdata$broadband_zip\n\n#broadband_zipcode<-read.csv(\"https://raw.githubusercontent.com/microsoft/USBroadbandUsagePercentages/master/dataset/broadband_data_zipcode.csv\")\n# contains mean absolute error (MAE), mean signed deviation (MSD)\n\n# check missing data and str------------------------------\nprofile_missing(broadband);head(broadband)\nprofile_missing(broadband_zipcode);head(broadband_zipcode)\n\nstr(broadband);dim(broadband)\nstr(broadband_zipcode);dim(broadband_zipcode)\n\n\n# data wrangling -------------------------------\nnames(broadband)<-make.names(tolower(names(broadband)))\nnames(broadband_zipcode)<-make.names(tolower(names(broadband_zipcode)))\n\nbroadband%>%filter(str_detect(\"-\",broadband$broadband.availability.per.fcc))\nbroadband$broadband.availability.per.fcc[broadband$broadband.availability.per.fcc==\"-\"]<-\"0\"\nbroadband$broadband.availability.per.fcc<-as.double(broadband$broadband.availability.per.fcc)\n\nbroadband%>%arrange(broadband.usage)\nbroadband$broadband.usage[broadband$broadband.usage==\"-\"]<-\"0\"\nbroadband$broadband.usage<-as.double(broadband$broadband.usage)\n\n###########################################################\n\nbroadband <- broadband %>%\n  mutate(county.name=sub(\" County\",\"\",county.name)) %>%\n  separate(county.id,into=c(\"state.id\",\"county.id\"),sep=-3) %>%\n  mutate(county.name = case_when(\n    county.name==\"LaSalle Parish\" ~ \"La Salle Parish\",\n    TRUE~county.name))\n\n# separate the county.id by state and county---------------\n  broadband_zipcode <- broadband_zipcode %>%\n  separate(county.id,into=c(\"state.id\",\"county.id\"),sep=-3)\n\n\n#####################################\n# in broadband_zipcode\n# some postal codes are made of 4 digits, to use \"geocode_zip\"\n# need 5 digits, so add a zero at the begin of the string\n\n# plyr::count(sprintf(\"%05d\", broadband_zipcode$postal.code))\n\nbroadband_zipcode$postal.code<-sprintf(\"%05d\", broadband_zipcode$postal.code)\n\n# broadband%>%filter(str_detect(county.name,\"Bedford\"))\n\n\n##################################################\n# make a unified dataset with broadband, postal codes and geodada------------------------------\nmy_df <- broadband%>%\n  full_join(broadband_zipcode, by= c(\"st\",\"state.id\",\"county.id\"))%>%\n  select(1,2,3,7,8,5,6,9:12) %>%\n  drop_na()\n\n\nnames(my_df)<-c(\"st\",\"state.id\",\"county.id\",\"county.name\",\"postal.code\",\"brd.available\",\"usage.1119\",\"usage.1020\",\"mae\",\"alpha\",\"msd\")\n\nhead(my_df);dim(my_df)\n\n\n#########################################\n# check of the counties in the data sets ----------\nc$county.name.x[!c$county.name.x%in%d$county.name.y]\nd$county.name.y[!d$county.name.y%in%c$county.name.x]\n\nss<-broadband%>%\n  full_join(broadband_zipcode, by= c(\"st\",\"state.id\",\"county.id\")) %>%\n  filter(county.name.x %in% c(\"Bedford city\",\n                              \"Covington city\",\n                              \"Emporia city\",\n                              \"Fairfax city\",\n                              \"Kusilvak Census Area\",\n                              \"Lexington city\",\n                              \"Manassas Park city\",\n                              \"Martinsville city\",\n                              \"Oglala\",\n                              \"Otter Tail\")) %>%\n  group_by(st,state.id,county.id) %>%\n  summarize(unique(county.name.x),unique(county.name.y),unique(postal.code))\n####################################\n\n\n# make a new column with y/n broadband in the county\nmy_df <- my_df %>%\n  mutate(broadband.id=ifelse(brd.available==0,\"no\",\"yes\"))\n\n\n# find the geocodes with postal codes -------------------\ngeocode_zip<-geocode_zip(my_df$postal.code)\n\n\n# add the geocodes------------------------------\ns<-my_df%>%\n  inner_join(geocode_zip,by=c(\"postal.code\"=\"zipcode\"))%>%\n  unite(\"id\",state.id:county.id,sep= \"\")\n\n\n# load the libraries for plotting ---------------------\nlibrary(sf)\nlibrary(raster)\nlibrary(spData)\nlibrary(spDataLarge)\n\nlibrary(maps)\nlibrary(viridis)\nlibrary(ggthemes)\nlibrary(RColorBrewer)\n\n# add font to mac---\nlibrary(showtext)\nlibrary(extrafont)\n#font_import(pattern=\"world of water\")\nloadfonts()\nfonts()\n\n# mapping --------------------------------\n\nmypalette<-display.brewer.pal(7,\"BrBG\")\nus_county_map <- map_data(\"county\")\n\nfinal_plot<-ggplot()+\n  geom_polygon(data=us_county_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\")+\n  geom_point(data=subset(s,lat>25&lat<50),\n             aes(x=lng,y=lat, group =st,color=brd.available),\n             alpha=0.3,size=0.5)+\n  scale_color_viridis(labels = scales::percent)+\n  labs(title=\"America's Broadband\",\n       subtitle=\"available values by County\",\n       caption=\"Viz. Federica Gazzelloni | US Broadband,Microsoft GitHub,The Verge | TidyTuesday week20\",\n       color=\"\")+\n  theme_map()+\n  theme(plot.title =element_text(size=40,face=\"bold\",family =\"Courier New\",color=\"black\"),\n        plot.subtitle =element_text(size=25,face=\"bold\",family =\"Courier New\"),\n        plot.caption =element_text(size=9,face=\"bold\",family =\"Courier New\"),\n        plot.title.position = \"panel\",\n        plot.margin = margin(5,5,5,5),\n        legend.text = element_text(size=8,family =\"Courier New\"))\n\n\n################################################################################\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"tidytuesday_Broadband.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################ \nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"tidytuesday_Broadband.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_Broadband.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w43_big_pumpkins/w43_big_pumpkins.html",
    "href": "tidytuesday/cases2021/posts2021/w43_big_pumpkins/w43_big_pumpkins.html",
    "title": "Big Pumpkins",
    "section": "",
    "text": "final week 43 Pumpkins\nrm(list=ls())\n\n# Libraries-----\nlibrary(tidyverse)\nlibrary(extrafont)\nlibrary(showtext)\nshowtext_opts(dpi = 320)\nshowtext_auto(enable=T)\nfont_add_google(\"Eater\",\"Eater\")\n\n\n# Data-----\npumpkins <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-19/pumpkins.csv')\n\n\n# Data wrangling-------\ndf <- pumpkins%>% #\n  filter(!str_detect(state_prov,\"Entries\")) %>%\n  filter(!country==\"Unknown country\") %>%\n  separate(id,into=c(\"year\",\"type\")) %>%\n  mutate(#place=as.integer(place),\n    year=as.integer(year),\n    pct_chart=as.double(pct_chart))%>%\n  mutate(type = factor(type,labels=c(\"F\"=\"Field Pumpkins\",\n                                     \"L\"=\"Long Gourds\",\n                                     \"P\"=\"Pumpkins\",\n                                     \"S\"=\"Squash\",\n                                     \"T\"=\"Tomato\",\n                                     \"W\"=\"Watermelon\"))) %>%\n  count(place,year,type,country,weight_lbs,ott,est_weight,pct_chart,sort=T) %>%\n  mutate(weight_lbs=as.factor(weight_lbs),\n         weight_lbs=as.double(weight_lbs),\n         est_weight=as.factor(est_weight),\n         est_weight=as.double(est_weight),\n         ott=as.factor(ott),\n         ott=as.numeric(ott)) %>%\n  filter(!ott==0) %>%\n  mutate(pct_weight=round(sum(weight_lbs),2),\n         pct_weight=round(weight_lbs/pct_weight*100,2),\n         .after=pct_chart) %>%\n  # I added this new information, so I need to re-run all the models\n  mutate(base=median(weight_lbs[year==2013]),\n         w_ratio=weight_lbs/base) %>% #head\n  arrange(year) %>%\n  select(-n,-base) # %>%count(year,w_ratio)\n\n\n# Set the df for plotting\nmed_ratios <- df%>%\n  filter(type==\"Pumpkins\")%>%\n  filter(year%in%c(\"2013\",\"2020\"))%>%\n  arrange(w_ratio) %>%\n  filter(!country%in%c(\"The Netherlands\",\"Spain\",\"Belgium\",\"Poland\",\"Portugal\"))%>%\n  group_by(country,year) %>%\n  summarize(median_w_ratio=round(median(w_ratio),2))%>%\n  ungroup()%>%\n  pivot_wider(names_from=year,values_from=median_w_ratio)%>%\n  arrange(2013,2020)\n\n# find the values for the secondary axis\nmy_y_axis <- df %>%\n  left_join(med_ratios,by=\"country\")%>%\n  mutate(country_ratio_13=paste0(`2013`,\"-\",country),\n         country_ratio_20=paste0(country,\"-\",`2020`),\n                                 .after=\"country\") \n\nmy_sec_y_axis <- c(\"Italy-0.78\",\"United Kingdom-0.97\",\n                   \"Germany-0.99\",\"United States-0.84\",\n                   \"Finland-0.96\",\"Japan-1.17\",\n                   \"Austria-0.96\",\"Canada-0.87\",\n                   \"Slovenia-1.21\",\"Switzerland-1.42\",\"France-1.13\")\n\nmy_sec_y_axis<- as.factor(my_sec_y_axis)\nmy_sec_y_axis <- rev(my_sec_y_axis)\n\n\n\n# violin plot\nfinal <- my_y_axis%>%\n  filter(type==\"Pumpkins\")%>%\n  filter(year%in%c(\"2013\",\"2020\"))%>%\n  arrange(w_ratio) %>%\n  filter(!country%in%c(\"The Netherlands\",\"Spain\",\"Belgium\",\"Poland\",\"Portugal\"))%>%\n  ggplot(aes(x=(w_ratio),y=fct_reorder(country_ratio_13,-(w_ratio)),group=country)) +\n  geom_jitter(shape=\".\",color=\"gold\")+\n  geom_violin(fill= \"darkorange\", color=\"darkgreen\",alpha=0.8,size=0.3)+\n  geom_boxplot(width=0.1,outlier.colour = NA,fill=\"sandybrown\",color=NA)+\n  scale_color_manual(values=c(\"green\",\"pink\"))+\n  scale_x_discrete(expand = expansion(mult = c(0, .1)))+\n  facet_wrap(~year)+\n  # from: https://cran.r-project.org/web/packages/ggh4x/vignettes/PositionGuides.html\n  guides(y = guide_axis_manual( label_size = c(12, 8)),\n    y.sec = guide_axis_manual(labels = my_sec_y_axis, label_size = c(12,8)))+\n  #label_colour = c(\"gold\", \"blue\")\n  labs(title=\"Pumpkins variability weights\",\n       subtitle=\"on selected countries 2013-2020\",\n       x=\"Ratios (Base 2013)\",y=\"Selected Countries\")+\n  theme(axis.text.x = element_text(angle=0))+\n  ggthemes::theme_solarized() +\n  theme(text = element_text(family=\"Eater\"),\n        strip.background = element_blank(),\n        strip.text = element_text(color=\"gold\",face=\"bold\",size=16),\n        plot.background = element_rect(fill=\"grey33\",color=\"grey33\"),\n        plot.title = element_text(color=\"gold\",face=\"bold\",size=34),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_text(color=\"springgreen4\"),\n        panel.background = element_rect(fill=\"grey33\",color=\"grey33\"),\n        axis.text.y = element_text(color=\"gold\",face=\"bold\"),\n        axis.title.y = element_blank(),\n        axis.title.x = element_text(color=\"gold\",face=\"bold\",family=\"Eater\",hjust=0.5),\n        axis.line.x = element_blank(),\n        axis.text.x = element_text(color=\"gold\",face=\"bold\",size=8),\n        axis.ticks.x = element_line(color=\"gold\",size=2),\n        plot.margin = margin(0.5,1,1.2,1,\"cm\"),\n        panel.spacing=unit(0, \"lines\"))\n\n\n# frame the plot\nlibrary(ggpubr)\ngraphics <- ggarrange(final)\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"\",\n                                              color = c(\"grey28\"), face = \"bold\", size = 3,\n                                              family = \"Eater\"),\n                              left = text_grob(\" \",\n                                               color = c(\"grey28\"), face = \"bold\", size = 5,\n                                               family = \"Eater\"),\n                              right = text_grob(\" \",\n                                                color = c(\"grey28\"), face = \"bold\", size = 10,\n                                                family = \"Eater\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: BigPumpkins - GPW - TidyTuesday week43\\n\",\n                                                 color = \"grey28\",family = \"Eater\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 13)\n)\n\n#source: BigPumpkins.com    Great Pumpkin Commonwealth\n\n# add annotations\nfinal_plot <- final_plot +\n  annotate(geom = \"text\", label = \"talking about Pumpkins\",\n           x = 0.75, y = 0.1,colour = \"gold\",size = 6,\n           family = \"Eater\",fontface = \"bold\") +\n  annotate(geom = \"text\", label = \"88% median value\",\n           x = 0.5, y = 0.85,colour = \"gold\",size = 6,\n           family = \"Eater\",fontface = \"bold\") +\n  annotate(geom = \"curve\",curvature=-0.2,\n           x = 0.6, xend=0.4, y = 0.7,yend=0.8,\n           colour = \"gold\",size = 1,\n           arrow=arrow(length=unit(0.03,\"npc\")))+\n  annotate(geom = \"text\", label = \"decreased in variability\",\n           x = 0.7, y = 0.7,colour = \"gold\",size = 3,\n           family = \"Eater\",fontface = \"bold\")\n\n\n\nlibrary(cowplot)\nlibrary(ggimage)\nlibrary(magick)\n\n# add the images for the legend keys\nimgpump <- image_read(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w43/GPCMedium512.png\")\nimgtt <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>% image_resize(\"300x300\")\n\n\n# ggdraw from {cowplot} draw the plot for setting the background colors of the side annotations\nfinal <- cowplot::ggdraw(final_plot) +\n  draw_image(imgtt, x = 0.8, y = 0.4,width = 0.15) +\n  draw_image(imgpump, x = 0.9, y = -0.45,width = 0.06) +\n  theme(plot.background = element_rect(fill = \"orange\",color = \"gold\"))\n\n\n\n\n# save final plot\nragg::agg_png(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w43/pumpkins.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w49_world_cup_cricket/w49_world_cup_cricket.html",
    "href": "tidytuesday/cases2021/posts2021/w49_world_cup_cricket/w49_world_cup_cricket.html",
    "title": "World Cup Cricket",
    "section": "",
    "text": "TidyTuesday week49 Cricket author: Federica Gazzelloni\n\nrm(list=ls())\n# libraries----------\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(extrafont)\nloadfonts()\nlibrary(xkcd)\n\nmatches <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-11-30/matches.csv')\n\n# matches%>%View\n\n# data wrangling------------\n# 113 ground, 109 ground_city, 21 ground_country\nmatches <- matches%>% # count(ground,ground_city,ground_country)%>%View\n  mutate(date=lubridate::mdy(match_date))%>%\n  filter(!date==is.na(date)) %>% \n  mutate(points=ifelse(winner==team1,score_team1,score_team2),\n         year=lubridate::year(date))\n\n# exploratory data analysis----------\n# points plot\npoints_yr<-matches %>% # count(date,winner)\n  ggplot(aes(x=(date),y=points))+\n  geom_point(aes(color=factor(year)),show.legend = F,shape=\".\")+\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\")+\n  geom_smooth(size=0.2)+\n  theme_xkcd()+\n  labs(x=\"Years\",y=\"Points rating\",\n       title=\"Points by Years\",\n       caption = \"Observed Values\")+\n  theme(text = element_text(size=12),\n        panel.grid.minor.x = element_line(size=6,color=\"darkseagreen3\"),\n        plot.background = element_blank(),\n        panel.background = element_blank(),\n        plot.title = element_text(size=14),\n        axis.line = element_line(),\n        axis.text.x = element_text(size=7,angle = 15))\n\n# time series | for extra plots------------\n# model sesonality \npr_df<- matches%>%select(ds=date,y=points)\nlibrary(prophet)\nm <-prophet(pr_df)\nfuture <- prophet::make_future_dataframe(m, periods=365)\nforecast <- predict(m,future)\n# tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])\n\nforecast%>%\n  mutate(ds=as.Date(ds,\"%Y-%m-%d\"))%>%\n  ggplot(aes(ds,yhat))+\n  geom_point(data=pr_df,aes(x=ds,y=y),size=0.05)+ # original data\n  geom_line(aes(x=ds,y=yhat_upper),size=0.03)+\n  geom_line(aes(x=ds,y=yhat_lower),size=0.03)+\n  geom_line(col=\"violet\",size=0.5)+\n  geom_smooth()\n\nprophet_plot_components(m, forecast)\n\n# week_trend plot\nweek_trend<- forecast%>%\n  mutate(day=lubridate::wday(ds,label = T,abbr = T,\n                             week_start = getOption(\"lubridate.week.start\", 7),\n                             locale = Sys.getlocale(\"LC_TIME\")),\n         .after=ds) %>%\n  select(ds,day,weekly,yearly,trend) %>%\n  \n  ggplot(aes(x=day,y=weekly,group = 1))+\n  geom_line(color=\"black\")+\n  theme_xkcd()+\n  labs(x=\"Weekdays\",y=\"Points rating\",\n       title=\"Days of the week with higher points\",\n       caption = \"Prophet Time Series\")+\n  theme(text = element_text(size=12),\n        plot.background = element_blank(),\n        plot.title = element_text(size=14),\n        axis.line = element_line(),\n        axis.text.x = element_text(size=8))\n\n\n# flags----------\n# add country code\nlibrary(ggflags)\nlibrary(countrycode)\n#countrycode::codelist_panel%>%View\ncountrycode::codelist%>%filter(str_detect(country.name.en,\"United\"))\n# countrycode::countrycode(matches)\nlibrary(maps)\n\nmatches%>%\n  select(date,year,winner,points,ground,ground_city,ground_country,match_date)%>%\n  mutate(country_code = countrycode(ground_country, \n                                    origin = 'country.name', \n                                    destination = 'iso2c'),\n         country_code=tolower(country_code))\n\n# not matched unambiguously England, Midlothian, Wales, West Indies\n# England, Midlothian, Wales == United Kingdom\n# West Indies ?\nambiguous_values <- matches%>%\n  select(ground,ground_city,ground_country)%>%\n  filter(ground_country==\"West Indies\")%>%\n  count(ground,ground_city,ground_country)\n\nmy_missing_cities<- ambiguous_values%>%\n  pull(ground_city)%>%\n  unlist()\n\n\nflags_df <- matches%>% #count(ground_country)\n  select(date,year,winner,points,ground,ground_city,ground_country,match_date)%>%\n  mutate(country=case_when(ground_country==\"England\"~\"United Kingdom\",\n                                  ground_country==\"Midlothian\"~\"United Kingdom\",\n                                  ground_country==\"Wales\"~\"United Kingdom\",\n                                  TRUE~ground_country))%>%\n  mutate(country=case_when(ground_city==\"Bridgetown\"~\"Barbados\",\n                           ground_city==\"Gros Islet\"~\"Saint Lucia\",\n                           ground_city==\"Kingston\"~\"Jamaica\",\n                           ground_city==\"Port of Spain\"~\"Trinidad and Tobago\",\n                           ground_city==\"Arnos Vale\"~\"Saint Vincent e Grenadine\",\n                           ground_city==\"St John's\"~\"Antigua e Barbuda\",\n                           TRUE~country))%>%\n  mutate(country_code = countrycode(country, \n                                    origin = 'country.name', \n                                    destination = 'iso2c'),\n         country_code=tolower(country_code),.after=winner)\n\n\n# ground country winners dataset--------\nworld1_geo<- rnaturalearth::ne_countries(scale=110,\n                                         returnclass = \"sf\")\n\n\nworld1_geo <- world1_geo%>%filter(!name==c(\"Antarctica\",\"Fr. S. Antarctic Lands\"))\n\npolygon_df <- matches%>%\n  left_join(world1_geo,by=c(\"ground_country\"=\"name\"))%>%\n  select(date,year,points,winner,ground_country,geometry)\n\n# centroids and coords with spData::world-----\nworld2_geo<- spData::world\nworld2_ctr<- st_centroid(world2_geo)\nworld2_ctr_coords<- st_coordinates(world2_ctr)%>%\n  as.data.frame()\n\ncountries <- matches$ground_country\n\nworld2_ctr_coords_my_countries<-cbind(world2_ctr_coords,ground_country=world2_geo$name_long)%>%\n  filter(ground_country%in%countries)%>%\n  left_join(polygon_df%>%select(year,ground_country,winner,points),by=\"ground_country\")\n\n# flags data sets\nflags_df_coords<- flags_df%>%\n  inner_join(world2_ctr_coords_my_countries,by=c(\"ground_country\",\"year\",\"winner\",\"points\"))\n\n# this set will be used\nflags_df_coords2<- flags_df_coords%>%count(country_code,X,Y)\n\n\n\n# map plot----------------\n  # world polygons\nmap_plot <- ggplot(world2_ctr_coords_my_countries)+\n  geom_sf(data=world1_geo,\n          aes(geometry=geometry),\n          fill=\"#f0ebc7\",size=0.2) +\n  # my polygons\n  geom_sf(data=polygon_df,\n          aes(geometry=geometry),color=\"red\",\n          fill=\"#d9ed53\",\n          show.legend = F) +\n  # polygons centroids\n  geom_point(data=world2_ctr_coords,\n             aes(x=X,y=Y),shape=\".\") +\n  # my polygons centroids\n  geom_point(data=world2_ctr_coords_my_countries,\n             aes(x=X,y=Y),size=0.3,color=\"red\") +\n  # my country names\n  geom_text(data=world2_ctr_coords_my_countries%>%  #count(ground_country)\n             filter(!ground_country%in%c(\"Ireland\",\n                                      \"United Arab Emirates\",\n                                      \"Bangladesh\")),\n            aes(x=X,y=Y,label=ground_country),\n            check_overlap = F,\n            vjust=-1.5,hjust=0.5,family=\"Roboto Condensed\") +\n  # flags\n  ggflags::geom_flag(data=flags_df_coords2,\n                     aes(x=X,y=Y,country=country_code), size=4.5) +\n  coord_sf()+\n  ggthemes::theme_map() +\n  theme(text = element_text(family=\"Roboto Condensed\"),\n        plot.background = element_blank(),\n        panel.background = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_text(face=\"bold\"))\n\n# green background plot------------\nbackround_plot<- ggplot()+\n  geom_blank()+\n  ggthemes::theme_map() +\n  theme(plot.background = element_rect(fill=\"darkseagreen3\",color=\"#42f59b\"),\n        panel.background = element_rect(fill=\"darkseagreen3\",color=\"#42f59b\"))\n  \n\n# draw plot------------\nlibrary(cowplot)\nfinal<- ggdraw()+\n  #plot background\n  draw_image(\"R_general_resources/TidyTuesday/TidyTuesday/w49_world_cup_cricket/ball.jpg\",\n             x=0,y=0,scale=1)+\n  draw_image(\"R_general_resources/TidyTuesday/TidyTuesday/w49_world_cup_cricket/ball.jpg\",\n             x=0.4,y=0.4,scale=0.2,width = 1,height = 0.98)+\n  draw_plot(backround_plot,width=1,heigh=0.75,x=0,y=0.1) +\n  # main playing area\n  draw_line(x=c(0.05,0.95),y=c(0.5,0.5),\n            size=90,color=\"#a8e657\",alpha=0.4)+\n  # map with extra labels\n  draw_plot(map_plot) +\n  draw_label(\"Ireland\",x=0.45,y=0.68,size=10,color=\"black\")+\n  draw_label(\"United Arab Emirates\",x=0.57,y=0.58,size=10,color=\"black\")+\n  draw_label(\"Bangladesh\",x=0.7,y=0.57,size=10,color=\"black\")+\n  # red lines \n  draw_line(x=c(0.05,0.05),y=c(0.33,0.665),\n            size=0.2,color=\"red\",alpha=1)+\n  draw_line(x=c(0.95,0.95),y=c(0.33,0.665),\n            size=0.2,color=\"red\",alpha=1)+\n  # crease: popping crease\n  draw_label(\"Popping Crease\",x=0.19,y=0.28,size=12)+\n  draw_line(x=c(0.19,0.18),y=c(0.29,0.37),size=0.4,color=\"red\")+\n  draw_line(x=c(0.18,0.18),y=c(0.38,0.635),\n            size=0.5,color=\"white\",alpha=1)+\n  draw_line(x=c(0.82,0.82),y=c(0.38,0.635),\n            size=0.5,color=\"white\",alpha=1)+\n  # crease: return crease\n  draw_label(\"Return Crease\",x=0.138,y=0.32,size=12)+\n  draw_line(x=c(0.17,0.15),y=c(0.33,0.42),size=0.4,color=\"red\")+\n  draw_line(x=c(0.05,0.18),y=c(0.42,0.42),\n            size=0.5,color=\"white\",alpha=1)+\n  draw_line(x=c(0.82,0.95),y=c(0.42,0.42),\n            size=0.5,color=\"white\",alpha=1)+\n  draw_line(x=c(0.05,0.18),y=c(0.6,0.6),\n            size=0.5,color=\"white\",alpha=1)+\n  draw_line(x=c(0.82,0.95),y=c(0.6,0.6),\n            size=0.5,color=\"white\",alpha=1)+\n  # crease: bowling crease\n  draw_label(\"Bowling Crease\",x=0.126,y=0.62,size=12)+\n  draw_line(x=c(0.13,0.15),y=c(0.61,0.58),size=0.4,color=\"red\")+\n  draw_line(x=c(0.15,0.15),y=c(0.42,0.6),\n            size=0.5,color=\"white\",alpha=1)+\n  draw_line(x=c(0.85,0.85),y=c(0.42,0.6),\n            size=0.5,color=\"white\",alpha=1) + \n  draw_plot(week_trend,x=0.25,y=-0.3,scale=0.2,width=1,heigh=1)+\n  draw_plot(points_yr,x=0.01,y=-0.3,scale=0.2,width=1,heigh=1)+\n  # title & caption\n  draw_label(\"Cricket Ground Country Winners \\n1996-2005\",\n             x=0.4,y=0.93,size=34,fontfamily=\"Impact\",\n             fontface=\"bold\")+\n  draw_label(\"Datasource: World Cup Cricket | ESPN Cricinfo\\n#TidyTuesday w49\\nInfographics: Federica Gazzelloni\",\n             x=0.82,y=0.05,size=12,fontfamily=\"Impact\",\n             fontface=\"plain\")\n\n\n# save the plot---------\nragg::agg_png(here::here(\"TidyTuesday/w49/cricket.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w38_billboard/w38_billboard.html",
    "href": "tidytuesday/cases2021/posts2021/w38_billboard/w38_billboard.html",
    "title": "Billboard",
    "section": "",
    "text": "Load libraries:\n\nlibrary(tidyverse)\n\nLoad data:\n\nbillboard <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/billboard.csv')\naudio_features <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-14/audio_features.csv')\n\nData wrangling and saving data on a csv file:\n\nmy_df <- billboard %>%left_join(audio_features,by=c(\"song\",\"song_id\",\"performer\"))%>%\n  select(-url,-instance,-key,-mode,-valence,-tempo,-time_signature,-previous_week_position,-starts_with(\"spotify\"))\n\n#write_csv(my_df,here::here(\"w38/my_df.csv\"))\nmy_df <- read.csv(here::here(\"w38/my_df.csv\"))\n\nmy_df\n\nI’d like to study the “speackness” variable:\n\nsummary(my_df$speechiness)\n\nDataExplorer::profile_missing(my_df)\n\nSome values are missing (about 13% of the total), we leave them out for this visualization.\n\nmy_df <- my_df%>%drop_na(speechiness)\n\nLoad fonts to use in the theme():\n\nlibrary(extrafont)\n#fonts()\n\nMake a plot:\n\nplot <- my_df %>%#pull(peak_position)%>%summary(peak_position)\n  mutate(speechiness_class=case_when(speechiness<=0.33~\"Most likely music\",\n                                            speechiness>0.33&speechiness<=0.66~\"Contain music and speech\",\n                                            speechiness>0.66&speechiness<=0.75~\"Probably spoken words\",\n                                            speechiness>0.75~\"Exclusively speech-like\"))%>%\n  mutate(peak_position_class=case_when(peak_position<=15~\"low\",\n                                            peak_position>15&peak_position<=30~\"medium\",\n                                            peak_position>30&peak_position<=50~\"high\",\n                                            peak_position>=50~\"top\"))%>%\n  \n  ggplot(aes(x=-log10(speechiness)))+ #aes(x=speechiness))+\n  geom_histogram(binwidth=0.03,aes(color=factor(peak_position_class),fill=factor(peak_position_class)))+\n  #guides(color=\"none\",fill=\"none\")+\n  #scale_x_reverse()+\n  labs(subtitle=\"The Billboard Hot 100 is the music industry standard record chart in the United States for songs, \\npublished weekly by Billboard magazine. (Billboard Top 100 - Wikipedia)\\nCharts show the `Speechiness` distributions based on peak positions on radio play, and online streaming in the United States.\\n\",\n       color=\"Peak position\",fill=\"Peak position\",\n       x=\"Speechiness values (Log10-tranformation)\",y=\"\")+\n  facet_wrap(~speechiness_class,scales=\"free\")+\n  theme(text = element_text(family=\"Luminari\",color=\"midnightblue\",face = \"bold\"),\n        plot.subtitle = element_text(family=\"Luminari\",color=\"midnightblue\",size=14,vjust=-0.5),\n        legend.position = \"top\", #c(0.1,0.85),\n        legend.background = element_blank(),\n        legend.text = element_text(face = \"bold\",color=\"midnightblue\",size=14),\n        plot.background = element_blank(),\n        panel.background = element_blank(),\n        strip.background = element_blank(),\n        strip.text = element_text(face = \"bold\",color=\"midnightblue\",size=14),\n        axis.text = element_text(face = \"bold\",color=\"midnightblue\",size=14)\n        )\n\nAdd some features such as phrases of explanation, add some logos and other little information:\n\nlibrary(ggpubr)\ngraphics <- ggarrange(plot)+\n  theme(plot.background = element_rect(fill=NA, color = NA))\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"Top 100 Billboard\",\n                                              color = \"#9A32CD\", face = \"bold\", size = 45,\n                                              family = \"Luminari\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: Top 100 Billboard from Data.World\",\n                                                 color = \"black\",family = \"Luminari\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 15),\n                              left = text_grob(\"#TidyTuesday week38: Top 100 Billboard\", color = c(\"#778899\"), rot = 90,size = 30),\n                              right = text_grob(bquote(\"Top 100 Billboard MUSIC 🎼\"), color = c(\"#778899\"),rot = 90,size = 30),\n                              fig.lab = \"TidyTuesday week38\", fig.lab.face = \"bold.italic\",fig.lab.size = 12,\n                              fig.lab.pos = \"bottom.right\"\n)\n\n\n\nfinal_plot <-\n  final_plot +\n\n  annotate(geom = \"text\", label = \"The Billboard Hot 100 \\nwas first released in August 1958\",\n           x = 0.11, y = 0.74,colour = \"#00D2BE\",size = 4,family = \"Luminari\") +\n  annotate(geom = \"curve\", x = 0.07, xend = 0.09, y = 0.85, yend = 0.78, colour = \"#00D2BE\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"Luminari\",size=1.5) +\n\n  \n  \n  annotate(geom = \"text\", label = \"a good balance hits \\nin all positions\",\n           x = 0.3, y = 0.6,colour =\"#6B8E23\",size = 4,family = \"Luminari\") +\n  annotate(geom = \"curve\", x = 0.25, xend = 0.28, y = 0.53, yend = 0.69, colour = \"#6B8E23\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Luminari\",size=1.5) +\n\n  \n  \n  annotate(geom = \"text\", label = \"Peak positions high \\nare most likely found with \\n`Most likely music`\",\n           x = 0.18, y = 0.63,colour = \"#FF4040\",size = 4,family = \"Luminari\") +\n  annotate(geom = \"curve\", x = 0.11, xend = 0.10, y = 0.63, yend = 0.70, colour = \"#FF4040\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Luminari\",size=1.5) +\n  \n  \n\n  annotate(geom = \"text\", label = \"all music hits \\nthe top high with higher frequency\",x = 0.22, y = 0.25, colour = \"#9A32CD\", size = 5,family = \"Luminari\") +\n\n  annotate(geom = \"text\", label = \"MUSIC 🎼\", x = 0.18, y = 0.03, colour = \"red\", size = 7,family = \"Luminari\")+\n\n\n  annotate(geom = \"text\", label = \"worthy speech hit \\nthe top-high\\n without music \\nvery rarely\", x = 0.62, y = 0.34, colour = \"#FF7256\", size = 5,family = \"Luminari\") +\n  annotate(geom = \"curve\", x = 0.68, xend = 0.64, y = 0.52, yend = 0.41, colour = \"#FF7256\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Luminari\",size=1.5)\n\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\n\n\nimg <- image_read(here::here(\"w38/colored_Billboard_logo.png\"))\nimg2 <- image_read(here::here(\"w38/Billboard_Hot_100_logo.png\"))\n\nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(img, x = 0.85, y = 0.39,width = 0.12)+\n  draw_image(img2, x = 0.1, y = -0.2,width = 0.12)\n\nSave final plot\n\nragg::agg_png(here::here(\"w38/w38_billboard.png\"),\n              res = 320, width = 16, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w42_seafood/w42-seafood.html",
    "href": "tidytuesday/cases2021/posts2021/w42_seafood/w42-seafood.html",
    "title": "Global Seafood",
    "section": "",
    "text": "WEEK42 SEAFOOD\n\n# Load library and data\nlibrary(tidyverse)\n\nfarmed <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/aquaculture-farmed-fish-production.csv')\ncaptured_vs_farmed <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/capture-fisheries-vs-aquaculture.csv')\ncaptured <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/capture-fishery-production.csv')\nconsumption <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-and-seafood-consumption-per-capita.csv')\nstock <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/fish-stocks-within-sustainable-levels.csv')\nfishery <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/global-fishery-catch-by-sector.csv')\nproduction <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/seafood-and-fish-production-thousand-tonnes.csv')\n\n# make one dataframe \ndf <- farmed %>%\n  full_join(captured_vs_farmed,by=c(\"Entity\",\"Code\",\"Year\",\"Aquaculture production (metric tons)\")) %>%\n  full_join(captured,by=c(\"Entity\",\"Code\",\"Year\",\"Capture fisheries production (metric tons)\")) %>%\n  full_join(consumption,by=c(\"Entity\",\"Code\",\"Year\")) %>%\n  full_join(stock,by=c(\"Entity\",\"Code\",\"Year\")) %>%\n  full_join(fishery,by=c(\"Entity\",\"Code\",\"Year\")) %>%\n  full_join(production,by=c(\"Entity\",\"Code\",\"Year\")) %>%\n  janitor::clean_names()\n\nnames(df);dim(df)\nDataExplorer::profile_missing(df)\n\n\n# set the dataset for the first plot \ndf_group1 <- df %>%\n  filter(is.na(code)) %>%\n  select(-code) %>%\n  filter(str_detect(entity,\"income\")) %>%\n  pivot_longer(cols = 3:19,names_to = \"names\",values_to = \"values\") %>%\n  mutate(values = ifelse(is.na(values),0,values)) %>%\n  filter(values > 0) %>% \n  mutate(entity = gsub(\"excluding high income\",\"*\",entity)) %>% #count(entity)\n  mutate(entity = factor(entity, levels = c('High income','Upper middle income','Middle income',\n                                          'Lower middle income','Low & middle income','Low income',\n                                          'Europe & Central Asia (*)','Latin America & Caribbean (*)',\n                                          'East Asia & Pacific (*)','Middle East & North Africa (*)','Sub-Saharan Africa (*)'))) \n\n\n# choose the color palette  \n# RColorBrewer::brewer.pal.info\n# set the text options \nlibrary(showtext)\nshowtext_opts(dpi = 320)\nshowtext_auto(enable = T)\nfont_add_google(\"Share Tech Mono\", \"techmono\")\n   \n\n# make the first plot: a facet_plot of the World Continents by income level\nfacet_plot <-  ggplot(data = df_group1, aes(x = factor(year), y = values/100000000,group = names,color = names)) +\n  geom_line(size = 1.3) +\n  guides(color = guide_legend(title = \"Production tons sc-%\",ncol = 1,title.position = \"top\", title.hjust = 0.5)) +\n  scale_x_discrete(breaks = seq(1960,2018,10)) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_color_manual(limits = c(\"aquaculture_production_metric_tons\",\"capture_fisheries_production_metric_tons\"),\n                     labels = c(\"aquaculture_production_metric_tons\" = \"Aquaculture\",\n                                \"capture_fisheries_production_metric_tons\" = \"Capture Fisheries\"),\n                     values = RColorBrewer::brewer.pal(2,\"Reds\")) +\n  facet_wrap(vars(entity),scales = \"free\",nrow = 2) +\n  labs(subtitle = \" \", caption = \" \") +\n  ggthemes::theme_fivethirtyeight() +\n  theme(text = element_text(family = \"techmono\",color = \"#FFF8DC\",face = \"bold\"),\n        legend.position = c(0.92,0.3),\n        legend.title = element_text(face = \"bold\",size = 14),\n        legend.box.background = element_blank(),\n        legend.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        legend.key = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        legend.text = element_text(size = 9),\n        strip.text = element_text(size = 9,face = \"bold\"),\n        strip.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_line(size = 0.2),\n        plot.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        panel.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        plot.title = element_text(face = \"bold\",size = 30),\n        plot.margin = margin(0,0,0,0,unit = \"pt\")) \n\n\n\n#-------------\n# seafood supply time-series plot of all countries and selected countries of seafood supply kg per capita FAO yr 2020\n\n\n# data to use in the second plot for the first geom_line for all countries (in grey)\ndf_group2 <- df %>% \n  filter(!is.na(code)) %>%\n  pivot_longer(cols = 14:20,names_to = \"livestock\",values_to = \"livestock_commodity\") %>%\n  select(-4,-5) %>%\n  mutate(livestock = gsub(\"commodity_balances_livestock_and_fish_primary_equivalent_\",\"\",livestock),\n         livestock = gsub(\"_production_5510_tonnes\",\"\",livestock),\n         livestock = gsub(\"[0-9]\",\"\",livestock),\n         livestock = gsub(\"_\",\"\",livestock)) %>%\n  pivot_longer(cols = 5:6,names_to = \"share_of_fish\",values_to = \"fish_stocks\") %>%\n  mutate(share_of_fish = recode(share_of_fish,\n                                share_of_fish_stocks_that_are_overexploited = \"overexploited\",\n                                share_of_fish_stocks_within_biologically_sustainable_levels_fao_2020 = \"sustainable\")) %>%\n  pivot_longer(cols = c(5,7),names_to = \"commercial\",values_to = \"scale_commercial\") %>%\n  mutate(commercial = recode(commercial,\n                             artisanal_small_scale_commercial = \"artisanal\",\n                             industrial_large_scale_commercial = \"industrial\")) %>%\n  rename(seafood_supply = fish_seafood_food_supply_quantity_kg_capita_yr_fao_2020)\n\n\ndf_group2[is.na(df_group2)] <- 0\n\ndf_group2 <- df_group2 %>% \n  filter(seafood_supply > 0) %>% \n  select(year,entity,seafood_supply)\n\n\n\n# data to use in the second geom_line for selected countries\ndf_group3 <- df_group2 %>%\n  filter(entity %in% c(\"Iceland\",\"Maldives\",\"Lesotho\",\"Brazil\",'Sri Lanka',\"Malaysia\",\"Chile\",\"Tanzania\",\"Japan\")) \n\n\n\n# make the second plot: time series of all countries and selected countries of seafood supply kg per capita FAO yr 2020\n seafood_plot <- ggplot() +\n  geom_line(data = df_group2, \n            aes(x = factor(year),y = (seafood_supply),group = entity),color = \"grey75\",size = 0.2) +\n  geom_line(data = df_group3 ,\n            aes(x = factor(year),y = (seafood_supply),group = entity,color = entity),size = 1.2,\n            key_glyph = \"timeseries\") +\n  scale_x_discrete(breaks = seq(1960,2018,5), expand = expansion(add = 0.5)) +\n  scale_y_log10(labels = scales::comma_format()) +\n  scale_color_manual(values = RColorBrewer::brewer.pal(9,\"Set1\")) +\n  guides(color = guide_legend(title = \"Selected Countries seafood production kg per capita FAO yr 2020\",\n                              nrow = 1,title.position = \"top\", title.hjust = 0.5,title.vjust = 0.5)) +\n  labs(x = \"Years\",y = \"Values in log scale\",\n       title = \" \",\n       subtitle = \" \") +\n  ggthemes::theme_fivethirtyeight() +\n  theme(text = element_text(family = \"techmono\",color = \"#FFF8DC\",face = \"bold\"),\n        axis.title.x = element_text(vjust = 0.5,face = \"bold\"),\n        axis.title.y = element_text(vjust = 0.5,face = \"bold\"),\n        plot.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        panel.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\"),\n        panel.grid.major.x = element_line(size = 0.2,linetype = \"dashed\"),\n        legend.background = element_blank(),\n        legend.text = element_text(size = 14),\n        legend.position = \"top\",\n        legend.title = element_text(face = \"bold\",size = 16),\n        legend.key = element_blank(),\n        plot.title = element_text(face = \"bold\",size = 30),\n        plot.margin = margin(0,0,0,0,unit = \"pt\"))\n\n\n# make one plot\nlibrary(patchwork)  \nplot <- (seafood_plot / facet_plot ) \n  #theme_update(plot.background = element_rect(fill=\"#009ACD\",color=\"#009ACD\"),\n               #panel.background = element_rect(fill=\"#009ACD\",color=\"#009ACD\"),\n               #plot.margin = margin(0,0,0,0,unit = \"pt\"))\n\n\n# load the libraries for final touches\nrequire(ggpubr)\n\n# ggarrange from {ggpubr} frames the plot to make side annotations\ngraphics <- ggpubr::ggarrange(plot) \n\nfinal_plot <- ggpubr::annotate_figure(graphics,\n                              top = text_grob(\"Global Seafood Supply in 182 countries \\n(1960 - 2018)\",\n                                              color = c(\"#FFF8DC\"), face = \"bold\", size = 34,\n                                              family = \"techmono\",vjust = 0.8),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: OurWorldinData.org - TidyTuesday week42\",\n                                                 color = \"#FFF8DC\",family = \"techmono\",\n                                                 hjust = 0.5, vjust = 0.5, x = 0.5, face = \"bold.italic\", size = 14),\n                              left = text_grob(\" \", color = c(\"#778899\"), rot = 90,size = 12),\n                              right = text_grob(bquote(\" \"), color = c(\"#778899\"),rot = 90,size = 10),\n                              fig.lab = \"\", fig.lab.face = \"bold.italic\",fig.lab.size = 8,\n                              fig.lab.pos = \"bottom.right\"\n)\n\nfinal_plot <- final_plot +\n  annotate(geom = \"text\", label = \"(*) excluding high income\",\n         x = 0.91, y = 0.1,colour = \"#FFF8DC\",size = 4,family = \"techmono\",fontface = \"bold\") \n  \n  \nlibrary(cowplot)  \nlibrary(ggimage)\nlibrary(magick)\n\n# add the images for the legend keys \n\nimgOWD <- image_read(here::here(\"w42/owd.png\"))\nimgfish <- image_read(here::here(\"w42/fish.png\"))\nimgtt <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\n# ggdraw from {cowplot} draw the plot for setting the background colors of the side annotations\nfinal <- cowplot::ggdraw(final_plot) + \n  draw_image(imgfish, x = 0.03, y = 0.44,width = 0.07) +\n  draw_image(imgfish, x = 0.08, y = 0.37,width = 0.05) +\n  draw_image(imgfish, x = 0.12, y = 0.32,width = 0.03) +\n  draw_image(imgtt, x = 0.85, y = 0.45,width = 0.12) +\n  draw_image(imgOWD, x = 0.9, y = -0.46,width = 0.06) +\n  theme(plot.background = element_rect(fill = \"#009ACD\",color = \"#009ACD\")) \n\n\n# save final plot\nragg::agg_png(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w42/w42_seafood.png\"),\n              res = 320, width = 16, height = 14, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w45_maps/w45_maps.html",
    "href": "tidytuesday/cases2021/posts2021/w45_maps/w45_maps.html",
    "title": "Making maps with R",
    "section": "",
    "text": "https://osdatahub.os.uk/downloads/open#CODEPO https://datatricks.co.uk/london-map-in-3-easy-steps https://data.police.uk/data/statistical-data/\n\nlibrary(tidyverse)\nlibrary(spData)\nlibrary(sf)\nlibrary(rgeos)\nlibrary(sp)\n# x <- c(\"ggmap\", \"rgdal\", \"rgeos\", \"maptools\", \"dplyr\", \"tidyr\", \"tmap\")\n#  # install.packages(x) # warning: uncommenting this may take a number of minutes\n# lapply(x, library, character.only = TRUE) # load the required packages\n\n\nspData::cycle_hire_osm\nspData::lnd\n\n\ncoord_lnd_cycl <- data.frame(st_coordinates(cycle_hire_osm$geometry))\n\ncycle_hire_osm <- as.data.frame(cycle_hire_osm)\n\n\ncycle_hire_osm$X <- coord_lnd_cycl$X\ncycle_hire_osm$Y <- coord_lnd_cycl$Y\n\n\ncycle_hire_osm\n\n\nspData::lnd\n\n\nplot(lnd)\n\n\nlondon_data <- lnd\n\nlnd_geo <- data.frame(london_data$GSS_CODE,london_data$HECTARES,london_data$geometry)\n\nnames(lnd_geo)[1]<- \"GSS_CODE\"\n\ncoord_london <- data.frame(st_coordinates(lnd_geo$geometry))\n\nlnd_geo_coord<- merge.data.frame(lnd_geo,coord_london)\n\n\nlnd_geo_coord%>%count(L3)\n\nLONDON MAP!!!!!!\n\nggplot() +\n  geom_polygon(data=lnd_geo_coord,\n               aes(x = X, y = Y,group=L3, fill = L3), \n               colour = \"black\")+\n  labs(x = \"Longitude\", y = \"Latitude\", \n       title = \"Map of Greater London with the borough boundaries\")\n\n\ncycle_hire_osm\n\n\nlibrary(extrafont)\nlibrary(showtext)\nfonts()\nloadfonts()\nfont.families.google()\nfont_add_google(\"Mr Dafoe\", \"MrDafoe\")\nshowtext_opts(dpi = 320)\nshowtext_auto(enable = T)\n\n\nlnd_center<- lnd_geo_coord%>%filter(X>c(-0.3) & X<0.0,\n                                    Y>51.4 & Y<51.6)\n\ncycle_hire_osm%>%count(name)\n\nfinal <-ggplot()+\n     geom_polygon(data=lnd_geo_coord,\n               aes(x = X, y = Y,group=L3, fill = L3), \n               colour = \"black\")+\n     geom_point(data=cycle_hire_osm, mapping=aes(x=X,y=Y),\n                color = 'gold', size=0.2, alpha=0.5)+ \n  coord_map()+\n  scale_fill_gradient(low = \"honeydew2\",high = \"darkgreen\")+\n  labs(x = \"Longitude\", y = \"Latitude\", \n       title = \"Map of Greater London with cycle hire\",\n       subtitle = \"with the borough boundaries\",\n       caption = \"Datasource: #TidyTuesday week45 - {spData} package \\n Infographics: Federica Gazzelloni\")+\n  cowplot::theme_map()+\n  theme(panel.grid.major = element_blank(),\n        axis.title.x=element_blank(), \n        axis.text.y=element_blank(), \n        plot.background = element_rect(color=\"midnightblue\",fill=\"midnightblue\"),\n        panel.background=element_rect(color=\"midnightblue\",fill=\"midnightblue\"),\n        plot.title=element_text(color=\"honeydew2\",size=33,family=\"Arial\"),\n        plot.subtitle=element_text(color=\"honeydew2\",size=24,family=\"Arial\"),\n        plot.caption = element_text(family=\"Arial\",color=\"honeydew2\"),\n        legend.position = \"none\")\n\n\n# save final plot\nragg::agg_png(\"~/Documents/R/R_general_resources/30DayMapChallenge/day7_green/green.png\",\n              res = 320, width = 11, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w36_bird_baths/w36_bird_baths.html",
    "href": "tidytuesday/cases2021/posts2021/w36_bird_baths/w36_bird_baths.html",
    "title": "Bird Baths",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggdendro)\nlibrary(dendextend)\nlibrary(ggraph)\nlibrary(tidygraph)\nlibrary(purrr)\nlibrary(rlang)\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 36)\nbird_baths <- tuesdata$bird_baths\n\nbird_baths <- bird_baths %>%\n  drop_na() %>%\n  filter(bird_count>0)  # %>% count(bird_type,sort=TRUE) %>% View()\n\nsurvey_year_id <- bird_baths %>% count(survey_year) %>%\n  mutate(survey_year_id = row_number()) %>% select(-n)\nurban_rural_id <- bird_baths %>% count(urban_rural) %>%\n  mutate(urb_rul_id = row_number()) %>% select(-n)\nbioregions_id <- bird_baths %>% count(bioregions) %>% \n  mutate(bioregions_id = row_number()) %>% select(-n)\nbird_type_id <- bird_baths %>% count(bird_type) %>% \n  mutate(bird_type_id = row_number()) %>% select(-n)\n\n\nbird_baths_numeric <- bird_baths %>%\n  inner_join(survey_year_id,\n             by=\"survey_year\") %>%\n  inner_join(urban_rural_id,\n             by=\"urban_rural\") %>%\n  inner_join(bioregions_id,\n             by=\"bioregions\") %>%\n  inner_join(bird_type_id,\n             by=\"bird_type\") %>%\n  count(survey_year_id,urb_rul_id,bioregions_id,bird_type_id) %>%\n  arrange(survey_year_id,urb_rul_id,bioregions_id,bird_type_id) \n\n\nbird_baths_half_numeric <- bird_baths %>%\n  inner_join(survey_year_id,\n             by=\"survey_year\") %>%\n  inner_join(urban_rural_id,\n             by=\"urban_rural\") %>%\n  inner_join(bioregions_id,\n             by=\"bioregions\") %>%\n  inner_join(bird_type_id,\n             by=\"bird_type\") %>%\n  count(survey_year,survey_year_id,\n        urban_rural,urb_rul_id,\n        bioregions,bioregions_id,\n        bird_type,bird_type_id) %>%\n  arrange(survey_year) \n\nbird_baths_numeric_short <- bird_baths %>%\n  inner_join(survey_year_id,\n             by=\"survey_year\") %>%\n  inner_join(urban_rural_id,\n             by=\"urban_rural\") %>%\n  inner_join(bioregions_id,\n             by=\"bioregions\") %>%\n  inner_join(bird_type_id,\n             by=\"bird_type\") %>%\n  count(survey_year_id,urb_rul_id,bioregions_id,bird_type_id) %>% #View()\n  filter(n<=20)\n\n\nbird_baths_half_numeric_short <- bird_baths %>%\n  inner_join(survey_year_id,\n             by=\"survey_year\") %>%\n  inner_join(urban_rural_id,\n             by=\"urban_rural\") %>%\n  inner_join(bioregions_id,\n             by=\"bioregions\") %>%\n  inner_join(bird_type_id,\n             by=\"bird_type\") %>%\n  count(survey_year,survey_year_id,\n        urban_rural,urb_rul_id,\n        bioregions,bioregions_id,\n        bird_type,bird_type_id) %>% #View()\n  filter(n<=20)\n\n\n\n#-------- data to use\n\n\nbb_piv_w <- bird_baths_half_numeric %>%\n  count(survey_year,bird_type,urban_rural,bioregions) %>%\n  pivot_wider(names_from=c(survey_year,urban_rural,bioregions),values_from=n,values_fill = 0)\n\n\n# https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html#the-3-clusters-from-the-complete-method-vs-the-real-species-category\nbirds <- column_to_rownames(bb_piv_w,var = \"bird_type\")\n\n\n\n# View(birds)\n\n# build a dendrogram\n\ndend_r <- birds %>%\n  dist(method = \"man\") %>%\n  hclust(method = \"ward.D2\") %>%\n  as.dendrogram %>%\n  ladderize %>%\n  color_branches(k=4)\n\ndend_c <- t(birds) %>%\n  dist(method = \"man\") %>%\n  hclust(method = \"com\") %>%\n  as.dendrogram %>%\n  ladderize%>%\n  color_branches(k=3)\n\n# set the colors\nsome_col_func <- function(n) (\n  colorspace::diverge_hcl(n, h = c(246, 40), c = 96, l = c(65, 90)))\n\n\n# plot the heatmap with the dendrograms\npar(mar = c(5,5,5,5))\n\nlibrary(gplots)\nset_graph_style(plot_margin = margin(1,1,1,1))\n\nplot <- gplots::heatmap.2(as.matrix(birds),\n                          main = \"Bird types concentration\",\n                          srtCol = 35,\n                          Rowv = dend_r,\n                          Colv = dend_c,\n                          trace=\"row\", hline = NA, tracecol = \"darkgrey\",\n                          margins =c(11,8),\n                          key.xlab = \"spotted/unspotted\",\n                          denscol = \"grey\",\n                          density.info = \"density\",\n                          col = some_col_func\n)\n\n## Save the plot as an image ----\n\nragg::agg_png(here::here(\"w36/heat_map.png\"),\n              res = 320, width = 15, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n#------------finish touches\n\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\n\nheat_map <- image_read(here::here(\"w36/heat_map.png\"))\n\nplot <- ggdraw() +\n  draw_image(heat_map)\n\nlibrary(ggpubr)\ngraphics <- ggarrange(plot)\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"\",\n                                              color = c(\"#8a5d24\"), face = \"bold\", size = 24,\n                                              family = \"xkcd\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: Cleary et al, 2016 TidyTuesday week36\",\n                                                 color = \"black\",family = \"xkcd\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n                              left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size = 10),\n                              right = text_grob(bquote(\"\"), color = c(\"#778899\"),rot = 90,size = 10),\n                              fig.lab = \"TidyTuesday week36\", fig.lab.face = \"bold.italic\",fig.lab.size = 8,\n                              fig.lab.pos = \"bottom.right\"\n)\n\nfinal_plot <-\n  final_plot +\n\n  annotate(geom = \"text\", label = \"While wild bird feeding is recognised as one of\nthe most popular forms of\nhuman-wildlife interaction, almost nothing is known\n           about the use of bird baths.\",\n           x = 0.15, y = 0.25,colour = \"black\",size = 3,family = \"xkcd\") +\n\n  annotate(geom = \"text\", label = \"\",\n           x = 0.15, y = 0.65,colour = \"black\",size = 3,family = \"xkcd\") +\n\n  annotate(geom = \"text\", label = \"Urbanisation is one of the leading causes of species extinction\n           due to extensive habitat alteration\",\n           x = 0.82, y = 0.04,colour = \"black\",size = 3,family = \"xkcd\") +\n\n  annotate(geom = \"text\", label = \"Bioregions\",x = 0.85, y = 0.88, colour = \"#FF7F00\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Rural\",x = 0.73, y = 0.58, colour = \"white\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Urban\",x = 0.1, y = 0.5, colour = \"#FF7F00\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.82, xend = 0.76, y = 0.88, yend = 0.72, colour = \"#FF7F00\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.72, xend = 0.68, y = 0.6, yend = 0.65, colour = \"#FF7F00\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.12, xend = 0.2, y = 0.5, yend = 0.43, colour = \"#FF7F00\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n\n  annotate(geom = \"text\", label = \"Comparing Bird types' while enjoing a bird bath\",\n           x = 0.4, y = 0.84,colour = \"#FF7F00\",size = 3,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Avian assemblages at urban and rural bird baths\n           differed between bioregions with aggressive\n           nectar-eating species\",\n           x = 0.67, y = 0.38,colour = \"black\",size = 3,family = \"xkcd\")\n\n\n\nrainbow_lorikeet_img <- image_read(here::here(\"w36/parrot2.png\"))\n\nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(rainbow_lorikeet_img, x = 0.89, y = 0.4,width = 0.12)\n\n\nfinal\n\n\n## Save final plot ----\n\nragg::agg_png(here::here(\"w36/w36_bird_baths.png\"),\n              res = 320, width = 15, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\n\n\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\nimg <- image_read(\"image.png\")\n\n\ntidy_final <- image_read(\"w35_lemurs.png\")\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator = \"atop\",\n                                 gravity = \"southwest\")\n\nimage_write(attached_logo, path = \"w35_lemurs.png\", format = \"png\")"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w16_US_Post_office/w16_US_Post_office.html",
    "href": "tidytuesday/cases2021/posts2021/w16_US_Post_office/w16_US_Post_office.html",
    "title": "US Post Office",
    "section": "",
    "text": "Loading libraries\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(maptools)\nlibrary(data.table)\n\nLoading data\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 16)\npost_offices <- tuesdata$post_offices\n\nWrangling\n\nhead(post_offices)\n\n\nmy_df<-post_offices%>%filter(established>=1639,established<=2000,\n                          discontinued>=1775 ,discontinued<=2002,\n                          !is.na(stamp_index),\n                          !duration<0,\n                          !is.na(gnis_dist),\n                          !stamp_index==55,\n                          !is.na(county1))%>%\n  select(\"duration\",\"gnis_dist\",\"stamp_index\")%>%\n  group_by(stamp_index)%>%\n  summarize(avg_duration=mean(duration),avg_dist=mean(gnis_dist))\n\nSetting data ready for plotting\n\nlibrary(igraph)\nmat <- cor(t(my_df))\nmat[mat<0.995] <- 0\n# Make an Igraph object from this matrix:\nnetwork <- graph_from_adjacency_matrix( mat, weighted=T, mode=\"undirected\", diag=F)\n\n# Basic chart\nplot(network)\n\n\n# color palette\nlibrary(RColorBrewer)\ncoul <- brewer.pal(nlevels(as.factor(my_df$stamp_index)), \"Set3\")\n\n# Map the color to cylinders\nmy_color <- coul[as.numeric(as.factor(my_df$stamp_index))]\n\nSetting for saving plot\n\nragg::agg_png(here::here(\"US_Post_office_space.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\n\n# plotting ############################################\n\npar(bg=\"mediumblue\", mar=c(1,1,1,1))\nset.seed(4)\nplot(network, \n     vertex.label.family=\"Georgia\", \n     edge.curved=0.08,\n     edge.width=2,                                 \n     edge.arrow.size=1,                       \n     edge.arrow.width=1,                          \n     edge.lty=\"solid\",\n     vertex.size=12,\n     vertex.shape=c(\"raster\",\"sphere\"), \n     vertex.color=my_color, \n     vertex.label.cex=0.7,\n     vertex.label.color=\"blue\",\n     vertex.frame.color=\"transparent\"\n)\n\nop <- par(family = \"Luminari\")\n\n#### legend and titles ########################\n\nlegend(x=1.3, y=0.7, \n       legend=paste( levels(as.factor(my_df$stamp_index)), \"stamp*\", sep=\"*\"), \n       col = coul , \n       bty = \"n\", pch=20 , pt.cex = 2, cex = 1,\n       text.col=\"white\" , horiz = F)\ntext(-1.4,1.1,\"US Post Offices\",col=\"white\", cex=1.5)\ntext(-1.3,1,\"Stamps index by distance\",col=\"white\", cex=1.2)\ntext(-1.1,0.9,\"visualization of the distance between offices by different stamps index\",col=\"white\", cex=0.8)\n\ntext(-1,-1.1,\"Viz @fgazzelloni | #TidyTueasday Week 16 | Space Day 14 | DataSource: Harvard Dataverse\",col=\"white\", cex=0.8)\npar(op)\n\nImaging\n\nlibrary(png)\nlibrary(grid)\nlibrary(magick)\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"400x400\")\n\nmypng2<-readPNG(\"satellite2.png\")\nmypng3<-readPNG(\"satellite3.png\")\n\n\ngrid.raster(tidy_logo, x=0.9, y=0.2, width=.08)\ngrid.raster(mypng2, x=.09, y=.7, width=.25)\ngrid.raster(mypng3, x=.9, y=.9, width=.25)\n\n####### final ###################\n\n# dev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w25_du_bois/w25_du_bois.html",
    "href": "tidytuesday/cases2021/posts2021/w25_du_bois/w25_du_bois.html",
    "title": "Dubois Challenge",
    "section": "",
    "text": "Week 25\nDataSource: https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-06-15/readme.md\nDubois Style https://github.com/ajstarks/dubois-data-portraits/blob/master/dubois-style.pdf\nAdd fonts https://cran.rstudio.com/web/packages/showtext/vignettes/introduction.html https://fonts.google.com/specimen/Shadows+Into+Light#standard-styles\ninspirations https://github.com/ivoruaro/tidytuesday/blob/main/2021w25.R https://github.com/nrennie/tidytuesday/blob/main/2021/15-06-2021/15062021.R https://gist.github.com/clauswilke/783e1a8ee3233775c9c3b8bfe531e28a\nimage background https://www.pngwing.com/en/free-png-zfvci\n\n\nload libraries\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(DataExplorer)\nlibrary(ggtext)\nlibrary(DataEditR)\nlibrary(tidyquant)\n\n\nlibrary(RColorBrewer)\n\nlibrary(maps)\nlibrary(rnaturalearth)\nlibrary(sp)\nlibrary(sf)\n\nlibrary(extrafont)\n#library(ggrepel)\n\n#library(viridis)\nlibrary(hrbrthemes)\n\nlibrary(ggimage)\nlibrary(patchwork)\nlibrary(cowplot)\n\nlibrary(ggpattern)\n\n\n# add font -------------------------------------------------\nlibrary(showtext)\nfont_add_google(\"Shadows Into Light\",\"shadow_into_light\")\nfont_add_google(\"Schoolbell\", \"bell\")\nshowtext_auto(enable = TRUE)\n\n# load data ----------------------------------------\ntuesdata <- tidytuesdayR::tt_load('2021-06-15')\n\ntweets <- tuesdata$tweets\n\n# check data -----------------------\nhead(tweets)\n\nprofile_missing(tweets)\n\n# tidying -----------------------------------\ndf_tweets<-tweets%>%\n  arrange(-like_count,-followers)%>%\n  drop_na()\n\nplyr::count(df_tweets$location)\n\n# load map data ------------------------------\n\n# world data full \nworld_full <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld_data <- filter(world_full, continent != \"Antarctica\")\n\n# world lat&long\nworld<-map_data(map = \"world\") \n\nmy_world_data<- world%>%\n  full_join(world_data, by = c(\"region\"=\"name\"))%>%\n  select(long,lat,group,order,region,region_wb)\n\n# states lat&long\nstates <- map_data(\"state\")\n\n# choose palette colors ----------------------\n# dubois palette taken from Dubois Style webpage\ndubois_pal <- c(\"black\" = \"#000000\", \n                \"brown\" = \"#654321\", \n                \"tan\" = \"#d2b48c\",\n                \"gold\" = \"#ffd700\",\n                \"pink\"=\"#ffc0cb\",\n                \"red\"=\"#dc143c\",\n                \"green\"=\"#00aa00\",\n                \"blue\"=\"#4682b4\")\n\npalette<-c(\"#000000\",\"#654321\",\"#d2b48c\",\"#ffd700\",\"#ffc0cb\",\"#dc143c\",\"#00aa00\",\"#4682b4\")\n\nstates_palette<-colorRampPalette(c(\"#654321\",\"#d2b48c\",\"#ffd700\",\"#ffc0cb\",\"#dc143c\",\"#00aa00\",\"#4682b4\"))(15537)\n\npal_west <- c(\"#000000\", \"#4682b4\")\npal_est <- c(\"#000000\", \"#4682b4\")\n\npal_fill<-c(\"background\"=\"#e8d8c3\",\n            \"water\"=\"#d9c09e\",\n            \"europe\"=\"#ffd700\",\n            \"canada\"=\"#654921\",\n            \"southAmerica\"=\"#1b1209\")\n\n\n# make the plot ---------------------\n\nworld_west <-ggplot() +\n  geom_polygon(data=my_world_data,aes(x=long,y=lat,group=group,fill=region_wb)) + scale_fill_manual(values=palette) + guides(fill=FALSE)+\n  \n  geom_polygon(data = states,aes(x = long, y = lat, group = group),fill=states_palette,color=\"#000000\",size=0.3)+#scale_fill_manual(values=states_palette) +guides(fill=FALSE)+\n  \n  geom_path(data=world,aes(x=long,y=lat,group=group),size=0.3) +\n  \n  geom_point(data = df_tweets,mapping=aes(x=long, y=lat, size=followers, shape=verified,color=verified),alpha=0.7) +\n  \n  geom_path(data = df_tweets,mapping=aes(x=long, y=lat,group=location),size=0.3,color=\"#654321\") + \n  \n  coord_map(\"ortho\", orientation = c(3.849945, -103.525750, 0)) + \n  \n  #geom_text(data = df_tweets,aes(x=long, y=lat, group=location, label=location), check_overlap = TRUE,color=\"#654321\",size = 3, hjust=0.5, vjust=-1)+\n  \n  #geom_curve(data = df_tweets,aes(x=long, y=lat, group=location, label=location))+\n  \n # annotate(\"text\", x = 0, y = 0,family= \"shadow_into_light\",label=\"World map of \",color = \"#ffc0cb\", size = 4,fontface=\"bold\") +\n  \n  scale_size(guide=FALSE, range = c(1,9)) +\n  scale_shape(guide=FALSE) +\n  scale_color_manual(values = pal_west, aesthetics = c(\"colour\")) +\n  labs(x=\"\",y=\"\",color=\"Verified accounts\") +\n  theme_void() +\n  theme(plot.background = element_rect(fill = \"#e8d8c3\", colour = \"#e8d8c3\"),#   element_rect(color=\"#e8d8c3\",fill=\"#e8d8c3\"),\n        panel.background = element_rect(color=\"#e8d8c3\",fill=\"#d9c09e\"),\n        axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"bottom\",\n        legend.text = element_text(family=\"shadow_into_light\"),\n        legend.title = element_text(family=\"shadow_into_light\"))\n\n# world_west\n\n\n\nworld_est <-ggplot() +\n  geom_polygon(data=my_world_data,aes(x=long,y=lat,group=group,fill=region_wb)) + scale_fill_manual(values=palette) + guides(fill=FALSE)+\n  \n  geom_polygon(data = states,aes(x = long, y = lat, group = group),fill=states_palette,color=\"#000000\",size=0.3)+#scale_fill_manual(values=states_palette) +guides(fill=FALSE)+\n  \n  geom_path(data=world,aes(x=long,y=lat,group=group),size=0.3) +\n  \n  geom_point(data = df_tweets,mapping=aes(x=long, y=lat, size=followers, shape=verified,color=verified),alpha=0.7) +\n  \n  geom_path(data = df_tweets,mapping=aes(x=long, y=lat,group=location),size=0.3,color=\"#654321\") + \n  \n  coord_map(\"ortho\", orientation = c(19.982182, 46.595135, 0)) +\n  \n  #geom_text(data = df_tweets,aes(x=long, y=lat, group=location, label=location), check_overlap = TRUE,color=\"#654321\",size = 3, hjust=0, vjust=-1)+\n  \n  #geom_curve(data = df_tweets,aes(x=long, y=lat, group=location, label=location))+\n  \n  #annotate(\"text\", x = 0, y = 0,family= \"shadow_into_light\",label=\"Tweets sized by followers\",color = \"#ffc0cb\", size = 4,fontface=\"bold\") +\n \n  scale_size(guide=FALSE, range = c(1,9)) +\n  scale_shape(guide=FALSE)+\n  scale_color_manual(values = pal_est,aesthetics = c(\"colour\"))+ #, \"fill\")) +\n  labs(caption=\"Viz @fgazzelloni DataSource: WEB Du Bois and Juneteenth #DuBoisChallenge tweets The Intercept #TidyTuesday 2021/25\",\n       x=\"\",y=\"\",color=\"\") +\n  theme_void() +\n  theme(plot.background = element_rect(fill = \"#e8d8c3\", colour = \"#e8d8c3\"),\n        panel.background = element_rect(color=\"#e8d8c3\",fill=\"#d9c09e\"),\n        plot.caption = element_text(color=\"#00aa00\",face=\"bold\",family=\"shadow_into_light\"),\n        axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\")\n\n# world_est\n\n\nmain_plot <- (world_west + world_est)\n\nplot <-plot_grid(main_plot)\n\nfinal <- plot +\n  theme(plot.background = element_rect(fill = \"#e8d8c3\", colour = \"#e8d8c3\"),\n        plot.margin = margin(t=0,r=1,b=0,l=1,unit=\"pt\"))\n\n\ntitle<- ggplot()+\n  labs(title=\"\\n\\n#DuBoisChalllenge 2021 Twitter Metrics\",\n       subtitle=\"Tweets by number of followers (verified or not) and by selected locations\\n\\nINSPIRED BY:\\n\",\n       tag=\"\\nTHE GEORGIA NEGRO \\nA SOCIAL STUDY \\nby W.E. BURGHARDT\\n\\n\") +\n  theme_void()+\n  theme(plot.background = element_rect(fill = \"#e8d8c3\", colour = \"#e8d8c3\"),# element_rect(color=\"#e8d8c3\",fill=\"#e8d8c3\"),\n        panel.background = element_rect(color=\"#e8d8c3\",fill=\"#e8d8c3\"),\n        plot.title = element_text(color=\"#000000\",size=20,face=\"bold\",family=\"bell\",hjust = 0.5,vjust = 0),\n        plot.subtitle = element_text(color=\"#000000\",size=12,face=\"bold\",family=\"bell\",vjust = 0,hjust = 0.5),\n        plot.tag = element_text(color=\"#000000\",size=12,face=\"bold\"),\n        plot.tag.position = \"bottom\",\n        plot.margin = margin(t=0,r=1,b=1,l=1,unit=\"pt\"))\n\ncaption<- ggplot()+\n  labs(title=\"ROUTES OF THE TWEETS BY LOCATIONS\",\n       subtitle=\"THIS CASE IS DEVOTED TO A SERIES OF CHARTS, MAPS AND OTHER DEVICES DESIGNED TO ILLUSTRATE \\nTHE DEVELOPMENT OF THE AMERICA NEGRO IN A SIGLE TYPICAL STATE OF THE UNITED STATES\",\n       tag=\"THE PROBLEM OF THE 20^th CENTURY IS THE PROBLEM OF THE COLOR-LINE\\n\") +\n  theme_void()+\n  theme(plot.background = element_rect(fill = \"#e8d8c3\", colour = \"#e8d8c3\"),# element_rect(color=\"#e8d8c3\",fill=\"#e8d8c3\"),\n        panel.background = element_rect(color=\"#e8d8c3\",fill=\"#e8d8c3\"),\n        plot.title = element_text(color=\"#000000\",size=11,face=\"bold\",family=\"bell\",hjust=0.5),\n        plot.subtitle = element_text(color=\"#000000\",size=10,face=\"bold\",family=\"bell\",vjust = -1,hjust = 0.5),\n        plot.tag = element_text(color=\"#000000\",size=8,face=\"bold\"),\n        plot.tag.position = \"bottom\",\n        plot.margin = margin(t=0,r=1,b=0,l=1,unit=\"pt\"))\n  \n\n        \nfinal_plot<-plot_grid(title,final,caption,ncol=1,rel_heights = c(0.4,1,0.15))\n\n\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w25\",\"w25_tweets.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"w25/w25_tweets.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"w25/w25_tweets.png\",\n            format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w32_paralympic/w32_paralympic.html",
    "href": "tidytuesday/cases2021/posts2021/w32_paralympic/w32_paralympic.html",
    "title": "Paralympic",
    "section": "",
    "text": "To set the search() function to check the kind of packages installed in the session:\n\nold <- search()\n\n\nlibrary(tidyverse)\n\nlibrary(extrafont)\n# loadfonts() # to do just once at the beginning of the session\n\nLoad this week data:\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 32)\ntidytuesdayR::readme(tuesdata)\nathletes <- tuesdata$athletes\n\n\nnames(athletes)\n\n\nhead(athletes,3)\n\n\nDataExplorer::profile_missing(athletes)\n\nSee the sports for the Paralympic Games: a total of 11 sports takes place with an avg of 8 each four year round 8,9,9,9,10,10,10,10,10,11\n\nathletes %>% filter(year==\"2016\") %>%count(type) %>% arrange(-n)\n\nSee which country “abbreviation” are missing: 49 rows, 1996 Gold 1\n\nathletes %>% filter(is.na(abb)) %>% count(medal)\n\nWhich Country won the Gold medal at the Paralympic in 1996 with Wheelchair Rugby ?\n\nUSA Rugby was the only US “Team Sport” to capture Gold during the 1996 Summer Paralympics.\n\nsource: Wheelchair rugby at the Summer Paralympics\n\nathletes %>% filter(is.na(abb)) %>% count(gender,type,medal,year)%>%arrange(-year)\n\nFill the row with the information above:\n\nid <- row.names(athletes)\n\nathletes <- cbind(id,athletes)\n\nathletes[athletes$id==\"9796\",\"abb\"]<-\"USA\"\n\n\nathletes%>%filter(abb==\"USA\" & year==\"1996\" & medal==\"Gold\",type==\"Rugby\") \n\n\nathletes %>% filter(is.na(abb)) %>% count(id,gender,type,medal,year)%>%count(medal,year)\n\nIn 1980 the USA won 75 Gold medals as well as Poland, while West Germany won just 68 Gold medals.\nsource\nTo see effectively who are the countries who have won the Paralympic and fill the gaps found, the best way is to check it by the year.\n\nathletes %>% filter(year==\"1980\") %>% count(medal,abb==\"USA\")\n\nLoad the Olympic Games data from last TidyTuesday: add the regions data to our dataset to use {ggflag} and add the round shaped flag to our geoms\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 31)\nregions <- tuesdata$regions\n\nSet up the full dataset with some minor changes:\n\nathletes_full <- athletes %>%\n  mutate(gender=case_when(gender==\"Mixed\" ~ \"Mixed team\",\n                          TRUE ~ gender)) %>%\n  inner_join(regions,by=c(\"abb\"=\"NOC\")) %>%\n  select(year,abb,country,region,type,gender,medal,event,athlete) %>%\n  mutate(abb=tolower(abb),country=tolower(country))\n\n\nDataExplorer::profile_missing(athletes_full)\n\nJust a double chek of the “country” vector and then we drop it:\n\nhead(athletes_full,3)\n\n\nathletes_full %>% count(abb,country,region)\n\n\nathletes_full <- athletes_full %>%\n  select(-country) \n\n10 years from 1980 to 2016 of Summer Paralympic Games:\n\nathletes_full %>% count(year)\n\nabb: abbreviation of country region are 112 , while the region vector contains 104 countries.\n\nChina region id divided in “chn” and “hkg”, only hkg has 198 events\nCzech Republic divided in “cze” and “tch”\nGermany divided in “frg”, “gdr”, “ger”\nRussia divided in “rus” and “urs”\nSerbia divided in “scg”, “srb”, “yug”\n\n\nathletes_full %>% count(region,abb)%>%arrange(region)\n\nAdd the {ggflags} package:\n\nlibrary(ggflags)\nlibrary(countrycode)\n\nAssigning a new name to have the athletes_full set as back up:\n\nmy_df <- athletes_full %>% \n  mutate(country_code = countrycode(region, \n            origin = 'country.name', \n            destination = 'iso2c'),\n         country_code = tolower(country_code)) %>%\n  rename(sport=type) %>%\n  select(year,region,sport,medal,country_code) \n\n\nmy_df %>% DataExplorer::profile_missing()\n\nWhat we want is to make a sigmoid network with geom_segment, geom_sigmoid, and geom_flag: to connect the 50+ highest frequency of countries at the Paralympic Games and the same by sports and Gold medals.\nSet the index vectors for each variable to connect with a sigmoid and rebuild a new set:\n\norder_year <- my_df %>%\n  count(year) %>% \n  mutate(index_year = row_number())\n\n\norder_region <- my_df %>%\n  count(region) %>% arrange(-n) %>%\n  mutate(index_region = row_number())\n\norder_sport <- my_df %>%\n  count(sport) %>% arrange(-n) %>%\n  mutate(index_sport = row_number())\n\n\norder_medal <- my_df %>%\n  count(medal) %>% arrange(-n) %>%\n  mutate(index_medal = row_number())\n\n\nmy_df_ordered <- my_df %>%\n  left_join(order_year) %>% select(-n) %>%\n  left_join(order_region) %>% select(-n) %>%\n  left_join(order_sport) %>% select(-n) %>%\n  left_join(order_medal) %>% select(-n) \n\nAdd the groups vectors and select the first 20 regions/countries by the highest frequency:\n\ngold_medal_sports <- my_df_ordered %>%\n  mutate(group = glue::glue(\"{year}-{region}\"),\n         group2 = glue::glue(\"{region}-{sport}\"),\n         group3 = glue::glue(\"{sport}-{medal}\"),\n         group4 = glue::glue(\"{region}-{medal}\"))\n         \n\nfirst_20_regions<- gold_medal_sports %>% \n  count(region) %>% \n  arrange(-n) %>% \n  filter(n>=259) %>% \n  select(-n) %>% \n  unlist()\n\nMake three more dataset for selected sigmoids data:\n\nsig_short <- gold_medal_sports %>% \n  filter(region %in% first_20_regions)# & year==2016)#  & region==c(\"UK\",\"Italy\",\"USA\")) \n\n\nsig_short_gold <- sig_short%>%filter(medal==\"Gold\")\n\n\nsig_short_gold_yr <- sig_short %>% \n  filter(medal==\"Gold\") %>% \n  count(year,region,index_year,index_region,group) %>% \n  arrange(-n) %>%\n  filter(n>=50)\n\n\nsig_short_gold_sport <- sig_short %>% \n  filter(medal==\"Gold\") %>% \n  count(region,sport,index_region,index_sport,group2) %>% \n  arrange(-n) %>%\n  filter(n>=50)\n\n\nlibrary(scales)\nlibrary(ggbump)\nlibrary(extrafont)\nlibrary(showtext)\nlibrary(cowplot)\nlibrary(ggstream)\nlibrary(colorspace) \nlibrary(ggpubr)\n\n## Automatically use showtext to render text for future devices\nshowtext_auto()\n\n## Tell showtext the resolution of the device,\n## only needed for bitmap graphics. Default is 96\nshowtext_opts(dpi = 320)\n\n## Loading Google fonts (https://fonts.google.com/)\n\nfont_add_google(\"Oswald\", \"oswald\")\nfont_add_google(\"Rock Salt\", \"rock\")\nfont_add_google(\"Amatic SC\" , \"amatic\")\n\n\nfont_add_google(\"Share Tech Mono\", \"techmono\")\nfont_add_google(\"Roboto Condensed\", \"roboto condensed\")\nfont_add_google(\"Gochi Hand\", \"gochi\")\nfont_add_google(\"Schoolbell\", \"bell\") # title\nfont_add_google(\"Covered By Your Grace\", \"grace\")\n\n\n\n\n\nbackground <- \"red\"\ntext_color <- \"grey50\"\n\npalette <- c(\"#0286c3\" , lighten(\"#0286c3\" , 0.5)  , \n             \"#fbb22e\" , lighten( \"#fbb22e\" , 0.5) , \n             \"#168c39\" , lighten(\"#168c39\" , 0.5)  ,\n             \"#ee2f4d\" , lighten(\"#ee2f4d\" , 0.5)  )\n\nOlympic Games color palettes: source: palettes\n\ncolor_paralympics <- c(\"#FF0000\",\"#C4161C\",\"#820000\",\"#ec008c\",\"#c40063\",\"#8B0037\",\"#92278F\",\"#6F2C91\",\"#3D1063\",\n                  \"#0095da\",\"#0063A5\",\"#013B82\",\"#39bb9d\",\n                  \"#39bb9d\",\"#00695E\",\"#B2D235\",\"#88ac2e\",\"#28752B\",\n                  \"#ffd400\",\"#e5A812\",\"#B18906\",\"#f7941E\",\n                  \"#E66A1F\",\"#985006\")\n\nMake the sigmoid network:\n\npara_plot <- ggplot(data=sig_short) +\n  \n  geom_text(\n    aes(x = -2.9, y = index_year+5, label = year), vjust=0, hjust=\"left\", color = \"red\", size = 4.5,family = \"oswald\") +\n\n  geom_text(\n    aes(x = -0.65, y = index_region, label = region), vjust=0, hjust=\"center\", color = \"red\", size = 4.5,family = \"oswald\") +\n  \n  geom_text(aes(x = 1.75, y = index_sport+5, label = sport),family = \"oswald\", hjust=\"center\", vjust=0, color = \"red\", size = 4.5) +\n  \n  geom_text(aes(x = 3.25, y = index_medal+10, label = medal),family = \"oswald\", hjust=0, vjust=0, color = \"red\", size = 4.5) +\n  \n  #################\n  # first sigmoid connecting years to regions\n  \n   geom_point(data = sig_short_gold, aes(x = -2.7, y = index_year+5), color = \"gold\", size = 2, inherit.aes = FALSE) +\n  \n  geom_sigmoid(\n     aes(x = -2.7, xend = -1, y = index_year+5, yend =index_region, group=factor(group)), color = \"#DCDCDC\") + \n  \n  geom_point(data = sig_short_gold, aes(x = -1, y = index_region), shape = 21, colour = \"gold\", fill = NA, size = 7, stroke = 1,inherit.aes = FALSE) +\n  \n  geom_sigmoid(data=sig_short_gold_yr,\n     aes(x = -2.7, xend = -1, y = index_year+5, yend =index_region, group=factor(group),color = region)) +\n  \n\n  ggflags::geom_flag(data = sig_short_gold, aes(x = -1, y = index_region, country = country_code), size=4.5) +\n  \n  ggflags::scale_country() +\n  guides(country=\"none\") +\n  \n  \n  #################\n  # second sigmoid to connect regions to sports\n  \n\n  geom_point(data = sig_short_gold, aes(x = -0.4, y = index_region),color = \"gold\", size = 2, inherit.aes = FALSE) +\n  \n  geom_sigmoid(\n     aes(x = -0.4, xend = 1.4, y = index_region, yend =index_sport+5, group=factor(group2)),color = \"#DCDCDC\") +\n  \n  geom_point(data = sig_short_gold, aes(x = 1.4, y = index_sport+5), color = \"gold\", size = 2, inherit.aes = FALSE) +\n  \n  geom_sigmoid(data=sig_short_gold_sport,\n     aes(x = -0.4, xend = 1.4, y = index_region, yend =index_sport+5, group=factor(group2),color = sport)) +\n \n  \n  ################### \n  # third sigmoid to connect sports to medals\n\n\n  geom_point(data = sig_short_gold, aes(x = 2.10, y = index_sport+5), color = \"gold\", size = 2, inherit.aes = FALSE)+\n  \n  geom_sigmoid(\n     aes(x = 2.10, xend = 3.15, y = index_sport+5, yend =index_medal+10, group=factor(group3)),color = \"#DCDCDC\") +\n  \n  geom_point(data = sig_short_gold, aes(x = 3.15, y = index_medal+10, color = medal), shape = 21, colour = \"gold\", fill = NA, size = 7, stroke = 1, inherit.aes = FALSE) +\n\n  geom_sigmoid(data = sig_short_gold,\n     aes(x = 2.10, xend = 3.15, y = index_sport+5, yend =index_medal+10, group=factor(group3), color = sport)) +\n  \n  \n  #####################\n\n  \n  ylim(0,200) +\n  xlim(-5,4) +\n  scale_y_reverse() +\n  scale_color_manual(values = color_paralympics) +\n  theme_void() +\n  theme(plot.background = element_blank(),\n        panel.background = element_blank(),\n        legend.position = \"none\")\n\n\n\nimg_olympics<-\"https://www.pngall.com/wp-content/uploads/2017/05/Olympic-Rings-Download-PNG.png\"\n\nsigmoid <- ggimage::ggbackground(para_plot, img_olympics,alpha=.2, color=\"#CD919E\")\n\n\nfinal <- ggdraw(\n  sigmoid \n  ) + \n  ggtitle(label=\"Paralympic Games: from 1980 to 2016\") +\n  theme_void() +\n  theme(\n    text = element_text(color = text_color , face = \"bold\"),\n    plot.title = element_text(family = \"amatic\" , size = 40 , hjust = 0.24,vjust=2),\n    axis.title = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank(),\n    plot.margin = margin(1,0,1,0, unit = \"cm\"),\n    plot.title.position = \"panel\") +\n  \n    annotate(geom = \"text\" , label = \"Source: Paralympic Medals, IPC, kaggle.com | Graphic: @fgazzelloni\" , x = 0.5 , y = 0 , family = \"rock\" , size = 6) +\n  \n    annotate(\"text\",label=\"The Paralympic Games or Paralympics is the largest international event for disabled athletes \\nand societal change and take place shortly after every Olympic Games in the same host city. \\nThe Paralympic Games are held every two years\", size=2.5,x = 0.78, y = 0.97,family=\"rock\") +\n    \n   annotate(\"text\",label=\"In 1980 the USA won 75 Gold medals \\nas well as Poland, while\\n West Germany won just 68 Gold medals.\", size=3,x = 0.14, y = 0.6,family=\"rock\") + \n    \n   annotate(\"text\",label=\"Which Country won the Gold medal at the Paralympic \\nin 1996 with Wheelchair Rugby ?\\nUSA Rugby was the only US “Team Sport” to capture \\nGold during the 1996 Summer Paralympics.\", size=3,x = 0.15, y = 0.2,family=\"rock\") +\n  \n   annotate(\"text\",label=\"Sigmoid network of the years, countries, sports and medals\", size=3,x = 0.8, y = 0.1,family=\"rock\") +\n  \n   annotate(\"text\",label=\"Countries with the highest frequency in participation\", size=3,x = 0.23, y =0.9,family=\"rock\") +\n  \n# annotate images\ndraw_image(image = (\"Olympic-Torch-PNG-Free-Download.png\"),\n             #\"https://www.pngall.com/wp-content/uploads/2017/05/Olympic-Rings-Download-PNG.png\",\n           x = -0.05 , y = 0.65 , height = 0.45 , width = 0.25) +\n  draw_image(image = \"https://camo.githubusercontent.com/1411a00ca19fc49c4b0099d26246d261baafd979a76c007ae835984f8c1ae3d2/68747470733a2f2f7777772e706172616c796d7069632e6f72672f73697465732f64656661756c742f66696c65732f7374796c65732f6c617267655f6f726967696e616c2f7075626c69632f323031392d31302f4950432532304e4557253230454d424c454d2e4a50473f69746f6b3d5f46534a62623651\",\n           x = 0.55 , y = 0.78 , height = 0.08 , width = 0.25)\n\n\nragg::agg_png(\"w32_paralympic.png\",\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\ntidy_final <- image_read(\"w32_paralympic.png\")\n\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"w32_paralympic.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w14_the_pudding/w14_the_pudding.html",
    "href": "tidytuesday/cases2021/posts2021/w14_the_pudding/w14_the_pudding.html",
    "title": "The Pudding",
    "section": "",
    "text": "Load libraries\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggtext)\nlibrary(scales)\nlibrary(extrafont)\nlibrary(patchwork)\nlibrary(cowplot)\nlibrary(ragg)\nlibrary(rmarkdown)\nlibrary(hrbrthemes)\nlibrary(wesanderson)\n\nLoad Datasets\n\nsephora <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-30/sephora.csv')\nulta <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-30/ulta.csv')\n\nallCategories <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-30/allCategories.csv')\nallShades <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-30/allShades.csv')\nallNumbers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-30/allNumbers.csv')\n\nLoad fonts\n\nloadfonts()\nfont_add_google(name = \"Amatic SC\", family = \"amatic-sc\")\nfont_add_google(\"Cedarville Cursive\", \"cedarville\")\n\nshowtext_auto(enable = TRUE)\n\npalette <- c(\"#FF0000\",\"#FF7070\",\"#F09200\",\"#FFBF1F\",\"#00A08A\",\"#2989A3\",\"#5BBCD6\",\"#A475D9\")\n\nManipulation of data\n\nsephora_sub<-sephora%>%\n  mutate(shop=rep(\"sephora\",length(brand)),\n         brand=tolower(brand),\n         product=tolower(product),\n         name=tolower(name))%>%\n  select(brand,product,name)\n\nulta_sub<-ulta%>%\n  mutate(shop=rep(\"ulta\",length(brand)),\n         brand=tolower(brand),\n         product=tolower(product),\n         name=tolower(name))%>%\n  select(brand,product,name)\n\n\nshops<-rbind(sephora_sub,ulta_sub)\n\nManipulation of data\n\nallCategories_sub<-allCategories%>%\n  mutate(brand=tolower(brand),\n         product=tolower(product),\n         name=tolower(name))%>%\n  separate_rows(categories, convert = TRUE) %>%\n  mutate(categories = fct_reorder(categories, lightness))  %>%\n  select(brand,product,name,hex,lightness,categories)\n\nallShades_sub<-allShades%>%\n  mutate(brand=tolower(brand),\n         product=tolower(product),\n         name=tolower(name))%>%\n  select(brand,product,name,hex,hue,sat,lightness)\n\nallNumbers_sub<-allNumbers%>%\n  mutate(brand=tolower(brand),\n         product=tolower(product),\n         name=tolower(name))%>%\n  select(brand,product,name,hex,lightness,lightToDark)\n\n################### Full Join of the datasets ##############\n\nmake_up<-full_join(allCategories_sub,\n                   allShades_sub,by.x=hex,by.y=lightness)\nmake_up<-full_join(make_up,\n                   allNumbers_sub,by.x=hex,by.y=lightness)\n\nmake_up_sub<-make_up%>%\n  select(brand,name,hex,hue,sat,lightness)%>%\n  filter(!is.na(hue))%>%\n  arrange(hex)\n\nCounting uniqueness\n\nplyr::count(make_up$brand); #107\nplyr::count(make_up$product);#328\nplyr::count(make_up$name);#1,317\nplyr::count(allCategories_sub$categories)#17\n\nSelection of data for making plots\n\nmy_companies <- sort(c(\"shiseido\",\"maybelline\",\"mac\",\"lancôme\",\"l'oréal\",\"guerlain\",\"estée lauder\",\"clinique\",\"benefit cosmetics\"), decreasing = TRUE)\n\nmake_up_for_plot <- make_up_sub %>%\n  filter(brand %in% my_companies) %>%\n  select(brand, name,hex, hue,sat,lightness) %>%\n  mutate(brand=as.factor(brand)) %>%\n  group_by(brand) %>%\n  mutate(mean_lightness = mean(lightness)) %>%\n  ungroup() %>%\n  mutate(brand = fct_reorder(brand, mean_lightness))\n\n\nlibrary(ggfx)\nlibrary(gridExtra)\n\n\nplot1<-make_up_for_plot%>%\n  ggplot(aes(brand,lightness,col=hex)) + \n  with_blur(\n    geom_boxplot(size=5,show.legend = FALSE)) + \n  geom_jitter(width = 0.15,height = 0.0,size = 1) + \n  scale_colour_identity() + \n  coord_polar() + \n  labs(title = \"Shades of makeup from The Pudding\",\n       subtitle = \"All collected from the US versions of Sephora and Ulta’s websites\",\n       caption = \"107 brands, 328 products, 317 names and 17 categories\",\n       tag = \"The Pudding\",\n       x = \"Lightness\",\n       y = \"Brands)\",\n       colour = \"white\")+\n  theme_void(base_family = \"cedarville\") + \n  theme(plot.background = element_rect(fill = \"black\",color=\"black\"),\n        axis.text.x = element_text(size = 30, vjust = 2,color=\"white\"),\n        plot.title = element_text(size = 56,hjust = 0.5,color=\"white\"),\n        plot.subtitle = element_text(size = 46,hjust = 0.5,color=\"white\"),\n        plot.caption = element_text(size = 36,hjust = 0.5, \n                                    margin = margin(t = 5, b = 10),color=\"white\"),\n        plot.tag = element_text()\n        )\n          \n\nplot2<-make_up_for_plot%>%\n  ggplot(aes(brand,lightness,col=hex)) + \n  with_blur(\n    geom_point(show.legend = FALSE)) + \n  geom_jitter(width = 0.15,height = 0.0,size = 2) + \n  scale_colour_identity() +\n  coord_polar(direction=1) +\n  theme_void() + \n  theme(plot.background = element_rect(fill = \"black\")) + \n  facet_wrap(vars(brand))\n\nFinal plot\n\nlibrary(ggimage)\nrequire(magick)\n\n\nmain_plot <- plot1 + plot2\n\nfinal <- main_plot + \n  labs(title = \"Makeup - The naked truth\",\n       subtitle = \"combination for naming their shades\",\n       caption = \"TidyTuesday W14 - The Pudding - Viz - @fgazzelloni\") + \n  scale_fill_manual(values = palette,\n                    guide = guide_legend(title = NULL)) + \n  theme_void(base_family = \"cedarville\") + \n  theme(plot.background = element_rect(fill = \"#FCEBDA\",color = NA),\n        strip.text.x = element_text(color = NA),\n        axis.text.x = element_text(size = 20, vjust = 2),\n        panel.grid.major = element_line(size = 0.03, linetype = 'solid',colour = \"black\"),\n        plot.margin = margin(10, 10, 5, 10),\n        plot.title = element_text(size = 56,hjust = 0.5, margin = margin(t = 5, b = 10)),\n        plot.subtitle = element_text(size = 40,hjust = 0.5),\n        plot.caption = element_text(hjust = 0.5, size = 26))\n\nSave the plot in a .png file\n\nragg::agg_png(here::here(\"w14_the_pudding\", \"w14_the_pudding.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\nRead the image, attach the Tidytuesday logo and save it\n\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nThe_Pudding_plot <- image_read(here::here(\"w14_the_pudding/w14_the_pudding.png\"))\n\nattached_logo <- image_composite(The_Pudding_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"southeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, \n            path = \"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w14_the_pudding/w14_the_pudding.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w13_UN_votes/w13_UN_votes.html",
    "href": "tidytuesday/cases2021/posts2021/w13_UN_votes/w13_UN_votes.html",
    "title": "UN Votes",
    "section": "",
    "text": "Libraries\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(tidytuesdayR)\nlibrary(ggplot2)\n\nlibrary(showtext)\nfont_add_google(\"Share Tech Mono\", \"techmono\")\nshowtext_opts(dpi = 320)\nshowtext_auto(enable = FALSE)\n\nGet data\n\nunvotes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-23/unvotes.csv')\nroll_calls <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-23/roll_calls.csv')\nissues <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-23/issues.csv')\n\nUNvotes_full and UNvotes_sub\n\nunvotes_full <- unvotes %>%\n  inner_join(un_roll_calls, by = \"rcid\") %>%\n  inner_join(un_roll_call_issues, by = \"rcid\")\n\nunvotes_sub <- unvotes_full%>%\n  select(date,country,session,vote,issue)\n\nUN Countries\n\ngerman<-unvotes_full%>%filter(str_detect(country, \"Germ\"))\n#table(german$country)\ncongo<-unvotes_full%>%filter(str_detect(country, \"Congo\"))\n#table(congo$country)\nyemen<-unvotes_full%>%filter(str_detect(country, \"Yemen\"))\n#table(yemen$country)\nguinea<-unvotes_full%>%filter(str_detect(country, \"Guinea\"))\n#table(guinea$country)\n\nunvotes_merged_country_names<-unvotes_sub%>%\n  mutate(country=case_when(country==\"Federal Republic of Germany\"~\"Germany\",\n                           country==\"German Democratic Republic\"~\"Germany\",\n                           country==\"Congo - Brazzaville\"~\"Congo\",\n                           country==\"Congo - Kinshasa\"~\"Congo\",\n                           country==\"Micronesia (Federated States of)\"~\"Micronesia\",\n                           country==\"Myanmar (Burma)\"~\"Myanmar\",\n                           country==\"Yemen Arab Republic\"~\"Yemen\",\n                           country==\"Yemen People's Republic\"~\"Yemen\",\n                           country==\"Guinea-Bissau\"~\"Giunea\",\n                           TRUE~country))%>%\n  select(date,country,vote,issue) %>%\n  arrange(date)\n\nby_country_year\n\nby_country_year <- unvotes_merged_country_names %>%\n  group_by(year = year(date), country) %>%\n  summarize(issue,votes = n(),\n            percent_yes = round(mean(vote == \"yes\")*100,1),\n            percent_no = round(mean(vote == \"no\")*100,1),\n            percent_astain = round(mean(vote == \"abstain\")*100,1))\n\nVisualization\n\nlibrary(graphics)\nbck_color <- \"#FEFCEF\"\nmain_plot<-ggplot(data=by_country_year,\n                  aes(x=year,y=votes,col=votes))+\n  geom_line()+\n  geom_point()+\n  scale_x_continuous(breaks=seq(1946,2019,10))+\n  \n  theme_void()+\n  theme(axis.text.x=element_text(color=bck_color))\n\nUN background image\n\nlibrary(ggimage)\n\n\nUN_img=\"https://camo.githubusercontent.com/654fb54c78403255bbe1457b6a75423f5e370ee075eab4db0a189b886b68b8d7/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f652f65652f554e5f656d626c656d5f626c75652e7376672f3132303570782d554e5f656d626c656d5f626c75652e706e67\"\n\ng<-ggbackground(main_plot, UN_img, alpha=.7,color=\"#94BCFF\")\n\nFinal plot annotations\n\nshowtext_auto(enable = TRUE)\nlibrary(patchwork)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(magick)\nlibrary(grid)\nlibrary(png)\n\nfinal <- g + plot_annotation(\n    title = \"UN Votes from 1946 to 2019\",\n    subtitle=\"on six issues: Colonialism,Arms control and disarmament,Economic development,Human rights,Palestinian conflict Nuclear weapons and nuclear material\",\n    caption = \"Visualization: Federica Gazzelloni | Data: Harvards' UN votes\",\n    theme = theme(\n      plot.margin = margin(10,10,10,10),\n      plot.background = element_rect(fill = bck_color, color = NA),\n      plot.caption = element_text(family = \"techmono\", size = 9, color = bck_color, margin = margin(15,0,0,0), hjust = 0.95)\n    )\n  )\n\nragg::agg_png(here::here(\"render\", paste0(\"UN_votes_\",\n                                          format(Sys.time(),\n                                                 \"%Y%m%d_%H%M%S\"),\n                                          \".png\")),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\nRead the image, attach the Tidytuesday logo and save it\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nUN_votes_plot <- image_read(\"~/R/Projects/TidyTuesday/render/UN_votes_20210326_201814.png\")\n\nattached_logo <- image_composite(UN_votes_plot, tidy_logo,\n                                 #offset = \"0+0\",\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"~/R/Projects/TidyTuesday/render/UN_votes_W13.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w19_water_access/w19_water_access.html",
    "href": "tidytuesday/cases2021/posts2021/w19_water_access/w19_water_access.html",
    "title": "Water Access",
    "section": "",
    "text": "Week 19 Water————\n\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(raster)\nlibrary(spData) # spatial data\nlibrary(spDataLarge)\nlibrary(tmap)    # for static and interactive maps\nlibrary(leaflet) # for interactive maps\n\n\n# loading data --------------------------\ntuesdata <- tidytuesdayR::tt_load(2021, week = 19)\n\n# manipulation ---------------\nwater <- tuesdata$water\nwater$water_source[is.na(water$water_source)] <- \"unknown\"\nwater_df<-water%>%\n  arrange(row_id)%>%\n  clean_names()%>%\n  mutate(report_date=format(as.Date(report_date,\"%m/%d/%Y\")),\n         report_date=as.Date(report_date),\n         water_source=as.factor(water_source),\n         status_id=as.factor(status_id))%>%\n  select(1:6,9)\n\n# loading africa -------------------\nworld_africa = world[world$continent == \"Africa\", ]\nafrica = st_union(world_africa)\n\n# plotting --------------------\nlibrary(extrafont)\nlibrary(patchwork)\n\nwater_plot<-ggplot() +  \n  geom_sf(data = africa) +\n  geom_point(data = water_df,\n             aes(x=lon_deg,y=lat_deg,color=country_name),\n             alpha=0.5) +\n  labs(title=\"Africa source of water by country\",\n       subtitle=\"\",\n       caption=\"Viz. Federica Gazzelloni DataSource: Water Access Points, WPDX TidyTuesday week 19\")+\n  theme_ps()+\n  theme(legend.position = \"none\",\n        plot.margin = margin(5,5,5,5),\n        plot.title = element_text(size=24,family=\"xkcd\",vjust=-2),\n        plot.caption = element_text(size=8,family=\"xkcd\",hjust = 0.5,vjust=-2))\n\n\n# background ---------\nlibrary(ggimage)\n\n\nimage<-\"frame.png\"\n\nfinal_plot<-ggbackground(water_plot, image, alpha=.7,color=\"#94BCFF\")\n\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"tidytuesday_Water.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()\n\n\n\n#### ATTACHING LOGO ############################ \nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo<-image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\n\nfinal_plot <- image_read(\"W19/tidytuesday_Water.png\")\n\nattached_logo <- image_composite(final_plot, tidy_logo,\n                                 operator=\"atop\",\n                                 gravity=\"northeast\") # tell R where to put the logo\n\n\nimage_write(attached_logo, path = \"tidytuesday_Water.png\", format = \"png\") # save final plot"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w40_NBER_papers/w40_NBER_papers.html",
    "href": "tidytuesday/cases2021/posts2021/w40_NBER_papers/w40_NBER_papers.html",
    "title": "NBER Papers",
    "section": "",
    "text": "Title: “TidyTuesday Week 40 - NBER Programs Category”\n\n\nAuthor: “Federica Gazzelloni”\n\n\nDate: “9/30/2021”\n\n\nDatasource: https://www.nber.org/\n\n#----Libraries----\n# Load the libraries\nlibrary(tidyverse)\nlibrary(tidymodels)\ntidymodels_prefer()\n#library(nberwp)\nlibrary(extrafont)\n#fonts()\nlibrary(RColorBrewer)\nlibrary(patchwork)\n\n#----Load Data----\n# TidyTuesday week40 datasets\npapers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/papers.csv')\nauthors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/authors.csv')\nprograms <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/programs.csv')\npaper_authors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/paper_authors.csv')\npaper_programs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-09-28/paper_programs.csv')\n\n#----Data Wrangling----\n# Joining sets\nauthors <- authors %>% select(author,name)\nprograms <- programs %>% drop_na()\n\ndf <- papers %>%  #count(paper)                # 29434     4\n  inner_join(paper_authors, by =\"paper\") %>%   # 67090     2\n  full_join(paper_programs, by = \"paper\") %>%  # 53996     2\n  inner_join(authors, by = \"author\") %>%       # 15437     2\n  full_join(programs, by = \"program\") %>%      #    20     3\n  drop_na() \n\n# Make a dataframe with programs category and proportions\ndf_cat <- df %>%\n  count(program_desc,program_category,sort=T) %>%\n  mutate(prop = n/sum(n)*100) %>%\n  pivot_wider(names_from = program_category, values_from = program_desc)\n\ndf_cat\n\n# Set the data ready to use in the plot function\n\ndf_plot <- df %>% count(year,program_category,program_desc) \n\nplot_fin_df <- df_plot %>% filter(program_category == \"Finance\")\nplot_mic_df <- df_plot %>% filter(program_category == \"Micro\")\nplot_mac_df <- df_plot %>% filter(program_category == \"Macro/International\")\n\n#----Plot features----\n# Set all the specifications for the plot function to build\n# Make three tibbles as to be used in the legends\nleg_fin <- tibble(\"Finance\"=paste(df_cat$Finance,\"-\",round(df_cat$prop,2),\"%\"))%>%filter(!str_detect(Finance,\"NA\"))\nleg_mic <- tibble(\"Micro\"=paste(df_cat$Micro, \"-\",round(df_cat$prop,2),\"%\"))%>%filter(!str_detect(Micro,\"NA\"))\nleg_mac <- tibble(\"Macro/International\"=paste(df_cat$`Macro/International`,\"-\",round(df_cat$prop,2),\"%\"))%>%filter(!str_detect(`Macro/International`,\"NA\"))\n\nleg_fin;leg_mic;leg_mac\n\n#Set the `color` option for the plot function\nrequire(RColorBrewer)\n# color\ncut_colors1 <- setNames(brewer.pal(2, \"Set1\"), levels(plot_fin_df$program_desc))\ncut_colors2 <- setNames(brewer.pal(4, \"Paired\"), levels(plot_mac_df$program_desc))\ncut_colors3 <- setNames(c(brewer.pal(name = \"Set3\", n = 12), brewer.pal(name = \"Pastel1\", n = 2)), levels(plot_mic_df$program_desc))\n\n# Unlist legends-dataframe to be used in the legends\n# leg_lab\nleg_fin <- unlist(leg_fin$Finance)\nleg_mac <- unlist(leg_mac$`Macro/International`)\nleg_mic <- unlist(leg_mic$Micro)\n\n# leg_pos  \nset1 = c(0.73,0.78)\nset2 = c(0.7,0.8)\nset3 = c(0.55,0.8)\n\n#----ggcombo-------\n# Make a `ggcombo()` plot building a function for plotting the program categories\n\nggcombo <- function(data1,data2,data3){\n  \n  ggbar_cat <- function(data,leg_pos,leg_lab,leg_col,color){\n    \n    data %>%\n      ggplot(aes(x = year,y = n,group = program_desc,fill = program_desc)) +\n      geom_col() +\n      facet_wrap(vars(program_category), ncol = 1, strip.position = \"right\") +\n      \n      scale_fill_manual(values = color, label = leg_lab, name = paste(data[[1,2]],\"category Impact proportion\")) +\n      scale_y_continuous(position = \"right\") +\n      guides(fill = guide_legend(ncol = leg_col,title.position = \"top\", title.hjust = 0.5)) +\n      ggthemes::theme_fivethirtyeight() +\n      theme(text = element_text(family = \"Roboto Condensed\"),\n            axis.text.x = element_text(face = \"bold\",size = 8),\n            axis.text.y = element_text(),\n            legend.text = element_text(size = 8),\n            legend.key.size = unit(0.3, 'cm'),\n            legend.title = element_text(face = \"bold\"),\n            \n            legend.position = leg_pos,\n            legend.background = element_blank(),\n            strip.placement = \"outside\",\n            strip.text = element_text(face = \"bold\",size = 14))\n  }\n  \n  plot_fin <- ggbar_cat(data1,set1,leg_fin,1,cut_colors1)\n  plot_mac <- ggbar_cat(data2,set2,leg_mac,1,cut_colors2)\n  plot_mic <- ggbar_cat(data3,set3,leg_mic,2,cut_colors3)\n  \n  require(patchwork)\n  plot_fin <- plot_fin +\n    labs(title = \"\\n\",subtitle = \"\\n\")\n  \n  plot_fin/plot_mac/plot_mic\n}\n\n\n# Assign a name to the ggcombo \nplot <- ggcombo(plot_fin_df,plot_mac_df,plot_mic_df)\n\n\n#----Pie chart----\n# Make a pie_chart logo\npie_colors <- brewer.pal(name = \"Set2\", n = 3)\n\npie_df <- df %>%\n  count(program_desc,program_category,sort = T) %>%\n  mutate(prop = n/sum(n)*100)\n\npar_prop <- pie_df %>%\n  group_by(program_category) %>%\n  summarize(par_prop = round(sum(prop),0))\n\npie_plot <- pie_df %>%\n  left_join(par_prop,by = \"program_category\") %>%\n  ggplot(aes(x = \"\", y = prop, fill = program_category)) +\n  geom_col(width = 1, stat = \"identity\") +\n  scale_fill_manual(values = pie_colors,name = \"NBER Programs Category\") +\n  guides(fill = guide_legend(ncol = 1,title.position = \"top\", title.hjust = 0.5)) +\n  ggthemes::theme_fivethirtyeight() +\n  theme(text = element_text(family = \"Roboto Condensed\"),\n        panel.grid = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text = element_blank(),\n        legend.text = element_text(size = 14),\n        legend.key.size = unit(0.5, 'cm'),\n        legend.title = element_text(face = \"bold\",size = 16),\n        legend.position = \"none\",#c(0.21,0.9),\n        legend.background = element_blank(),\n        strip.placement = \"outside\") +\n  annotate(geom = \"text\", label = \"Micro\\n62%\", x = 1.1, y = 20, colour = \"grey20\", size = 14, family = \"Roboto Condensed\") +\n  annotate(geom = \"text\", label = \"Macro\\n28%\", x = 1.2, y = 80, colour = \"grey20\",size = 14, family = \"Roboto Condensed\") +\n  annotate(geom = \"text\", label = \"Finance\\n10%\", x = 1.2, y = 95, colour = \"grey20\", size = 11,family = \"Roboto Condensed\") +\n  coord_polar(\"y\", start = 0) \n\n# save the pie_chart_logo\nragg::agg_png(here::here(\"w40/w40_pie_ep.png\"),\n              res = 320, width = 8, height = 8, units = \"in\")\npie_plot\ndev.off()  \n\n#----Annotations----\n# Annotate the figure first with adding top and bottom information to have it framed with `ggarrange()`\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\nlibrary(ggpubr)\n\ngraphics <- ggarrange(plot)\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"NBER National Bureau of Economic Research\",\n                                              color = c(\"grey28\"), face = \"bold\", size = 34,\n                                              family = \"Roboto Condensed\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: NBER - TidyTuesday week40\\n\",\n                                                 color = \"grey28\",family = \"Roboto Condensed\",\n                                                 hjust = 0.5, x = 0.58, face = \"bold.italic\", size = 16)\n)\n\n\n# Finally, add some other extra information with more annotations\nlibrary(gridExtra)\n\nfinal_plot <-\n  final_plot +\n  \n  annotate(geom = 'segment',y = 0.87, yend = 0.93, x = 0.9,xend = 0.9, color = \"#1E90FF\", size = 10) +\n  \n  annotate(geom = \"text\", label = \"All three Program Categories reached the top level in 2020 with \n           the highest number of paper publications due to Covid19\",\n           x = 0.58, y = 0.90,colour = \"grey20\",size = 6,family = \"Roboto Condensed\",fontface = \"bold\") +\n  \n  annotate(geom = \"text\", label = \"Finance topic started in 1978 \n           but with lack of success since late 1990 \n           when started its continuous growth\",\n           x = 0.25, y = 0.7,colour = \"grey20\",size = 5,family = \"Roboto Condensed\") +\n  \n  annotate(geom = \"text\", label = \"Macro/International topic started in 1975 \n           reaching the highest level among the other \n           categories, after the first decrease in early 1990 decade, \n           most probably for the increased interest in other topics, \n           maintained a steady growth along the years\",\n           x = 0.28, y = 0.5,colour = \"grey20\",size = 4,family = \"Roboto Condensed\") +\n  \n  annotate(geom = \"text\", label = \"Micro topic is the most varied one, \n           and maintained little but steady increase \n           along the whole period\",\n           x = 0.24, y = 0.15,colour = \"grey20\",size = 5,family = \"Roboto Condensed\") \n\n#----Logos----\n# add the logos \nimg_pie <- image_read(here::here(\"w40_NBER_papers/pie_ep.png\"))\nimglogo <- image_read(here::here(\"w40_NBER_papers/nber-logo.png\"))\n\nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(img_pie, x = 0.05, y = 0.35,width = 0.22) +\n  draw_image(imglogo, x = 0.01, y = -0.48,width = 0.2)\n\n\n#----Save final plot----\nragg::agg_png(here::here(\"w40_NBER_papers/w40_NBER_papers.png\"),\n              res = 320, width = 10, height = 12, units = \"in\")\nfinal\ndev.off()\n\n#----Tidytuesday logo----\n# read the image, attach the Tidytuesday logo and save it\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\ntidy_final <- image_read(here::here(\"w40_NBER_papers/w40_NBER_papers.png\"))\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator = \"atop\",\n                                 gravity = \"southeast\")\n\nimage_write(attached_logo, path = \"w40_NBER_papers.png\", format = \"png\")"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w37_formula1/w37_formula1.html",
    "href": "tidytuesday/cases2021/posts2021/w37_formula1/w37_formula1.html",
    "title": "FORMULA1",
    "section": "",
    "text": "TidyTuesday Week37 - FORMULA1\n\nlibrary(tidyverse)\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 37)\n\nresults <- tuesdata$results\nqualifying <- tuesdata$qualifying\nconstructors <- tuesdata$constructors\ndrivers <- tuesdata$drivers\n\n\nmy_df <- qualifying%>%\n  left_join(results%>%select(raceId,driverId,constructorId,points), by=c(\"raceId\",\"driverId\",\"constructorId\")) %>%\n  left_join(constructors,by=\"constructorId\") %>%\n  left_join(drivers%>%select(driverId,forename,surname),by=\"driverId\") %>%\n  count(qualifyId,raceId,driverId,forename,surname,constructorId,name,number,position,points,sort=T) %>%\n  unite(\"driver_name\",forename:surname,sep=\" \",remove=TRUE) %>%\n  count(driverId,driver_name,constructorId,name,number,position,points)%>%\n  arrange(position,-number,-points) %>%\n  filter(position<=10)\n\n\nrank_df<- my_df%>%\n  group_by(name,position)%>%\n  summarize(total=sum(points),.groups=\"drop\")%>%\n  ungroup()%>%\n  arrange(position) %>%\n  pivot_wider(values_from = total,names_from=position)\n\nrank_df[is.na(rank_df)]<-0\n\n\n# rank_df <- column_to_rownames(rank_df,var = \"driver_name\")\n\nrank_df\n\n#library(ggbump)\nlibrary(ggrepel)\nlibrary(extrafont)\n#fonts()\n\nrank_df_long <- rank_df %>%arrange(-`1`)%>% slice(1:10)%>%\n  pivot_longer(cols = 2:11,names_to=\"position\",values_to=\"points\")%>%\n  mutate(position=as.numeric(position),\n         position=factor(position))\n\nsummary_first_position <- rank_df_long%>%filter(name==c(\"Mercedes\",\"Red Bull\",\"Ferrari\"))%>%filter(position==1)%>%summary()\n\nlibrary(hrbrthemes)\nlibrary(GGally)\nlibrary(viridis)\n\ncolors <- c(\"#0EED4D\", \"#008B00\", \"#17B6EB\",\n            \"#C00000\" , \"#FF8700\", \"#00D2BE\",\n            \"#0600EF\", \"#FFF500\", \"#E68C17\", \"#0082FA\")\n\ncolors2 <- c(\"grey70\", \"grey70\", \"grey70\",\n            \"#C00000\" , \"#FF8700\", \"#00D2BE\",\n            \"#0600EF\", \"grey70\", \"grey70\", \"grey70\")\n\n\nplot <- rank_df_long%>%\n  ggplot(aes(x=fct_reorder(position,-position),y=points,group=name,color=factor(name)))+\n  geom_point(aes(size=points),shape = 21, fill = \"white\",  stroke = 5)+\n  geom_line(size=2)+\n  scale_color_manual(values = colors2)+\n  labs(y=\"Points\",x=\"Positions\",\n       color=\"Top 10 Constructors\",size=\"Points\")+\n  theme_gray()+\n  theme(text = element_text(family=\"Impact\",color=\"grey90\"),\n        plot.margin = margin(1,1,1,1,unit = \"pt\"),\n        panel.grid.major.y = element_line(size=2),\n        panel.background = element_rect(color=\"grey20\",fill=\"grey20\"),\n        plot.background = element_rect(color=\"grey20\",fill=\"grey20\"),\n        legend.key = element_blank(),\n        legend.background = element_blank(),\n        legend.text = element_text(color=\"grey90\",size=14),\n        legend.title = element_text(color=\"grey90\",size=14),\n        axis.text = element_text(color=\"grey90\"),\n        axis.title = element_text(size=14),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.y = element_blank()\n  )\n\n\nlibrary(ggpubr)\ngraphics <- ggarrange(plot)+\n  theme(plot.background = element_rect(fill=\"#228B22\", color = NA))\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"FORMULA 1 WINNER CONSTRUCTORS\",\n                                              color = c(\"red\"), face = \"bold\", size = 45,\n                                              family = \"Impact\"),\n                              bottom = text_grob(\"Infographics Federica Gazzelloni DataSource: Ergast API, TidyTuesday week37\",\n                                                 color = \"black\",family = \"Impact\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 20),\n                              left = text_grob(\"FORMULA 1\", color = c(\"#778899\"), rot = 90,size = 30),\n                              right = text_grob(bquote(\"FORMULA1\"), color = c(\"#778899\"),rot = 90,size = 30),\n                              fig.lab = \"TidyTuesday week37\", fig.lab.face = \"bold.italic\",fig.lab.size = 12,\n                              fig.lab.pos = \"bottom.right\"\n)\n\n\n\nfinal_plot <-\n  final_plot +\n\n  annotate(geom = \"text\", label = \"Lewis Hamilton\\nNico Rosberg\\n Valtteri Bottas \\n- Mercedes\",\n           x = 0.11, y = 0.85,colour = \"#00D2BE\",size = 4,family = \"Impact\") +\n  annotate(geom = \"curve\", x = 0.07, xend = 0.09, y = 0.85, yend = 0.76, colour = \"#00D2BE\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"Impact\",size=1.5) +\n\n  annotate(geom = \"text\", label = \"Sebastian Vettel\\nMark Webber\\nMax Verstappen - Red Bull\",\n           x = 0.23, y = 0.49,colour = \"#0600EF\",size = 4.5,family = \"Impact\") +\n  annotate(geom = \"curve\", x = 0.25, xend = 0.28, y = 0.53, yend = 0.69, colour = \"#0600EF\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Impact\",size=1.5) +\n\n  annotate(geom = \"text\", label = \"Charles Leclerc\\nFernando Alonso\\n - Ferrari\",\n           x = 0.1, y = 0.63,colour = \"#C00000\",size = 4,family = \"Impact\") +\n  annotate(geom = \"curve\", x = 0.09, xend = 0.10, y = 0.67, yend = 0.70, colour = \"#C00000\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Impact\",size=1.5) +\n\n  annotate(geom = \"text\", label = \"F1\",x = 0.85, y = 0.88, colour = \"red\", size = 5,family = \"Impact\") +\n\n  annotate(geom = \"text\", label = \"MERCEDES, RED BULL and FERRARI\\n reached the higest level of points\\n at being number one\\nwith an average of 418.8 points\",x = 0.7, y = 0.81, colour = \"white\", size = 7,family = \"Impact\")+\n\n\n  annotate(geom = \"text\", label = \"Lewis Hamilton - McLaren\",x = 0.7, y = 0.53, colour = \"#FF8700\", size = 5,family = \"Impact\") +\n  annotate(geom = \"curve\", x = 0.68, xend = 0.64, y = 0.52, yend = 0.41, colour = \"#FF7F00\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"Impact\",size=1.5)\n\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\n\n\nlogo_f1_img <- image_read(here::here(\"w37/F1.svg.png\"))\n\n\nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(logo_f1_img, x = 0.1, y = 0.47,width = 0.12)\n\n\n\n## Save final plot ----\n\nragg::agg_png(here::here(\"w37/formula1_second_version.png\"),\n              res = 320, width = 16, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w52_starbucks/w52_strabucks.html",
    "href": "tidytuesday/cases2021/posts2021/w52_starbucks/w52_strabucks.html",
    "title": "Starbucks drinks",
    "section": "",
    "text": "library(tidyverse)\n\nstarbucks <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-12-21/starbucks.csv')\n\n\nhead(starbucks)\n\n\nmy_coffee<-starbucks%>%count(product_name,sort=T)%>%slice(1:10)%>%select(-n)%>%unlist()\n\n\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=110)\nlibrary(sysfonts)\nfont_add_google(name =\"Black Han Sans\" ,family = \"my_font\")\nfont_add_google(name =\"Odibee Sans\" ,family = \"my_font1\")\n\nfamily = \"my_font\"\nfamily1 = \"my_font1\"\n\n\nimage <- \"w52/cup.png\"\n\ndata<- starbucks%>%\n  mutate(trans_fat_g=as.numeric(trans_fat_g),fiber_g=as.numeric(fiber_g))%>%\n  select(-size,-milk,-serv_size_m_l)%>%\n  filter(product_name%in%my_coffee)%>%\n  arrange(product_name)%>%\n  mutate(product_name =fct_reorder(product_name,-calories)) %>%\n  group_by(product_name)%>%\n  summarise_all(.funs = mean)%>%\n  ungroup()%>%\n  tibble::column_to_rownames(\"product_name\")%>%\n  as.matrix()%>%\n  scale()%>%\n  as.data.frame()%>% \n  rownames_to_column()%>%\n  rename(product=rowname)%>%\n  mutate(product=as.factor(product))%>%\n  pivot_longer(cols=-product,names_to=\"names\",values_to=\"values\")%>%\n  mutate(names=gsub(\"_g|_mg\",\"\",names),\n         names=gsub(\"_\",\" \",names),\n         names=gsub(\"total \",\"\",names))%>%\n  mutate(names=ifelse(names==\"saturated fat\",yes = \"satur fat\",no = names))%>%\n  mutate(names=tools::toTitleCase(names),\n         values=round(values,5))%>%\n  mutate(img = image)%>%\n  group_by(product)%>%\n  mutate(values2 =ifelse(values==max(values),values,NA),\n         values3 =ifelse(values==min(values),values,NA))%>%\n  ungroup()%>%\n  mutate(imagemax=ifelse(!is.na(values2),img,NA),\n         imagemin=ifelse(!is.na(values3),img,NA))\n\nlibrary(RColorBrewer)\n  my_hmap<- data%>%\n    ggplot(mapping=aes(x=fct_reorder(names,values),y=fct_reorder(product,values),\n           fill=factor(values)))+\n  geom_tile(show.legend = F) +\n  ggimage::geom_image(aes(image=imagemax,scale=values),\n                      asp = 1.5, size = 0.1, by = \"width\") +\n  ggimage::geom_image(aes(image=imagemin,scale=values),\n                      asp = 1.5, size = 0.1, by = \"width\") +\n  labs(title=\" \")+\n  scale_fill_manual(values=colorRampPalette(brewer.pal(5, \"BrBG\"))(98))+\n  scale_color_manual(values=colorRampPalette(brewer.pal(5, \"BrBG\"))(98))+\n  theme_void()+\n  theme(text = element_text(family=family1,color=\"#F5F5F5\"),\n        axis.title = element_blank(),\n        axis.text.y = element_text(vjust=0,hjust=0.95,size=16),\n        axis.text.x = element_text(size=11),\n        plot.background = element_blank(),\n        panel.background = element_blank())\n  \n\n\n# build a nice legend\nlibrary(circlize)\ncol_fun = circlize::colorRamp2(c(0, 0.5, 1), c(\"#A6611A\", \"#F5F5F5\", \"#018571\"))\nlgd = ComplexHeatmap::Legend(at = c(0, 0.5, 1),\n                             labels = c(\"  Low\", \"\", \"  High\"),\n                             col_fun = col_fun, \n                             grid_width = unit(3.4, \"cm\"),\n                             labels_gp = gpar(col = \"#F5F5F5\", \n                                              fontsize=11,\n                                              fontface=\"bold\"))\n \nComplexHeatmap::draw(lgd)\ndev.off()\n\nlibrary(cowplot)\nlibrary(grid)\nleg<-grid.grabExpr(ComplexHeatmap::draw(lgd))\nlegend<-plot_grid(leg)\nclass(legend)\n\n# remove bg from pictures\n# https://www.remove.bg/upload\n\n # assemble all the pieces\n library(cowplot)\nfinal<- ggdraw()+\n  draw_image(image=\"w52/bg.jpg\",scale=1.5,x=0)+\n  draw_image(\"w52/title.png\",x=-0.05,y=0.35,scale=0.9)+\n  draw_plot(my_hmap,scale=0.83,x=0.05,y=-0.05)+\n  draw_label(\"STARBUCKS 10' COFFEE\",x=0.48,y=0.9,size=55,color=\"black\",\n             fontfamily = family,fontface = \"bold\")+\n  draw_image(\"w52/cup.png\",scale=0.5,x=-0.435,y=-0.25)+\n  draw_plot(legend,x=-0.422,y=-0.28)+\n  draw_label(\"STARBUCKS\",x=0.067,y=0.17,\n             size=9,color=\"black\",fontfamily = family)+\n  draw_label(\"DataSource: Starbucks Coffee Company | DataViz: Federica Gazzelloni\",\n             x=0.3,y=0.03,size=11,color=\"#F5F5F5\",\n             fontfamily = family1)+\n  draw_image(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\",\n             x=0.45,y=0.45,scale=0.09)\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"w52/starbucks.png\"),\n              #res = 320, \n              width = 1200, \n              height = 675, \n              units = \"px\",\n              #pointsize = 12,\n              background = \"white\",\n              scaling = 1)\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w50_spiders/w50_spiders.html",
    "href": "tidytuesday/cases2021/posts2021/w50_spiders/w50_spiders.html",
    "title": "Spiders",
    "section": "",
    "text": "library(tidyverse)\nspiders <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-12-07/spiders.csv')\n\n# spiders%>%View\nsp_family_graph<-spiders%>%\n  count(family,genus,species,sort=T)%>%\n  select(-n)\n\n# https://stackoverflow.com/questions/24173194/remove-parentheses-and-text-within-from-strings-in-r\nmy_spider_countries<- spiders%>%\n  separate(distribution,into=c(\"country\",\"region\"),sep=\",|;\",remove = FALSE)%>%\n  mutate(country=stringi::stri_trans_totitle(country))%>%\n  mutate(country2=gsub(\"\\\\s*\\\\([^\\\\)]+\\\\)*\",\"\",country))%>%\n  mutate(country2=gsub(\"^D.r.|Dr.\",\"Dem. Rep. \",country2))%>%\n  \n  mutate(country2=gsub(\"^ \",\"\",country2))%>%\n  \n  mutate(country2=gsub(\" To .*$\",\"\",country2))%>% \n  \n  mutate(country2=gsub(\" Or .*$\",\"\",country2))%>% \n  \n  mutate(country2=gsub(\"Is.$\",\"Islands\",country2))%>%\n  \n  mutate(country2=gsub(\"\\\\?$\",\"\",country2))%>%\n  mutate(country2=gsub(\" And .*$\",\"\",country2))%>%#\n  \n  mutate(country2=gsub(\". Introduced$\",\"\",country2))%>%\n  \n  mutate(country2=case_when(str_detect(country2,\"Austral\")~\"Australia\",\n                            #str_detect(country2,\"Rep.\")~\"Republic\",\n                            str_detect(country2,\"Bahama\")~\"Bahamas\",\n                            str_detect(country2,\"Brazi\")~\"Brazil\",\n                            str_detect(country2,\"Brezi\")~\"Brazil\",\n                            str_detect(country2,\"Bosnia Herzegovina\")~\"Bosnia and Herz.\",\n                            #str_detect(country2,\"Canary\")~\"Canary Islands\",\n                            str_detect(country2,\"Caribbean\")~\"Caribbean\",\n                            str_detect(country2,\"Czechia\")~\"Czech Rep.\",\n                            str_detect(country2,\"Cina\")~\"China\",\n                            str_detect(country2,\"Central Africa\")~\"Central African Rep.\",\n                            str_detect(country2,\"Asia\")~\"Asia\",\n                            str_detect(country2,\"Cape Verde\")~\"Cape Verde\",\n                            str_detect(country2,\"Colombia\")~\"Colombia\",\n                            str_detect(country2,\"Columbia\")~\"Colombia\",\n                            str_detect(country2,\"Europ\")~\"Europe\",\n                            str_detect(country2,\"Himalaya\")~\"Himalayas\",\n                            str_detect(country2,\"Indonesia\")~\"Indonesia\",\n                            str_detect(country2,\"Guinea\")~\"Guinea\",\n                            str_detect(country2,\"Usa\")~\"United States\",\n                            str_detect(country2,\"Britain\")~\"United Kingdom\",\n                            str_detect(country2,\"Ecuador\")~\"Ecuador\",\n                            str_detect(country2,\"Ghana\")~\"Ghana\",\n                            str_detect(country2,\"Greece\")~\"Greece\",\n                            str_detect(country2,\"Guadeloupe\")~\"Guadaloupe\",\n                            str_detect(country2,\"Kyrgystan\")~\"Kyrgyzstan\",\n                            str_detect(country2,\"Laos\")~\"Laos\",\n                            str_detect(country2,\"Malaysia\")~\"Malaysia\",\n                            str_detect(country2,\"Spain\")~\"Spain\",\n                            str_detect(country2,\"Reunion\")~\"Réunion\",\n                            str_detect(country2,\"Saint Lucia\")~\"Saint Lucia\",\n                            str_detect(country2,\"São Tomé\")~\"São Tomé Príncipe\",\n                            str_detect(country2,\"Kerguelen\")~\"Kerguelen Islands\",\n                            str_detect(country2,\"St. Vincent\")~\"St. Vincent\",\n                            str_detect(country2,\"Virgin Islands\")~\"Virgin Islands\",\n                            str_detect(country2,\"Mexic\")~\"Mexico\",\n                            TRUE~country2))%>%\n  filter(!str_detect(country2,\"Unknown|West|North|Western|East|Poss|prob|Pres|Prob\"))\n\n\nit_to_from<-my_spider_countries%>%\n  filter(country2==\"Italy\")%>%\n  mutate(region=trimws(region))%>%filter(!is.na(region))%>% #count(region)%>%View\n  mutate(region=gsub(\"\\\\?$\",\"\",region))%>%\n  mutate(region=gsub(\"Central Europe to \",\"\",region))%>%#count(region)%>%View\n  filter(!str_detect(region,\"Central to \"),\n         !region==\"south-eastern Europe\")%>%#count(region)%>%View\n  mutate(region=gsub(\" and|to*$\",\"\",region))%>%\n  mutate(region=case_when(str_detect(region,\"Greece\")~\"Greece\",\n                          str_detect(region,\"Ukraine\")~\"Ukraine\",\n                          str_detect(region,\"Russia\")~\"Russia\",\n                          TRUE~region))%>%\n  mutate(region=gsub(\"\\\\)$\",\"\",region))%>%\n  rename(from=country2,to=region)\n\n#it_to_from%>%count(to)\n\n# library(ggraph)\n# library(igraph)\n# library(tidyverse)\n\nspiders_Balkans <-  c(\"Bulgaria\",\"Albania\",\"Greece\",\"Bosnia\",\"Kosovo\",\"Macedonia\",\n                      \"Montenegro\",\"Romania\",\"Serbia\")%>%as_tibble()%>%\n  rename(to=value)\n\nitaly_to<-it_to_from%>%count(to)%>%select(-n)\nitaly_to<- italy_to%>%filter(!to==\"Balkans\")\nitaly_to <- rbind(italy_to,spiders_Balkans)%>%unlist()\n\n\nworld <- map_data(\"world\")%>%\n  filter(!region==\"Antarctica\")\n\nitaly<- world%>%\n  filter(region==\"Italy\")\n\n\nlibrary(sf)\n# centroids and coords with spData::world-----\nworld2_geo<- spData::world\n# library(countrycode)\n# countrycode::codelist\n\n# italy centroids\nit_centroids<- world2_geo%>%\n  filter(name_long==\"Italy\")%>%\n  st_centroid()%>%\n  st_coordinates()%>%\n  as.data.frame()%>%\n  mutate(from=\"Italy\")%>%\n  rename(long_from=X,lat_from=Y)\n\n# extrapolate the centroids for italy_to countries\nto_country_geom<- world2_geo%>%\n  filter(name_long%in%italy_to) %>% #22 out of  28\n  st_centroid()%>%select(name_long)# %>%count(name_long) \n\n# check missing values\nas.data.frame(italy_to)%>% # count(italy_to) # 28\n  anti_join(to_country_geom,by=c(\"italy_to\"=\"name_long\")) # missing values (\"Malta\",\"North Macedonia\",\"Russia\",\"Sardinia\",\"Sicily\",\"Bosnia\")\n\n\nto_centroids<- to_country_geom%>%\n  st_coordinates()%>%\n  as.data.frame()%>%\n  rename(long_to=X,lat_to=Y)\n\n\n\nto_df<-cbind(to=to_country_geom$name_long,to_centroids)%>%\n  filter(!to%in%c(\"Kosovo\",\"France\"))    \n# 46.261157084423814, 2.3345436786735583\n\n\n\n\nto_and_from<- it_to_from%>%\n  count(family,genus,species,subspecies,year,from,to)%>%\n  select(-n)%>%\n  filter(to%in%to_df$to) %>%\n  left_join(it_centroids,by=\"from\") %>%#count(to)\n  left_join(to_df,by=\"to\")#%>%count(to,long_to,lat_to)\n\n\nbalkans_to<- to_df%>%\n  filter(to%in%c(\"Serbia\",\"Montenegro\",\"Macedonia\",\"Albania\"))%>%\n  merge(it_centroids)\n\n\nlng_rng <- range(to_and_from$long_to)\nlat_rng <- range(to_and_from$lat_to)\n\nlibrary(extrafont)\nloadfonts()\nlibrary(showtext)\nfont_add(family = \"Blackwidow\", regular = \"Blackwidow-o6ga.ttf\") # https://www.fontspace.com/blackwidow-font-f23155\n#font_add(family = \"Montserrat\", regular = \"Montserrat-Regular.ttf\") # https://fonts.google.com/specimen/Montserrat?category=Sans+Serif\nshowtext_auto()\nshowtext_opts(dpi = 320)\n\n# map--------\n\nitaly_map<-ggplot(world)+\n  # rest of the countries ploygons\n  geom_polygon(aes(x=long,y=lat,group=group),\n               alpha=0.5,fill=\"darkcyan\",color=\"grey58\") +\n  # italy polygon\n  geom_polygon(data=italy,\n               aes(x=long,y=lat,group=subregion),\n               color=\"azure4\",fill=\"darkgoldenrod3\") +\n  # name of the countries (to)\n  geom_text(data= to_df,\n            aes(x=long_to,y=lat_to,label=to),\n            color=\"black\",nudge_y = 0.5,nudge_x=0.5,\n            family=\"Blackwidow\",size=6) +\n  # to points\n  geom_point(data= to_df,\n             aes(x=long_to,y=lat_to),\n             color=\"#D16296\",size=4,alpha=0.9,shape=21,stroke=2)+\n  # points connections\n  geom_curve(data= to_and_from,\n               aes(x = long_from, y = lat_from, \n                   xend = long_to, yend = lat_to),\n             curvature = 0.2,size=0.3,\n             color=\"dodgerblue4\",\n             alpha=0.4,\n             arrow = arrow(length = unit(0.25, \"cm\"))) +\n  # adding balkans countries points connections\n  geom_curve(data= balkans_to,\n             aes(x = long_from, y = lat_from, \n                 xend = long_to, yend = lat_to),\n             curvature = 0.2,size=0.3,\n             color=\"dodgerblue4\",\n             alpha=0.4,\n             arrow = arrow(length = unit(0.25, \"cm\"))) +\n  # stroke of centre point of italy\n  geom_point(data= it_centroids,\n             aes(x=long_from,y=lat_from),\n             color=\"#D16296\",size=3,shape=21,stroke=2,alpha=0.9) +\n  # center point of italy\n  geom_point(data= it_centroids,\n             aes(x=long_from,y=lat_from),\n             color=\"yellow2\",size=1) +\n  geom_text(data= it_centroids,\n             aes(x=long_from,y=lat_from,\n                 label=\"Italy\"),\n            family=\"Blackwidow\",nudge_y = 1,\n             color=\"black\",size=10) +\n  geom_curve(aes(x = 12.1, y = 42.8, \n            xend = 2.3345436786735583, yend = 46.261157084423814),\n             curvature = 0.2,size=0.3,\n             color=\"dodgerblue4\",\n             alpha=0.4,\n             arrow = arrow(length = unit(0.25, \"cm\"))) +\n  geom_text(aes(x = 2.3345436786735583, y = 46.261157084423814,\n                label=\"France\"),\n            family=\"Blackwidow\",nudge_y = 1,\n            color=\"black\",size=8)+\n  coord_cartesian(xlim=c(-8.42048,54.28545),ylim=c(28.18548,49.14882))+\n  labs(caption=\"Datasource: World Spiders Database | Majer et al, 2015 | #TidyTuesday week50\\nDataViz: Federica Gazzelloni\")+\n  ggthemes::theme_map()+\n  theme(text = element_text(family=\"Roboto Condensed\"),\n        plot.caption = element_text(size=11))\n\n# export the radial plot and save it as .png\n\n# gt table -----------\n# https://gt.rstudio.com/reference/tab_options.html\nlibrary(gt)\nlibrary(tidyverse)\nlibrary(glue)\n\nspiders_italy <-  filter(my_spider_countries, grepl(\"Italy\", country2))\nspiders_italy<- spiders_italy%>%filter(!is.na(subspecies))\n\ntax_tb<-spiders_italy %>%\n  arrange(year)%>%\n  select(Year=year,Family=family,Genus=genus,Species=species,Subspecies=subspecies) %>%\n  gt() %>%\n  tab_header(\n    title = md(\"**Italy-Spiders Taxonomy**\"),\n    subtitle = glue(\"1907 to 1973\")\n  ) %>%\n  tab_source_note(\n    source_note = md(\"Datasource: **World Spiders Database** | Majer et al, 2015\")\n  )  %>%\n  tab_options(table.background.color=\"#D16296\")%>%\n  bstfun::as_ggplot()\n\n\n# final touches----------\nlibrary(cowplot)\nfinal_plot<- ggdraw(italy_map)+\n  draw_label(\"Spiders from Italy to?\",x=0.55,y=0.1,\n             fontfamily = \"Blackwidow\",size=65)+\n draw_line(x=c(0.715,0.985),y=c(0.52,0.52),size=45,\n           color=\"#D16296\")+\n  \n draw_label(\"The history of Italian spiders formally begins in 1868,\\na list of 404 species were reported at the time.\\nThere were unbalanced discoveries between \\nnorthen and southern Italy.\\nKnowledge on Italian spiders increased rapidly, \\nbetween 1901-1951\\nSpiders are mostly found in Alto-Adige, Valle D'Aosta,\\nLombardia,Veneto,Calabria and Sardegna.\",\n             x=0.85,y=0.52,size=10,color=\"white\",\n            fontfamily=\"Roboto Condensed\")+\n  draw_plot(tax_tb,scale=0.37,x=0.35,y=0.3)+\n  draw_image(\"w50/arages_small.png\",scale=0.1, x=-0.44,y=0.35)+\n  draw_image(\"w50/ESA.jpg\",scale=0.08,x=-0.44,y=0.25)+\n  draw_image(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\",\n             scale=0.1,x=-0.44,y=0.45) \n\n####### SAVING ######################################\nragg::agg_png(here::here(\"w50/spiders2.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w29_scoobydoo/w29_scoobydoo.html",
    "href": "tidytuesday/cases2021/posts2021/w29_scoobydoo/w29_scoobydoo.html",
    "title": "Scoobydoo",
    "section": "",
    "text": "scooby doo font\nfonts\n\n\nlibrary(gistfo)\nlibrary(carbonate)\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(ggtext)\nlibrary(viridis)\nlibrary(extrafont)\nlibrary(patchwork)\nlibrary(cowplot)\nlibrary(ggpubr)\nlibrary(png)\nlibrary(grid)\nlibrary(magick)\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 29)\nscoobydoo <- tuesdata$scoobydoo\nhead(scoobydoo)\n\n\nscoobydoo_long <- scoobydoo%>%\nselect(-imdb,-engagement,-run_time,-trap_work_first,-c(if_it_wasnt_for:door_gag),\n-c(jeepers:rooby_rooby_roo),-c(fred_va:scooby_va),-c(split_up:set_a_trap))%>%\nmutate(caught_other=as.character(caught_other),\ncaught_not=as.character(caught_not),\nunmask_other=as.character(unmask_other))%>%\npivot_longer(cols=contains(\"caught\"),names_to=\"caught\",values_to=\"caught_value\")%>%\npivot_longer(cols=contains(\"captured\"),names_to=\"captured\",values_to=\"captured_value\")%>%\npivot_longer(cols=contains(\"unmask\"),names_to=\"unmask\",values_to=\"unmask_value\")%>%\npivot_longer(cols=contains(\"snack\"),names_to=\"snack\",values_to=\"snack_value\")%>%\npivot_longer(cols=c(non_suspect,arrested),names_to=\"investigate\",values_to=\"investigate_value\")%>%\npivot_longer(cols=c(batman:blue_falcon),names_to=\"super_hero\",values_to=\"super_hero_value\")\n\n\nhead(scoobydoo_long)\n\n\nnames(scoobydoo_long)\n\n\ndim(scoobydoo_long)\n\n\nscoobydoo_long %>% \n  select(date_aired,caught,caught_value) %>%\n  mutate(year=lubridate::year(date_aired)) %>%\n  filter(caught_value==\"TRUE\") %>%\n  ggplot(aes(x=(year/1969)/100000,y=factor(caught),group=caught)) +\n  geom_col(aes(fill=caught)) +\n  guides(fill=\"none\") + \n  labs(title=\"Who caught more within the years?\") +\n  theme_fivethirtyeight() +\n  theme(axis.text.x = element_text(angle=0))\n\nPlotting final:\n\nscooby_family <- \"Scooby Doo\"\n\ncolors <- c(\"Fred\"=\"#0000CD\",\n            \"Scooby\"=\"#8B3E2F\",\n            \"Shaggy\"=\"#228B22\",\n            \"Daphnie\"=\"#FFD700\",\n            \"Velma\"=\"#FF7F00\")\n\ncaught <- scoobydoo_long %>% \n  select(date_aired,caught,caught_value) %>%\n  mutate(year=lubridate::year(date_aired)) %>%\n  filter(caught_value==\"TRUE\",year==\"1969\") %>%\n  ggplot(aes(caught,fill=caught)) +\n  geom_histogram(aes(y = after_stat(count / max(count))),stat=\"count\") + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_discrete(labels=c(\"Fred\",\"Scooby\", \"Shaggy\")) +\n  scale_fill_manual(values=c(\"#0000CD\",\"#8B3E2F\",\"#228B22\")) +\n  guides(fill=\"none\") +\n  labs(title=\"Caught\",y=\"\") +\n  theme_fivethirtyeight() +\n  theme(text=element_text(size=16,  family=scooby_family),\n        axis.text.x = element_text(size=10),\n        axis.title.x = element_blank())\n\ncaptured <- scoobydoo_long %>% \n  select(date_aired,captured,captured_value) %>%\n  mutate(year=lubridate::year(date_aired)) %>%\n  filter(captured_value==\"TRUE\",year==\"1969\") %>%\n  ggplot(aes(captured,fill=captured)) +\n  geom_histogram(aes(y = after_stat(count / max(count))),stat=\"count\") + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_discrete(labels=c(\"Daphnie\",\"Fred\",\"Scooby\", \"Shaggy\",\"Velma\")) +\n  scale_fill_manual(values=c(\"#FFD700\", \"#0000CD\",\"#8B3E2F\",\"#228B22\",\"#FF7F00\")) +\n  guides(fill=\"none\") +\n  labs(title=\"Captured\") +\n  theme_fivethirtyeight() +\n  theme(text=element_text(size=16,  family=scooby_family),\n        axis.text.x = element_text(size=10),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank())\n\nunmask <- scoobydoo_long %>% \n  select(date_aired,unmask,unmask_value) %>%\n  mutate(year=lubridate::year(date_aired)) %>%\n  filter(unmask_value==\"TRUE\",year==\"1969\") %>%\n  ggplot(aes(unmask,fill=unmask)) +\n  geom_histogram(aes(y = after_stat(count / max(count))),stat=\"count\") + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_discrete(labels=c(\"Fred\",\"Scooby\", \"Shaggy\",\"Velma\")) +\n  scale_fill_manual(values=c(\"#0000CD\",\"#8B3E2F\",\"#228B22\",\"#FF7F00\")) +\n  guides(fill=\"none\") +\n  labs(title=\"Unmask\",y=\"\") +\n  theme_fivethirtyeight() +\n  theme(text=element_text(size=16,  family=scooby_family),\n        axis.text.x = element_text(size=10),\n        axis.title.x = element_blank() )\n\nsnack <- scoobydoo_long %>% \n  select(date_aired,snack,snack_value) %>%\n  mutate(year=lubridate::year(date_aired)) %>%\n  filter(snack_value==\"TRUE\",year==\"1969\") %>%\n  ggplot(aes(snack,fill=snack)) +\n  geom_histogram(aes(y = after_stat(count / max(count))),stat=\"count\") + \n  scale_y_continuous(labels = scales::percent) +\n  scale_x_discrete(labels=c(\"Daphnie\",\"Fred\",\"Shaggy\",\"Velma\")) +\n   scale_fill_manual(values=c(\"#FFD700\", \"#0000CD\",\"#228B22\",\"#FF7F00\")) +\n  guides(fill=\"none\") +\n  labs(title=\"Snack\") +\n  theme_fivethirtyeight() +\n  theme(text=element_text(size=16,  family=scooby_family),\n        axis.text.x = element_text(size=10),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank())\n\nrequire(patchwork)\naction_plot <- caught+captured+unmask+snack\n\nimg <- png::readPNG('all5.png')\n\n lealeft <- ggplot()+\n  theme_void() +\n  theme(plot.background = element_rect(fill = \"#87cf80\")) + \n  background_image(img) +\n  action_plot \n \n\ngraphics <- ggarrange(lealeft) \n\nfinal_plot <- annotate_figure(graphics,\n               top = text_grob(\"Scooby-Doo 1969: Percent of \", \n                               color = c(\"#778899\"), face = \"bold\", size = 35,family=\"Scooby Doo\"),\n               bottom = text_grob(\"DataViz: @fgazzelloni DataSource: \\n TidyTuesday week29, Scooby-Doo,Kaggle,ScoobyPedia\",\n                                  color = \"#6C7B8B\",family=\"Scooby Doo\",\n                                  hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n               left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size=10),\n               right = text_grob(bquote(\"\"), color=c(\"#778899\"),rot = 90,size=10),\n               fig.lab = \"TidyTuesday week29\", fig.lab.face = \"bold.italic\",fig.lab.size=8,\n               fig.lab.pos=\"bottom.right\"\n)\n\nfinal_plot <- final_plot +\n  annotate(geom = \"text\", label=\"Scooby-Doo and Guess Who?\",x = 0.24, y = 0.87, \n           colour = \"#BF3EFF\", size = 9,family=scooby_family) +\n  annotate(geom = \"text\", label=\"Velma\",x = 0.10, y = 0.71, colour = \"#FF7F00\", size = 7,family=scooby_family) +\n  annotate(geom = \"text\", label=\"Shaggy\",x = 0.13, y = 0.82, colour = \"#228B22\", size = 7,family=scooby_family) +\n  annotate(geom = \"text\", label=\"Scooby\",x = 0.23, y = 0.67, colour = \"#8B3E2F\", size = 7,family=scooby_family) +\n  annotate(geom = \"text\", label=\"Fred\",x = 0.33, y = 0.78, colour = \"#0000CD\", size = 7,family=scooby_family) +\nannotate(geom = \"text\", label=\"Daphnie\",x = 0.40, y = 0.72, colour = \"#FFD700\", size = 7,family=scooby_family) \n\n  \nrequire(cowplot)\n\nimg2 <- png::readPNG('car_all5.png')\nimg3 <- png::readPNG('scooby.png')\n\n\nfinal <- ggdraw() +\n  draw_image(img2,  x = 0.4, y = 0.41, scale = .2) +\n  draw_image(img3,  x = -0.41, y = 0.45, scale = .15) +\n  draw_plot(final_plot)\nfinal\n\nSaving:\n\nragg::agg_png(here::here(\"w29\", \"w29_scoobidoo.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w27_animal_rescues/w27_animal_rescues.html",
    "href": "tidytuesday/cases2021/posts2021/w27_animal_rescues/w27_animal_rescues.html",
    "title": "Animal Rescues",
    "section": "",
    "text": "Week 27 TidyTuesday Animal Rescues\nmore reading: Animal rescues by London fire brigade rise 20% in pandemic year - TrackReconstruction - animate bar plot - composition of plots - annotate\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(ggthemes)\nlibrary(ggalt)\nlibrary(gganimate)\nlibrary(ggdist)\nlibrary(ggExtra)\nlibrary(ggtext)\n\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 27)\nanimal_rescues <- tuesdata$animal_rescues\n\nhead(animal_rescues)\n\n\ndim(animal_rescues)\n\n\nnames(animal_rescues)\n\n\nanimal_rescues_small <- animal_rescues %>% \n  select(date_time_of_call,cal_year,incident_notional_cost,animal_group_parent,\n         special_service_type,ward,borough,stn_ground_name,latitude,longitude) %>%\n  mutate(borough=tolower(borough)) %>% \n  drop_na() %>%\n  mutate(animal_group_parent=case_when(stringr::str_detect(animal_group_parent,\"^Unknown\") ~ \"Unknown\",\n                                       TRUE ~ animal_group_parent),\n         cal_year=as.factor(cal_year) ,\n         incident_notional_cost=ifelse(incident_notional_cost==\"NULL\",0,incident_notional_cost),\n         incident_notional_cost=as.numeric(incident_notional_cost),\n         date_time_of_call=as.Date(date_time_of_call,\"%d/%m/%Y\")) %>%\n  rename(date=date_time_of_call,year=cal_year) %>%\n  mutate(month=lubridate::month(date),\n         day=lubridate::day(date)) %>%\n  complete(date = full_seq(date, 1)) %>%\n  mutate(incident_notional_cost_full = round(spline(x = date, y = incident_notional_cost, xout = date)$y))\n  \n\nstr(animal_rescues_small)\n\nanimal_rescues_small %>% count(incident_notional_cost) %>% arrange(-n) #desc(incident_notional_cost))\n\n\nDataExplorer::profile_missing(animal_rescues_small)\n\n\ncalls <- animal_rescues_small%>%group_by(year)%>%count(year)%>%arrange(-n)\n\n\nbar_plot <- ggplot(data=animal_rescues_small%>%drop_na(),aes(x=year,y=borough)) + \n  geom_col(aes(group=borough,fill=borough,color=borough)) +\n  geom_text(data=calls, aes(x= year, y=n, label=n), hjust=0.5,\n           position = position_stack(vjust = 18),fontface = \"bold\"\n            )+\n  guides(color=\"none\",fill=\"none\") +\n  labs(title=\"Numbers of call by Year to the London Fire Brigate for Animal Rescues\",\n       x=\"Year\",y=\"by London Borough\") + \n  ggthemes::theme_calc() +\n  theme(axis.text.y = element_blank(),\n        axis.text.x = element_text(size=8),\n        axis.title.x = element_text(vjust=-2),\n        axis.ticks.x = element_line(size=2,color=\"pink\"),\n        plot.title = element_text(face=\"bold\",size=11),\n        plot.margin = unit(c(0.5,0.5,0.5,0.5), \"cm\"))\n\nbar_plot\n\n\nbox_plot <- animal_rescues_small %>%  drop_na() %>% # count(year)\n  filter(incident_notional_cost<2000) %>%\n  ggplot(aes(x=fct_reorder(animal_group_parent, incident_notional_cost),y=incident_notional_cost, group=animal_group_parent)) +\n  geom_boxplot(aes(color=animal_group_parent),size=0.5,alpha=0.4) +\n  scale_y_continuous(labels = scales::comma) +\n  guides(color=\"none\") +\n  labs(title=\"LFB Animal Rescues - Incident notional cost 2009 - 2021\",\n       color=\"Animal group parent\", y=\"Cost value £\",x=\"\") +\n  coord_flip() +\n  ggthemes::theme_calc() +\n  theme(axis.text.y = element_text(size=8,angle=0),\n        axis.text.x = element_text(size=8,angle=0),\n        axis.title.x = element_text(vjust=-2),\n        axis.ticks.x = element_line(size=2,color=\"pink\"),\n        axis.ticks.y = element_line(size=2,color=\"pink\"),\n        panel.grid.major.y = element_line(size=0.2),\n        plot.title = element_text(face=\"bold\",size=11),\n        plot.margin = unit(c(0.5,0.5,0.5,0.5), \"cm\"))\n\nbox_plot\n\n\nsmoth_line <-animal_rescues_small%>%\n  group_by(month)%>%\n  summarise(med_val=median(incident_notional_cost))%>%\n  ungroup() \n\n\n\ncost_month_plot <- ggplot(data=smoth_line,aes(x=month,y=med_val))+\n  geom_point(shape=21,aes(fill=month)) +\n  geom_line(linetype = 3)+\n  geom_smooth(size=0.3,fill=\"pink\") +\n  geom_boxplot(data=subset(animal_rescues_small,incident_notional_cost<500 & incident_notional_cost>200),\n               aes(x=month,y=incident_notional_cost,group=month,color=month),fill=NA) +\n  geom_text(aes(label=med_val),vjust = -1) +\n  scale_x_discrete(limits =seq(1,12,1), labels=c(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\n                                                 \"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"))+\n  guides(fill=\"none\",color=\"none\") + \n  labs(title=\"Cost of incident by month (2009 - 2021)\",\n       x=\"Month\",y=\"Median value £\") +\n  ggthemes::theme_calc() +\n  theme(axis.text.y = element_blank(),\n        axis.text.x = element_text(size=8),\n        axis.title.x = element_text(vjust=-2),\n        axis.ticks.y = element_blank(),\n        axis.ticks.x = element_line(size=2,color=\"pink\"),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.y = element_line(size=0.1),\n        plot.title = element_text(face=\"bold\",size=11),\n        plot.margin = unit(c(0.5,0.5,0.5,0.5), \"cm\"))\n\ncost_month_plot\n\n\nsmoth_line_yr <-animal_rescues_small%>%#count(year)\n  mutate(year=as.numeric(year))%>% #count(year)\n  group_by(year)%>%\n  summarise(tot_val=sum(incident_notional_cost_full))%>%\n  ungroup() \n\n\n\ncost_yr_plot <- ggplot(data=smoth_line_yr,aes(x=year,y=tot_val))+\n  geom_point(shape=21,aes(fill=year)) +\n  geom_line(linetype = 3)+\n  geom_smooth(size=0.3,fill=\"pink\") +\n  geom_text(aes(label=scales::comma(tot_val)),vjust = -1.5,size=3) +\n  scale_x_discrete(limits =seq(1,13,1),labels=seq(2009,2021,1))+\n  guides(fill=\"none\",color=\"none\") + \n  labs(title=\"Annual cost of incidents by Year (2009 - 2021)\",\n       y=\"Annual cost - median value £\",x=\"Year\") +\n  ggthemes::theme_calc() +\n  theme(axis.text.y = element_blank(),\n        axis.text.x = element_text(size=8),\n        axis.title.x = element_text(vjust=-2),\n        axis.ticks.y = element_blank(),\n        axis.ticks.x = element_line(color=\"pink\",size=1),\n        panel.grid.major.x = element_line(size=0.1),\n        panel.grid.major.y = element_blank(),\n        plot.title = element_text(face=\"bold\",size=11),\n        plot.margin = unit(c(0.5,0.5,0.5,0.5), \"cm\"))\n\ncost_yr_plot  \n\n\np1 <- ggarrange(bar_plot, box_plot + \n                font(\"x.text\", size = 9),\n                ncol = 1, nrow = 2)\np2 <- ggarrange(cost_month_plot, cost_yr_plot +\n                font(\"x.text\", size = 9),\n                ncol = 1, nrow = 2)\ngraphics<- ggarrange(p1, p2, ncol = 2, nrow = 1)\n\n\n\n\nfinal_plot <- annotate_figure(graphics,\n               top = text_grob(\"Animal rescues by London fire brigade rise 20% in pandemic year\", \n                               color = c(\"#FF34B3\", \"#FFFFFF\", \"#FFFFFF\"), face = \"bold\", size = 14),\n               bottom = text_grob(\"DataViz: @fgazzelloni DataSource: \\n TidyTuesday and Animal Rescues - London.gov - The Guardian - week27\",\n                                  color = \"blue\",\n                                  hjust = 1, x = 1, face = \"italic\", size = 10),\n               left = text_grob(\"Last year 337 animals were helped compared with 269 in 2019\", color = c(\"#BA55D3\", \"#FFFFFF\", \"#FFFFFF\"), rot = 90,size=10),\n               right = text_grob(bquote(\"The LFB calculates the average cost of each rescue to be £346\"), rot = 90,size=10),\n               fig.lab = \"TidyTuesday week27\", fig.lab.face = \"bold\"\n)\n\nfinal_plot\n\n\n###################### SAVING ############################\n\n\nragg::agg_png(here::here(\"w27\",\"w27_animals.png\"),\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal_plot\n\ndev.off()\n\n##################################################"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w35_lemurs/w35_lemurs.html",
    "href": "tidytuesday/cases2021/posts2021/w35_lemurs/w35_lemurs.html",
    "title": "Lemurs",
    "section": "",
    "text": "inspired by https://github.com/cararthompson/30DayChartChallenge/blob/main/scripts/2.2_animals.R\nrm(list = ls()) ## Load libraries —-\n\nlibrary(tidyverse)\nlibrary(extrafont)\nlibrary(cowplot)\nlibrary(ggExtra)\nextrafont::fonts()\n\n## Read in data ----\nlemurs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-08-24/lemur_data.csv')\n\n#-----------\n\ndf <- lemurs %>%\n  filter(!sex == \"ND\") %>%\n  mutate(year_dob = lubridate::year(dob),\n         month_dob = lubridate::month(dob),\n         .after = dob) %>%\n  mutate(year_dod = lubridate::year(dod),\n         month_dod = lubridate::month(dod),\n         .after = dod) %>%\n  group_by(taxon,sex,birth_type, dob,year_dob,month_dob,dod,year_dod,month_dod,age_max_live_or_dead_y,age_category) %>%\n  summarize(mean_weight = round(mean(weight_g)/1000,2)) %>%\n  ungroup() %>%\n  filter(!mean_weight == 0) %>%\n  filter(!is.na(age_max_live_or_dead_y)) %>%\n  filter(!birth_type == \"unknown\") %>%\n  rename(mum_age_category = age_category,\n         max_age = age_max_live_or_dead_y) %>% #\n  mutate(status = if_else(is.na(dod),\"alive\",\"dead\"),\n         .after = dod) %>%\n  mutate(status_id = case_when(\n    status == \"alive\" ~ 1,\n    status == \"dead\" ~ 0),\n    .after = status )  %>% # DataExplorer::profile_missing()\n  mutate(birth_type = case_when(\n    birth_type == \"CB\" ~ \"captive-born\",\n    birth_type == \"WB\" ~ \"wild-born\",\n    TRUE ~ \"unknown\")) %>%\n  mutate(mum_age_category = case_when(\n    mum_age_category == \"IJ\" ~ \"infant\",\n    mum_age_category == \"young_adult\" ~ \"young\",\n    TRUE ~ mum_age_category)) %>%\n  select(-status) %>%\n  mutate(birth_type_id = if_else(birth_type == \"captive-born\",1,0),\n         sex_id = if_else(sex == \"F\",1,0),\n         mum_age_category_id = case_when(mum_age_category == \"infant\" ~ 1,\n                                         mum_age_category == \"young\" ~ 2,\n                                         mum_age_category == \"adult\" ~ 3)) %>%\n  mutate(sex = if_else(sex == \"F\",\"Female\",\"Male\"))\n\n\ndf <- df %>%\n  mutate(mean_weight_class = case_when(mean_weight<=0.2 ~ \"0.01 - 0.1\",\n                                       mean_weight>0.1 & mean_weight<=0.8 ~ \"0.11 - 0.8\",\n                                       mean_weight>0.8 & mean_weight<=1.45 ~ \"0.81 - 1.45\",\n                                       mean_weight>1.45 & mean_weight<=2.3 ~ \"1.46 - 2.3\",\n                                       mean_weight>2.3 ~ \"2.3 +\")) %>%\n  mutate(mean_weight_class = factor(mean_weight_class))\n\ndf_taxon_id <- df %>% count(taxon,sort = TRUE) %>% mutate(taxon_id = row_number()) %>% select(-n)\ndf_weight_class_id <- df %>% count(mean_weight_class) %>% mutate(weight_class_id = row_number()) %>% select(-n)\n\ndf <- df %>%\n  inner_join(df_weight_class_id, by = \"mean_weight_class\") %>%\n  inner_join(df_taxon_id, by = \"taxon\") %>%\n  select(last_col(),everything())\n# %>% select(-taxon,-mean_weight_class)\n\nhead(df,3)\n#--------\n\n# Create label data\nlabels <- tibble(mum_age_category = c(\"Infant\", \"Young\", \"Adult\"),\n                 mum_age_category_x = c(0, 0, 0),\n                 mum_age_category_y = c(1, 1, 1))\n\n\n\n\n## Create colour scheme and theme ----\nlemurs_hues <- c(\"#d2dbe4\", \"#8a5d24\", \"#646376\", \"#192029\", \"#acb3bf\", \"#596e94\")\n\ntheme_lemurs_light <- function() {\n  theme_minimal() %+replace%\n    theme(text = element_text(colour = lemurs_hues[4]),\n          axis.text = element_text(size = 8),\n          axis.title = element_text(size = 10),\n          axis.ticks = element_blank())\n}\n\n## Plot it ----\n\n\n\n# infant = grey\n# young = light brown\n# adult = light grey\n\np <- ggplot(df) +\n  scale_colour_manual(values = c(lemurs_hues[c(3, 2, 5)]),\n                      labels = c(\"Infant\", \"Young\", \"Adult\")) +\n  scale_fill_manual(values = c(lemurs_hues[c(3, 2, 5)]),\n                      labels = c(\"Infant\", \"Young\", \"Adult\")) +\n  geom_point(aes(x = dob,y = dod, colour = mum_age_category,size = mean_weight),alpha = 0.7) +\n  geom_smooth(aes(x = dob,y = dod, colour = mum_age_category), se = FALSE) +\n      labs(x = \"Year of birth\",\n           y = \"Year of death\",\n           size = \"Years\") +\n      guides(colour = \"none\", size = \"none\") +\n      theme_lemurs_light() +\n  theme(text = element_text(family = \"xkcd\"))\n\n\nmarg <- ggMarginal(p, type = \"densigram\", groupColour = T, groupFill = T, alpha = 0.7)\n\nbm <- ggplot(df, aes(x = mean_weight)) +\n  geom_histogram(aes(y = stat(count),fill = mum_age_category, colour = factor(mum_age_category)),\n                 position = position_dodge(width = 0.3),\n                 bins = 50,\n                 alpha = 0.7, show.legend = T) +\n  guides(color = \"none\") +\n  facet_wrap(vars(sex)) +\n  labs(y = \"N.\",\n       x = \"Lemurs' weight in kg\",\n       fill = \"Lemurs' mother age category\") +\n  scale_fill_manual(values = c(lemurs_hues[c(3, 2, 5)]),\n                    labels = c(\"Infant\", \"Young\", \"Adult\")) +\n  scale_colour_manual(values = c(lemurs_hues[c(3, 2, 5)]),\n                      labels = c(\"Infant\", \"Young\", \"Adult\")) +\n  theme_lemurs_light() +\n  theme(text = element_text(family = \"xkcd\"),\n        legend.position = c(0.5,1.1),\n        legend.justification = \"center\",\n        legend.direction = \"horizontal\"\n        )\n\ntitle <- ggdraw() +\n  draw_label(\"Is Lemurs life expectancy distribution dependent from their mums status at pregnancy?\",\n             fontfamily = \"xkcd\",\n             colour = lemurs_hues[6],\n             hjust = 0.5,\n             size = 22)\n\nsubtitle <- ggdraw() +\n  draw_label(\"Baby lemurs stay with their mothers for about two years. In this time span, the baby lemurs are nursed and protected by their mother.\n             When it grows up the lemur stays in the troop, if it is a female, or otherwise it joins another group. The life span of a lemur is approximately eighteen years\",\n             fontfamily = \"xkcd\",\n             colour = lemurs_hues[4],\n             hjust = 0.5,\n             size = 12)\n\ncaption <- ggdraw() +\n  draw_label(\"TidyTuesday week35 - InfoGraphic: Federica Gazzelloni - Source: Lemurs,Kaggle,Zehr et al, 2014 - Nature\",\n             fontfamily = \"xkcd\",\n             colour = lemurs_hues[4],\n             hjust = 0.5,\n             size = 9)\n\ncombined_p <- plot_grid(title,\n                        subtitle,\n                        marg,\n                        bm,\n                        caption,\n                        ncol = 1,\n                        rel_heights = c(0.05, 0.1, 0.6, 0.2, 0.05))\n\n\n\n\n\nlibrary(ggpubr)\ngraphics <- ggarrange(combined_p)\n\nfinal_plot <- annotate_figure(graphics,\n                              top = text_grob(\"\",\n                                              color = c(\"#8a5d24\"), face = \"bold\", size = 24,\n                                              family = \"xkcd\"),\n                              bottom = text_grob(\"\",\n                                                 color = \"#6C7B8B\",family = \"xkcd\",\n                                                 hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n                              left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size = 10),\n                              right = text_grob(bquote(\"\"), color = c(\"#778899\"),rot = 90,size = 10),\n                              fig.lab = \"TidyTuesday week35\", fig.lab.face = \"bold.italic\",fig.lab.size = 8,\n                              fig.lab.pos = \"bottom.right\"\n)\n\nfinal_plot <- \n  final_plot +\n  \n  annotate(geom = \"text\", label = \"In the wild, ring-tailed lemurs can live about 20 years. \n           They are the most commonly found species of lemur in zoos, \n           where they can live up to a decade longer.\",\n           x = 0.15, y = 0.65,colour = \"black\",size = 3,family = \"xkcd\") +\n  \n  annotate(geom = \"text\", label = \"\",\n           x = 0.15, y = 0.65,colour = \"black\",size = 3,family = \"xkcd\") +\n  \n  annotate(geom = \"text\", label = \"The Indri,also known as the Babakoto,is the biggest living lemur. \n           A tree-dwelling Madagascar species, the Indri is known to grow as tall as 3 feet, \n           and weigh as much as 10 pounds.\",\n           x = 0.77, y = 0.18,colour = \"black\",size = 3,family = \"xkcd\") +\n  \n  annotate(geom = \"text\", label = \"Adult\",x = 0.83, y = 0.78, colour = \"#FF7F00\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Young\",x = 0.73, y = 0.58, colour = \"#FF7F00\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Infant\",x = 0.1, y = 0.5, colour = \"#FF7F00\", size = 5,family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.81, xend = 0.76, y = 0.78, yend = 0.72, colour = \"#FF7F00\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.72, xend = 0.68, y = 0.6, yend = 0.65, colour = \"#FF7F00\", curvature = .3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n  annotate(geom = \"curve\", x = 0.12, xend = 0.2, y = 0.5, yend = 0.43, colour = \"#FF7F00\", curvature = -.3, arrow = arrow(length = unit(2, \"mm\")),family = \"xkcd\") +\n\n  annotate(geom = \"text\", label = \"Comparing lemurs' life expectancy and weight\",\n         x = 0.5, y = 0.84,colour = \"#FF7F00\",size = 3,family = \"xkcd\") +\n  annotate(geom = \"text\", label = \"Male and female ring-tailed lemurs are similar physically.\nThey are roughly the same size, measuring about 42.5 cm or 1.4 ft.\n           from head to rump and weighing roughly 2.25 kg or 5 lb.\",\n           x = 0.67, y = 0.38,colour = \"black\",size = 3,family = \"xkcd\") \n\n\n\nlibrary(ggimage)\nlibrary(magick)\nlibrary(cowplot)\n\nlemur_img <- image_read(\"image.png\")\n#logo_file <- system.file(\"extdata\", \"logo.png\", package = \"cowplot\")\n  \nfinal <- ggdraw() +\n  draw_plot(final_plot) +\n  draw_image(lemur_img, x = 0.04, y = 0.3,width = 0.15)\n  \n\nfinal\n\n\n## Save plot ----\n\nragg::agg_png(here::here(\"w35/w35_lemurs.png\"),\n              res = 320, width = 12, height = 14, units = \"in\")\nfinal\n\ndev.off()\n\n\n\n# read the image, attach the Tidytuesday logo and save it --------------------------\nlibrary(ggimage)\nlibrary(magick)\n\n\ntidy_logo <- image_read(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\") %>%\n  image_resize(\"300x300\")\n\nimg <- image_read(\"image.png\")\n\n\ntidy_final <- image_read(\"w35_lemurs.png\")\nattached_logo <- image_composite(tidy_final, tidy_logo,\n                                 operator = \"atop\",\n                                 gravity = \"southwest\")\n\nimage_write(attached_logo, path = \"w35_lemurs.png\", format = \"png\")"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w44_ultra_trail_running/w44_ultra_trail_running.html",
    "href": "tidytuesday/cases2021/posts2021/w44_ultra_trail_running/w44_ultra_trail_running.html",
    "title": "Ultra Trail Running",
    "section": "",
    "text": "library(tidyverse)\n\nlibrary(tidyquant)\nlibrary(ggpattern)\n\nlibrary(extrafont)\nloadfonts()\nlibrary(showtext)\nfont_add_google(\"Shadows Into Light\",\"shadow_into_light\")\nfont_add_google(\"Schoolbell\", \"bell\")\nshowtext_opts(dpi = 320)\nshowtext_auto(enable = T)\n#font_families()\n\n\nultra_rankings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/ultra_rankings.csv')\nrace <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-26/race.csv')\n\n\nMake one dataset using the key primary variable “race_year_id” as a link between the two datasets\nselect the variables needed for making the map\n\nthere are some missing values, we deal with those later on the making\nCountry to fix:\n\nHong Kong, China ~“China”\nFL, United States ~ “US”\n\nLA, United States\n\nPA, United States\n\nUnited States\nMyoko, Japan ~ “Japan”\nUnited Kingdom ~ “UK”\n\n\nrace%>%\n  inner_join(ultra_rankings ,by=\"race_year_id\") %>% \n  mutate(year=lubridate::year(date))%>% #count(year)\n  mutate(participation=tolower(participation))%>%count(age,gender)\n\n\nmap_df <- race%>%\n  inner_join(ultra_rankings ,by=\"race_year_id\")%>%\n  mutate(year=lubridate::year(date))%>%\n  #select(city,country,gender,year,runner)%>%\n  filter(!is.na(country),!is.na(rank)) %>%\n  mutate(country=case_when(country==\"Hong Kong, China\"~\"China\",\n                           country==\"FL, United States\"~\"USA\",\n                           country==\"LA, United States\"~\"USA\",\n                           country==\"PA, United States\"~\"USA\",\n                           country==\"United States\"~\"USA\",\n                           country==\"United Kingdom\"~\"UK\",\n                           country==\"Myoko, Japan\"~\"Japan\",\n                           TRUE~country)) \n\nLet’s see the cities:\n\nmap_df <- map_df %>% #count(year)\n  arrange(city)%>%\n  mutate(city=tolower(city))%>%\n  mutate(city=gsub(\"\\\\d\",\"\",city),\n         city=gsub(\"\\\\?\",NA,city),\n         city=gsub(\"-\",\"\",city)) \n\ndrop the missing values\n\nmap_df<- map_df%>%drop_na()\n\n\nranks <- map_df%>%\n  filter(rank==\"1\")%>%\n  filter(gender==\"W\")%>%\n  count(country,nationality,distance,time_in_seconds,year)%>%\n  dplyr::select(-n)%>%\n  arrange(-distance,time_in_seconds) %>%#count(distance)\n  slice(1:10)\n\n\ncou_yr_m <- c(\"Finland_2018\",\"France_2019\",\"Spain_2019\",\"Indonesia_2019\",\"USA_2018\")\ncountry_m<- c(\"Finland\",\"France\",\"Spain\",\"Indonesia\",\"USA\")\nlatitude_m<- c(60.192059, 46.7111, 40.416775,-6.200000,40.981613)\nlongitude_m<-c(24.945831,1.7191,-3.703790,106.816666,-73.691925)\n\n\ncou_yr_w<-c(\"UK_2016\",\"Nepal_2018\",\"Greece_2016\",\"Poland_2017\",\"Italy_2018\",\"USA_2017\")\ncountry_w<- c(\"UK\",\"Nepal\",\"Greece\",\"Poland\",\"Italy\",\"USA\")\nlatitude_w<- c(43.844264,27.700769,39.366669,50.012100,42.349998,40.981613)\nlongitude_w<- c(-21.086052,85.300140,22.933332,20.985842,14.166667,-73.691925)\n\nmy_map_text_w<- data.frame(cou_yr_w,country_w,latitude_w,longitude_w)\n\nmy_map_text_m<- data.frame(cou_yr_m,country_m,latitude_m,longitude_m)\n\nload the libraries form the map\n\nlibrary(maps)\nlibrary(rnaturalearth)\nlibrary(sp)\nlibrary(sf)\n\nFirst step for the geo codes and geometry\n\ngeocode() {ggmap} finds latitude and longitude for the cities (See ?register_google)\nne_countries() {rnaturalearth} for world country polygons\nsf() {sf} for simple feature list column\nmap_data() {ggplot2} for a data frame of map data (require(“maps”))\n\nDataset is downloaded from:——–207 matches —– kaggle dataset\ngeonames can be another fount for geocodes\nLoad the data form {rnaturalearth} with geometry and join {maps} with map_data()for the lat and lon\n\n# world data full \nworld_full <- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld_data <- filter(world_full, continent != \"Antarctica\")\n\n# world lat&long\nworld<-map_data(map = \"world\") #%>%count(subregion)\n# states lat&long\nstates <- map_data(\"state\") # let's see if we use it\n\nworld_geodata<- world %>%\n  full_join(world_data, by = c(\"region\"=\"name\"))%>%\n  select(long,lat,group,order,region,region_wb) #%>%count(region)\n\n# my df with geocodes\nmap_geodata <- map_df%>%\n  left_join(worldcitiespop_match,by=\"city\")%>%\n  janitor::clean_names()\n\n\ngeom_polygon() for the world borders\ngeom_polygon() for the US borders\ngeom_path() for delimiting world regions\n\n\nmap_geodata_dot <- map_geodata %>% \n  arrange(time_in_seconds)%>%\n  mutate(participation=tolower(participation))%>%\n  mutate(elevation=elevation_gain+elevation_loss,.after=elevation_gain)%>%\n  select(-elevation_gain,-elevation_loss) %>%\n  select(country,latitude,longitude,gender,participation,rank)%>%\n  mutate(country_code = countrycode(country, \n            origin = 'country.name', \n            destination = 'iso2c'),\n         country_code=tolower(country_code))\n\nWe do not use these features:\n\ngeom_polygon(data=world_geodata,aes(x=long,y=lat,group=group),fill=“lightslategray”) +\ngeom_polygon(data = states,aes(x = long, y = lat, group = group),fill=NA,color=“#000000”,size=0.3)+\ngeom_path(data=world,aes(x=long,y=lat,group=group),size=0.1,color=“darkslateblue”) +\n\n\npal_gender<- c(\"deepskyblue4\",\"mediumvioletred\")\n\n\nmy_map_text_w\n\nWest world\n\nworld_west<-  ggplot() +\n  \n  geom_point(data = states,aes(x = long, y = lat),color=\"darkslateblue\",shape=\".\") +\n  geom_point(data=world,aes(x=long,y=lat,group=group),shape=\".\",color=\"darkslateblue\") +\n  \n  # now we need to add our data \n  geom_point(data=map_geodata_dot,\n             mapping=aes(x=longitude,y=latitude,color=factor(gender)),\n             alpha=0.7,stroke=1,size=1,shape = 21,fill=NA) +\n  geom_point(data=map_geodata_dot,\n             mapping=aes(x=longitude,y=latitude),\n             alpha=0.7,shape=\".\",color=\"yellow3\",show.legend = T) +\n  geom_point(data=map_geodata,\n             mapping=aes(x=longitude,y=latitude),alpha=0.7,shape=\".\",color=\"yellow3\") +\n  geom_text(data=my_map_text_m,mapping=aes(x=longitude_m, y=latitude_m,label=cou_yr_m),\n            family=\"shadow_into_light\",color=\"gold\",hjust=-0.5) +\n  \n  coord_map(\"ortho\", orientation = c(3.849945, -103.525750, 0)) +\n  \n  guides(color = guide_legend(override.aes = list(size = 5)))+\n  scale_color_manual(values = pal_gender,labels=c(\"Male\",\"Female\")) +\n  labs(x=\"\",y=\"\",color=\"Gender\") +\n  theme_void() +\n  theme(text = element_text(family=\"shadow_into_light\",color=\"gold\"),\n        plot.background = element_rect(fill = \"midnightblue\", colour = \"midnightblue\"),\n        panel.background = element_rect(color=\"midnightblue\",fill=\"midnightblue\"),\n        axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = c(0.2,0.5),\n        legend.text = element_text(family=\"shadow_into_light\"),\n        legend.title = element_text(family=\"shadow_into_light\"))\n\n\nworld_west\n\nEast World\n\nworld_east<-  ggplot() +\n  \n  geom_point(data = states,aes(x = long, y = lat),color=\"darkslateblue\",shape=\".\") +\n  geom_point(data=world,aes(x=long,y=lat,group=group),shape=\".\",color=\"darkslateblue\") +\n  \n  # now we need to add our data \n  geom_point(data=map_geodata_dot,\n             mapping=aes(x=longitude,y=latitude,color=gender),\n             alpha=0.7,stroke=1,size=1,shape = 21,fill=NA,show.legend = F) +\n  geom_point(data=map_geodata_dot,\n             mapping=aes(x=longitude,y=latitude),alpha=0.7,shape=\".\",color=\"yellow3\") +\n  geom_point(data=map_geodata,\n             mapping=aes(x=longitude,y=latitude),alpha=0.7,shape=\".\",color=\"yellow3\") +\n  \n  geom_text(data=my_map_text_w,mapping=aes(x=longitude_w, y=latitude_w,label=cou_yr_w),\n            family=\"shadow_into_light\",color=\"gold\",hjust=-0.2) +\n  \n  coord_map(\"ortho\", orientation = c(19.982182, 46.595135, 0)) +\n  \n  scale_color_manual(values = pal_gender) +\n  labs(x=\"\",y=\"\",color=\"\") +\n  theme_void() +\n  theme(text = element_text(family=\"shadow_into_light\",color=\"gold\"),\n        plot.background = element_rect(fill = \"midnightblue\", colour = \"midnightblue\"),\n        panel.background = element_rect(color=\"midnightblue\",fill=\"midnightblue\"),\n        axis.line = element_blank(),\n        axis.text.x = element_blank(),\n        panel.grid = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        legend.position = \"none\")\n\n world_east \n\n\nlibrary(patchwork)\nlibrary(cowplot)\n\nmain_plot <- (world_west + world_east)# +\n  #theme_update(plot.background = element_rect(fill = \"midnightblue\", colour = \"midnightblue\"),\n  #             panel.background = element_rect(fill = \"midnightblue\", colour = \"midnightblue\"),\n  #             plot.margin = margin(0,0,0,0,unit = \"pt\"))\n\n\n# load the libraries for final touches\nlibrary(ggpubr)\n\n# ggarrange from {ggpubr} frames the plot to make side annotations\ngraphics <- ggpubr::ggarrange(main_plot)\n\nfinal_plot <- ggpubr::annotate_figure(graphics,\n                              top = text_grob(\"Global State of Ultra Running 2012-2021\",\n                                              color = c(\"gold\"), face = \"bold\", size = 32,\n                                              family=\"shadow_into_light\",vjust = 0.8),\n                              bottom = text_grob(\"DataSource: BjnNowak-Github Repo, RunRepeat.com-TidyTuesday week44\\n30DayMapChallenge day1 - Infographics: Federica Gazzelloni\",\n                                                 color = \"gold\",family=\"shadow_into_light\",\n                                                 hjust = 0.5, vjust = 0.5, x = 0.5, \n                                                 face = \"bold.italic\", size = 14))\n\nfinal_plot <- final_plot +\n  annotate(geom = \"text\", label = \"Top 6 Countries with faster Female runners at distances between 164 and 173 km\",\n         x = 0.5, y = 0.9,colour = \"gold\",size = 4,family = \"shadow_into_light\",fontface = \"bold\")+\n  annotate(geom = \"text\", label = \"Ranking number one faster\",\n         x = 0.91, y = 0.12,colour = \"gold\",size = 4,family = \"shadow_into_light\",fontface = \"bold\")\n\n\nlibrary(cowplot)\nlibrary(ggimage)\nlibrary(magick)\n\n# add the images for the legend keys\nimgrunners <- image_read(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w44/runner.png\")\n\n\n# ggdraw from {cowplot} draw the plot for setting the background colors of the side annotations\nfinal <- cowplot::ggdraw(final_plot) +\n  draw_image(imgrunners, x = 0.9, y = -0.45,width = 0.06) +\n  theme(plot.background = element_rect(fill = \"midnightblue\", colour = \"midnightblue\"))\n\n\n# save final plot\nragg::agg_png(here::here(\"/Users/federica/Documents/R/R_general_resourses/TidyTuesday/TidyTuesday/w44/w44_runners.png\"),\n              res = 320, width = 12, height = 8, units = \"in\")\nfinal\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w33_bea_Infrastructure_Investment/w33_bea_Infrastructure_Investment.html",
    "href": "tidytuesday/cases2021/posts2021/w33_bea_Infrastructure_Investment/w33_bea_Infrastructure_Investment.html",
    "title": "Bea Infrastructure Investment",
    "section": "",
    "text": "Introduction\nThe measurement of infrastructure in the U.S. National Economic Accounts (NEAs) considers different metrics, provided are the resources devoted to different types of infrastructure each year and a useful overview of trends.\nClassification of investment categories is provided by North American Industry Classification System (NAICS)\n\nTypes of infrastructure:\n\nBasic: transportation and utilities\nSocial: pubblic safety, education and health\nDigital: it excludes servers owned by private firms outside of NAICS 518 and 519\n\nthe analysis spans through 70 Years of investments from 1947 to 2017.\n\n\nThis analysis starts with analysing the classification of the investment categories by looking at:\n\n\nThe original datasets provided by the website are very useful to check whether the category and the meta category variables are homogeneous within the data sets:\n1 - Investment data set:\nInvestment data set is extracted from the original .xlsx file and shows the basic structure of the group categories on which the analysis is based.\n\ndf_inv_raw <- readxl::read_excel(\"infrastructure-data-may-2020.xlsx\", sheet = \"cu$inv\",skip = 2)\n\n\ndf_inv_raw <- df_inv_raw %>% \n  rename(group = ...1, category = ...2) %>% \n  filter(!is.na(category)) %>% \n  mutate(\n    meta_cat = if_else(!is.na(group), category, NA_character_), \n    group_num = group,\n    .after = \"category\"\n    ) \n\n\nDT::datatable(df_inv_raw %>% select(meta_cat,group,category))\n\nIn addtion it contains the gross investment variable which is the variable that will be used in the analysis as one of the factors to construct the Implicit Price Deflators index.\n\nnames(investment)\n\n2 - Chain investment data set:\nIt is extracted as the same as the investment set and it contains the same group of category variables except for one element in the category which is missing, it will be shown in more details further below in the analysis.\nIt doesn’t contains the gross investment variable but it the gross investment chain instead.\n\nnames(chain_investment)\n\n3 - IPD: Implicit Price Deflators data set:\n\nDT::datatable(df_IPD_inv_raw %>% select(meta_cat,group,category))\n\n\nipd <- df_IPD_inv_raw %>%\n  fill(meta_cat, group_num) %>%\n  pivot_longer(names_to = \"year\", values_to = \"gross_inv_ipd\", cols = `1947`:`2017`,\n               names_transform = list(year = as.integer)) %>% \n  filter(is.na(group)) %>% \n  select(-group) \n\nIPD set contains one more meta category as well as one more group number for the GDP element of the vector, which corresponds to group category number 0.\nIn fact the script for the IPD variable changes slightly with the addition of one more line of code.\nIt also contains the gross investment ipd variables whixh is the object of this study.\n\n ipd <- ipd %>%\n  mutate(meta_cat = if_else(category == \"GDP\", \"GDP\", meta_cat)) \n\nnames(ipd)\n\n\n\n\nData can also be loaded via:\n\ntuesdata <- tidytuesdayR::tt_load(2021, week = 33)\ntidytuesdayR::readme(tuesdata)\n\n\n\n\n\n\nThe original data sets are very useful to check whether the investments classified within their categories are homogeneous within the other data sets.\nThe analysis starts with checking of the three data sets, to see what are the common categories and if there are any differences. Next step would be to unify the three data sets to make a model for the Implicit Price Deflators.\n\nThe first data set Investment is the one used for understanding the composition of the variables. The other two are quite similar except for the investment variable, and two other differences in group category.\nLet’s start having a look at any missing values:\n\ninvestment <- tuesdata$investment\nDataExplorer::profile_missing(investment)\n\nNo values are missing in investment which is made of 5 variables:\n\ncategory: Category of investment (60 categories)\nmeta_cat: Group category of investment (16 meta categories)\ngroup_num: Group number of investment (1 to 20 number of sub-group of investment category)\nyear: Year of investment (from 1947 to 2017)\ngross_inv: Gross investment in millions of USD (which ranges from -194 to 500 900 millions $)\n\nThe meta_cat vector is the Group category of investment, and it has a sub-group numeric version named group_num, and a sub-sub-group of more specific categories of investments named: category.\nThe last variable is gross_inv i.e. Gross investment which is the sum of gross private domestic investment, government gross investment, and balance on current account, national income and product accounts.\n\nDT::datatable(head(investment,3))\n\n\n\n\n16 meta_cat:\n\nDT::datatable(investment%>%count(meta_cat))\n\n\ninvestment <- investment %>%\n  mutate(meta_cat = case_when(meta_cat==\"Total basic infrastructure\" ~ \"Basic\",\n                              TRUE~meta_cat ))\n\n\n\n\n\n20 sub-group of the meta_cat corresponding to group_num:\n\nDT::datatable(investment %>% count(group_num))\n\n\n\n\n\n60 sub-sub-group category vector:\n\nDT::datatable(investment %>% count(category))\n\nThe list of category contains a specification of the classification method for some of the elements in the vector, such as:\n\nPrivate communications equipment in NAICS 515, 517, 518, and 519\nPrivate computers in NAICS 515, 517, 518, and 519\nOffice buildings, NAICS 518 and 519\nPrivate software in NAICS 515, 517, 518, and 519\n\nThese elements are part of the Digital meta category of investment and the numbers at the ends are to specify that they are classified by the NAICS and only those classified in North America are accepted within the list of digital investments. So, other form of digital investments are not considered in this study.\n\ninvestment <- investment %>%\n  mutate(category = case_when(\n    category==\"Private communications equipment in NAICS 515, 517, 518, and 519\"~\"Private communications equipment\",\n    category==\"Private computers in NAICS 515, 517, 518, and 519\"~\"Private computers\",\n    category==\"Office buildings, NAICS 518 and 519\"~\"Office buildings\",\n    category==\"Private software in NAICS 515, 517, 518, and 519\"~\"Private software\",\n    TRUE~category)) \n\n\n\n\nExploratory analysis on Gross investments shows an increase in investments in the private sector as the most flourishing category within the last 70 years, followed by basic, S&L and social investments in infrastructures. Digital infrastructure and transports are still below 200 000 millions $. To be noted is that the private category for gross investment is still divided by amount of investments, but as a whole it releases the stronger increase over time.\n\nplot1\n\nA second visualization of the gross investment shows the category with the highest level of gross investment within the last 70 years in millions $.\n\nplot2\n\n\nplot3\n\n\nBefore continuing with other visualizations of investment trends, let’s check the other data sets to see the differences and then decide if to make a unified dataframe to use for comparison of gross investments, chained investments with implicit price deflactors (IPDs).\nThe first 4 variables are in common within all datasets, the next step is to check whether there are differences within the first 4 variables.\nThe second set doesn’t contains differences in classification when compared with investment set.\n\nchain_investment <- tuesdata$chain_investment\nDataExplorer::profile_missing(chain_investment)\n\n\nchain_investment <- chain_investment%>% \n  mutate(meta_cat = case_when(meta_cat==\"Total basic infrastructure\" ~ \"Basic\",\n                              TRUE~meta_cat ))\n\n59 chain investment categories:\n\nchain_investment <- chain_investment %>% \n  mutate(category=case_when(category==\"Private communications equipment in NAICS 515, 517, 518, and 519\"~\"Private communications equipment\",\n                            category==\"Private computers in NAICS 515, 517, 518, and 519\"~\"Private computers\",\n                            category==\"Office buildings, NAICS 518 and 519\"~\"Office buildings\",\n                            category==\"Private software in NAICS 515, 517, 518, and 519\"~\"Private software\",\n         TRUE~category)) \n\n“Office buildings” is the only category in “investment” df which doesn’t appear in “chain_investment” df.\n\ncat <- chain_investment %>% count(category) %>% select(-n) %>% unlist()\ninvestment %>% filter(!category %in% cat) %>% \n  count(category)\n\n\nImplicit Price Deflators (IPDs). An implicit price deflator is the ratio of the current-dollar value of a series, such as gross domestic product (GDP), to its corresponding chained-dollar value, multiplied by 100.\n\nipd <- tuesdata$ipd\nDataExplorer::profile_missing(ipd)\n\n\nmeta_inv <- investment%>%count(meta_cat)%>%select(-n)%>%unlist()\nipd%>%filter(!meta_cat%in%meta_inv)%>%count(meta_cat)\n\n\nipd <- ipd%>%\n  mutate(meta_cat = case_when(meta_cat==\"Total basic infrastructure\" ~ \"Basic\",\n                              meta_cat==\"Infrastructure\"~\"Total infrastructure\",\n                              meta_cat==\"Health care\"~\"Health\",\n                                TRUE~meta_cat ))\n\n\nipd <- ipd %>%\n  mutate(category=case_when(category==\"Private communications equipment in NAICS 515, 517, 518, and 519\"~\"Private communications equipment\",\n                            category==\"Private computers in NAICS 515, 517, 518, and 519\"~\"Private computers\",\n                            category==\"Office buildings, NAICS 518 and 519\"~\"Office buildings\",\n                            category==\"Private software in NAICS 515, 517, 518, and 519\"~\"Private software\",\n         TRUE~category)) \n\n60 categories are in the “Implicit Price Deflators” df\n\nipd_cats <-ipd %>% count(category)%>%unlist()\n\ncomparing it with the “investment” and “chain investment” categories, 6 of those have a slightly different name, the best wat to handle this for obtaining a unified data set made of the three sets is to have homogeneous values for the category variable.\nThese are the 6 categories in ipd to be changed:\n\ncat_investment <- investment%>%count(category)%>%select(-n)%>%unlist()\nipd_cats_to_be_renamed <- ipd%>%filter(!category%in%cat_investment)%>%count(category)%>%select(-n)%>%unlist()\n\nipd_cats_to_be_renamed\n\nThese 6 categories are in the investment data set and we want to use these names for the category variable for all the sets:\n\nselected_categories <- investment %>% filter(!category %in% ipd_cats) %>% count(category,group_num) %>% arrange(group_num)\n\nselected_categories\n\n\nipd <- ipd %>% \n  mutate(category = case_when(\n    category == \"Basic\" ~ \"Total basic infrastructure\",\n    category == \"Social\" ~ \"Total social infrastructure\",\n    category == \"Digital\" ~ \"Total digital infrastructure\",\n    category == \"Health care\" ~ \"Health\",\n    category == \"Communications structures\" ~ \"Private communications structures\",\n    TRUE ~ category\n  ))\n\nLet’s see how meta_cat of these 6 categories perform:\n\nplot4\n\n\ntotal_inv_df <- ipd %>% \n  count(category,meta_cat,year,gross_inv_ipd) %>% \n  group_by(year,meta_cat) %>%\n  summarize(total=ifelse(!is.na(round(sum(gross_inv_ipd))),round(sum(gross_inv_ipd)), 0)) %>%\n  ungroup() %>%\n  filter(!total==0) \n\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext_auto()\nshowtext_opts(dpi = 320)\nfont_add_google(\"Roboto Condensed\", \"roboto condensed\")\n\n\nplot5\n\n\nlibrary(patchwork)\nlibrary(ggpubr)\nlibrary(cowplot)\n\n\nimg <- png::readPNG('images.png')\n\n \n\ngraphics <- ggarrange(plot5) \n\nfinal_plot <- annotate_figure(graphics,\n               top = text_grob(\"IPDs Group investment categories\\n\", \n                               color = c(\"#FFD700\"), face = \"bold\", size = 34,\n                               family=\"roboto condensed\"),\n               bottom = text_grob(\"BEA: measurement of infrastructure in the U.S. National Economic Accounts (NEAs)\\nInfographic: @fgazzelloni\\n DataSource: TidyTuesday Week33: BEA Infrastructure Investment\",\n                                  color = \"#6C7B8B\",family=\"roboto condensed\",\n                                  hjust = 0.5, x = 0.5, face = \"bold.italic\", size = 10),\n               left = text_grob(\"\", color = c(\"#778899\"), rot = 90,size=10),\n               right = text_grob(bquote(\"\"), color=c(\"#778899\"),rot = 90,size=10),\n               fig.lab = \"TidyTuesday week33\", fig.lab.face = \"bold.italic\",fig.lab.size=8,\n               fig.lab.pos=\"bottom.right\"\n)\n\nfinal_plot <- final_plot +\n  annotate(geom = \"text\", label=\"values of the implicit price deflator ratio\",x = 0.25, y = 0.92, \n           colour = \"black\", face=\"bold\",size = 7,family=\"roboto condensed\") +\n  annotate(geom = \"text\", label=\"Digital just started in 1978 and followed \\nwith a deep decline during the last 40 years\",x = 0.70, y = 0.68, colour = \"#FF7F00\", size = 5,family=\"roboto condensed\") \n\n  \n\nfinal <- ggdraw() +\n  draw_image(img,  x = -0.4, y = -0.48, scale = .15) +\n  draw_plot(final_plot)\n\nfinal\n showtext.auto(enable = FALSE) \n\n\nragg::agg_png(\"w33_bea2.png\",\n              res = 320, width = 14, height = 8, units = \"in\")\nfinal\n\ndev.off()\n\nInvestment on Electric power only appear starting from 1993 with a ratio of 336:\n\nlist<-total_inv_df %>% filter(year==1992)%>%count(meta_cat)%>%select(-n)%>%unlist()\ntotal_inv_df %>% filter(year==1993,!meta_cat%in%list)\n\nmeta_cat are the Group category of investment, there are 4 values which are different within the sets:\n\nHealth care = Health\nInfrastructure = Total infrastructure\nBasic = Total basic infrastructure\nGDP\n\nWe need to add GDP as further meta_cat for both investment and chain_investment sets, and chenge the other three values into common values as shown above.\n\ninv_meta_cats <- investment %>% count(meta_cat) %>% select(-n) %>% unlist()\n\nipd %>% filter(!meta_cat %in% inv_meta_cats) %>% count(meta_cat)\n\nGDP is the only left meta_cat category, that it is not present in the other sets.\n\nipd %>% filter(!meta_cat %in% inv_meta_cats) %>% count(meta_cat)\n\nWhat about category variable? What are the differences in ipd set when compared with the other two?\nAs seen investment and chain_investment sets have the same category variables except for one variable which is “Office buildings”, so next step is to find the differences of this vector in ipd set:\n\ncat_inv <- investment %>% count (category) %>% select(-n) %>% unlist\nipd %>% filter(!category %in% cat_inv) %>% count(category)\n\nwe need to convert these values in ipd set:\n\nBasic = Total basic infrastructure\nCommunications structures = Private communications structures\nDigital = Total digital infrastructure\nGDP\nHealth care = Health\nSocial = Total social infrastructure\n\nFinally, GDP is the category group number 0 which is not in investment and chain investment sets, but only in IPD. While “Office buildings” is only in investment.\n\nipd <- ipd %>% \n  mutate(category = case_when(\n    category==\"Basic\"~\"Total basic infrastructure\",\n    category==\"Communications structures\"~\"Private communications structures\",\n    category==\"Digital\"~\"Total digital infrastructure\",\n    category==\"Health care\"~\"Health\",\n    category==\"Social\"~\"Total social infrastructure\",\n    TRUE~category))\n\n\nipd %>% filter(!category %in% cat_inv) %>% count(category)\n\nThe new data sets will contain the 4 common variables plus these other three:\n\ngross_inv: Gross investment in millions of USD\ngross_inv_chain: Gross investment (chained 2021 dollars) in millions of USD\ngross_inv_ipd: Implicit Price Deflators (IPDs)\n\nThe Implicit Price Deflators (IPDs) is obtained as an index result of:\n[ (gross_inv *100) / (gross_inv_chain *100) ] *100\nThe ipd set contains some missing values, these values are the results of 0 investments for some of the selected categories within the years.\n\nipd %>% filter(is.na(gross_inv_ipd)) %>% count(meta_cat,category)\n\nLet’s calculate the gross_inv_ipd vector with the formula, assigning its value to a different name vector and then check the missing values. To do this we need to join the three sets together:\n\ninvestment_full <- investment%>%\n  full_join(chain_investment,by=c(\"category\",\"meta_cat\",\"group_num\",\"year\")) %>%\n  full_join(ipd,by=c(\"category\",\"meta_cat\",\"group_num\",\"year\")) %>%\n  #filter(meta_cat==\"GDP\"| category==\"Office buildings\") %>% \n  mutate(gross_inv_chain = if_else(category==\"Office buildings\",0,gross_inv_chain),\n         gross_inv_ipd = if_else(gross_inv<=0,0,gross_inv_ipd),\n         gross_inv_ipd2 = if_else(gross_inv_chain==0,0,((gross_inv/100)/(gross_inv_chain/100))*100),\n         gross_inv_ipd2 = round(gross_inv_ipd2,2))\n  #DataExplorer::profile_missing()"
  },
  {
    "objectID": "tidytuesday/cases2021/posts2021/w51_spice_girls/w51_spice_girls.html",
    "href": "tidytuesday/cases2021/posts2021/w51_spice_girls/w51_spice_girls.html",
    "title": "Spice Girls",
    "section": "",
    "text": "library(tidyverse)\n\nstudio_album_tracks <- readr::read_csv(\"https://github.com/jacquietran/spice_girls_data/raw/main/data/studio_album_tracks.csv\")\n\n\nstudio_album_tracks%>%select(contains(\"key\"))%>%distinct()%>%arrange(key)\n\ndf<-studio_album_tracks%>%select(danceability,\n                                 year=album_release_year,\n                                 #mode,\n                                 energy,\n                                 loudness,\n                                 speechiness,\n                                 acousticness,\n                                 instrumentalness,\n                                 liveness,valence,duration_ms,tempo)\n\nugly <- ggthemr::define_palette(\n  swatch = c('black', 'red', 'green', 'blue', 'brown', 'purple', 'yellow'), \n  gradient = c(lower = 'red', upper = 'green')\n)\n\nggthemr::ggthemr(ugly)\n\nlibrary(extrafont)\nloadfonts()\nfamily=\"Impact\"\n\nviolins<-df%>%\n  select(-year,-instrumentalness)%>%\n  #recipe()%>%\n  #step_normalize(all_numeric())\n  scale()%>%as.data.frame()%>%mutate(year=df$year)%>%\n  #mutate(duration_ms=duration_ms/sum(duration_ms))%>%#count(duration_ms)\n  pivot_longer(cols=c(1:8),names_to=\"variables\",values_to=\"values\")%>%\n  #pull(values)%>%summary()\n  mutate(variables=tools::toTitleCase(variables),\n         variables=case_when(variables==\"Duration_ms\"~\"Duration in ms\",\n                             TRUE~variables))%>%\n  #mutate(across(variables, factor, levels=c(\"\")\n  ggplot(aes(x=factor(year),y=values,fill=variables))+\n  geom_boxplot(alpha=0.7)+\n  geom_violin(alpha=0.5)+\n  geom_point(color=\"gold\",size=0.2)+\n  facet_wrap(vars(variables),scales=\"free\",nrow = 2)+\n  scale_fill_brewer(type = \"seq\", palette = \"Spectral\")+\n  guides(fill=\"none\")+\n  labs(x=\"\",title=\"\")+\n  theme(text = element_text(family=family),\n        axis.title.y = element_blank(),\n        plot.background = element_blank(),\n        panel.background = element_blank(),\n        panel.grid = element_line(size=0.3),\n        strip.text = element_text(color=\"hotpink\",size=12),\n        strip.background = element_rect(color=\"black\",fill=\"black\"),\n        axis.line = element_line(color=\"hotpink\",size=2),\n        axis.text.x = element_text(color=\"gold\",size=10),\n        axis.text.y = element_text(color=\"darkolivegreen2\",size=10))\n\n#violins\nbg<-ggplot()+\n  geom_blank()+\n  theme_void()+\n  theme(plot.background = element_rect(color=\"black\",fill=\"black\"))\n\nlibrary(cowplot)\n\nfinal<-ggdraw()+\n  draw_plot(bg)+\n  draw_image(\"w51/spice_bg.png\",scale = 1,\n             y=0.2) +\n # draw_image(\"w51/spices_image.jpg\",scale = 1.2) +\n            # scale=0.4,x=0.25,y=-0.28)+\n  draw_plot(violins,height = 0.55,y=-0.04)+\n  draw_label(\"What Makes a Song Likeable?\",\n             x=0.5,y=0.95,size=42,color=\"gold\",\n             fontfamily = family,fontface = \"bold\")+\n  draw_label(\"What Makes a Song Likeable?\",\n             x=0.5,y=0.95,size=41,color=\"hotpink\",\n             fontfamily = family,fontface = \"bold\")+\n  draw_label(\"DataViz: Federica Gazzelloni\",\n             angle=90,size=9,x=0.02,y=0.8,\n             fontfamily=family)+\n  draw_label(\"DataSource: Spice Girls by Jacquie Tran\",\n             angle=0,size=9,x=0.8,y=0.49,\n             fontfamily=family)+\n  \n  draw_label(\"1996\",\n             angle=15,size=25,x=0.5,y=0.87,\n             fontfamily=family)+\n  draw_label(\"1997\",\n             angle=15,size=23,x=0.65,y=0.83,\n             fontfamily=family)+\n  draw_label(\"2000\",\n             angle=15,size=27,x=0.8,y=0.85,\n             fontfamily=family)+\n  \n  \n  draw_label(\"1996\",color=\"white\",\n             angle=15,size=24,x=0.5,y=0.87,\n             fontfamily=family)+\n  draw_label(\"1997\",color=\"white\",\n             angle=15,size=22,x=0.65,y=0.83,\n             fontfamily=family)+\n  draw_label(\"2000\",color=\"white\",\n             angle=15,size=26,x=0.8,y=0.85,\n             fontfamily=family) +\n  draw_label(\"scaled values\",color=\"white\",\n             angle=0,size=6,x=0.96,y=0.46,\n             fontfamily=family)\n\n\n####### SAVING ######################################\nragg::agg_png(here::here(\"w51/spicegirls.png\"),\n              res = 320, width = 8, height = 8, units = \"in\")\nfinal\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2021/index.html",
    "href": "tidytuesday/cases2021/index.html",
    "title": "TidyTuesday 2021",
    "section": "",
    "text": "Starbucks drinks\n\n\nNetworks\n\n\n\n\n\n\nDec 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpice Girls\n\n\nNetworks\n\n\n\n\n\n\nDec 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpiders\n\n\nNetworks\n\n\n\n\n\n\nDec 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Cup Cricket\n\n\nNetworks\n\n\n\n\n\n\nNov 30, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Who\n\n\nNetworks\n\n\n\n\n\n\nNov 23, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearning with afrilearndata\n\n\nNetworks\n\n\n\n\n\n\nNov 9, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaking maps with R\n\n\nNetworks\n\n\n\n\n\n\nNov 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUltra Trail Running\n\n\nNetworks\n\n\n\n\n\n\nOct 26, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBig Pumpkins\n\n\nNetworks\n\n\n\n\n\n\nOct 19, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal Seafood\n\n\nNetworks\n\n\n\n\n\n\nOct 12, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegistered Nurses\n\n\nNetworks\n\n\n\n\n\n\nOct 5, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNBER Papers\n\n\nNetworks\n\n\n\n\n\n\nSep 28, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmmy Awards\n\n\nNetworks\n\n\n\n\n\n\nSep 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBillboard\n\n\nNetworks\n\n\n\n\n\n\nSep 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFORMULA1\n\n\nNetworks\n\n\n\n\n\n\nSep 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBird Baths\n\n\nNetworks\n\n\n\n\n\n\nAug 31, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLemurs\n\n\nNetworks\n\n\n\n\n\n\nAug 24, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarTrek\n\n\nNetworks\n\n\n\n\n\n\nAug 17, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBea Infrastructure Investment\n\n\nNetworks\n\n\n\n\n\n\nAug 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParalympic\n\n\nNetworks\n\n\n\n\n\n\nAug 3, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOlympic Medals\n\n\nNetworks\n\n\n\n\n\n\nJul 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUS drought\n\n\nNetworks\n\n\n\n\n\n\nJul 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScoobydoo\n\n\nNetworks\n\n\n\n\n\n\nJul 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInternational Independence Days\n\n\nNetworks\n\n\n\n\n\n\nJul 6, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimal Rescues\n\n\nNetworks\n\n\n\n\n\n\nJun 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUS Public Parks\n\n\nNetworks\n\n\n\n\n\n\nJun 22, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDubois Challenge\n\n\nNetworks\n\n\n\n\n\n\nJun 15, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreat Lakes Fish\n\n\nNetworks\n\n\n\n\n\n\nJun 8, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvivors\n\n\nNetworks\n\n\n\n\n\n\nJun 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMario Kart World\n\n\nNetworks\n\n\n\n\n\n\nMay 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsk a Manager Survey\n\n\nNetworks\n\n\n\n\n\n\nMay 18, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUS Broadband\n\n\nNetworks\n\n\n\n\n\n\nMay 11, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWater Access\n\n\nNetworks\n\n\n\n\n\n\nMay 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCeo Departures\n\n\nNetworks\n\n\n\n\n\n\nApr 27, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNETFLIX & Upwards\n\n\nNetworks\n\n\n\n\n\n\nApr 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUS Post Office\n\n\nNetworks\n\n\n\n\n\n\nApr 13, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal deforestation\n\n\nEnvironment\n\n\n\nFederica Gazzelloni\n\n\nApr 6, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Pudding\n\n\nConnections\n\n\n\nFederica Gazzelloni\n\n\nMar 30, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUN Votes\n\n\nSocial Networks\n\n\n\nFederica Gazzelloni\n\n\nMar 23, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidytuesday/cases2023/index.html",
    "href": "tidytuesday/cases2023/index.html",
    "title": "TidyTuesday 2023",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidytuesday/cases2022/index.html",
    "href": "tidytuesday/cases2022/index.html",
    "title": "TidyTuesday 2022",
    "section": "",
    "text": "The content is in development. Interested in contributing to Unlocking the power of data visualization with R? Check out our call for contributions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStar Trek Timelines\n\n\nNetworks\n\n\n\n\n\n\nDec 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorld Freedom index\n\n\nNetworks\n\n\n\n\n\n\nDec 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeather Forecast Accuracy\n\n\nNetworks\n\n\n\n\n\n\nDec 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonthly State Retail Sales\n\n\nNetworks\n\n\n\n\n\n\nDec 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElevators\n\n\nNetworks\n\n\n\n\n\n\nDec 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFIFA World Cup\n\n\nNetworks\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUK Museums\n\n\nNetworks\n\n\n\n\n\n\nNov 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb page metrics\n\n\nNetworks\n\n\n\n\n\n\nNov 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRadio Stations\n\n\nNetworks\n\n\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDog breeds\n\n\nNetworks\n\n\n\n\n\n\nNov 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHorror Movies\n\n\nNetworks\n\n\n\n\n\n\nNov 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreat British Bakeoff\n\n\nNetworks\n\n\n\n\n\n\nOct 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStranger things dialogue\n\n\nNetworks\n\n\n\n\n\n\nOct 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRavelry data\n\n\nNetworks\n\n\n\n\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct Hunt products\n\n\nNetworks\n\n\n\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtists in the USA\n\n\nNetworks\n\n\n\n\n\n\nSep 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHydro Wastewater plants\n\n\nNetworks\n\n\n\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBigfoot\n\n\nNetworks\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLEGO database\n\n\nNetworks\n\n\n\n\n\n\nSep 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPell Grants\n\n\nNetworks\n\n\n\n\n\n\nAug 30, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCHIP dataset\n\n\nNetworks\n\n\n\n\n\n\nAug 23, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpen Source Psychometrics\n\n\nNetworks\n\n\n\n\n\n\nAug 16, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFerris Wheels\n\n\nNetworks\n\n\n\n\n\n\nAug 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOregon Spotted Frog\n\n\nNetworks\n\n\n\n\n\n\nAug 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBring your own data\n\n\nNetworks\n\n\n\n\n\n\nJul 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTechnology Adoption\n\n\nNetworks\n\n\n\n\n\n\nJul 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuropean flights\n\n\nNetworks\n\n\n\n\n\n\nJul 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSan Francisco Rentals\n\n\nNetworks\n\n\n\n\n\n\nJul 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUK Gender pay gap\n\n\nNetworks\n\n\n\n\n\n\nJun 28, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJuneteenth\n\n\nNetworks\n\n\n\n\n\n\nJun 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUS Drought\n\n\nNetworks\n\n\n\n\n\n\nJun 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPride Corporate Accountability Project\n\n\nNetworks\n\n\n\n\n\n\nJun 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompany reputation poll\n\n\nNetworks\n\n\n\n\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWomens Rugby\n\n\nNetworks\n\n\n\n\n\n\nMay 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEurovision\n\n\nNetworks\n\n\n\n\n\n\nMay 17, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNYTimes best sellers\n\n\nNetworks\n\n\n\n\n\n\nMay 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolar/Wind utilities\n\n\nNetworks\n\n\n\n\n\n\nMay 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKaggle Hidden Gems\n\n\nNetworks\n\n\n\n\n\n\nApr 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCrossword Puzzles and Clues\n\n\nNetworks\n\n\n\n\n\n\nApr 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndoor Air Pollution\n\n\nNetworks\n\n\n\n\n\n\nApr 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigital Publications\n\n\nNetworks\n\n\n\n\n\n\nApr 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollegiate Sports Budgets\n\n\nNetworks\n\n\n\n\n\n\nMar 29, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBBaby names\n\n\nNetworks\n\n\n\n\n\n\nMar 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErasmus student mobility\n\n\nNetworks\n\n\n\n\n\n\nMar 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternative Fuel Stations\n\n\nNetworks\n\n\n\n\n\n\nMar 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDuBoisChallenge2022\n\n\nNetworks\n\n\n\n\n\n\nFeb 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTuskegee Airmen\n\n\nNetworks\n\n\n\n\n\n\nFeb 8, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoard games\n\n\nNetworks\n\n\n\n\n\n\nJan 25, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCRAN/BIOC Vignettes\n\n\nNetworks\n\n\n\n\n\n\nJan 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChocolate Bar ratings\n\n\nNetworks\n\n\n\n\n\n\nJan 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBee Colony losses\n\n\nNetworks\n\n\n\n\n\n\nJan 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBring your own data from 2022!\n\n\nNetworks\n\n\n\n\n\n\nJan 4, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w45_radio_stations/w45_radio_stations.html",
    "href": "tidytuesday/cases2022/posts2022/w45_radio_stations/w45_radio_stations.html",
    "title": "Radio Stations",
    "section": "",
    "text": "library(tidyverse)\n# unzip(\"data/FM_service_contour_current.zip\")\n\nSource of data: https://www.fcc.gov/media/radio/fm-service-contour-data-points\nthis contour data is only generated once for each application ID number use https://www.fcc.gov/media/radio/fm-query to associate specific service contour records with the proper station or application data, match the application ID number or LMS application ID the record with the corresponding data in the LMS database.\n\nraw_contour <- read_delim(\n  \"data/FM_service_contour_current.txt\",\n  delim = \"|\"\n)\n# save(raw_contour,file=\"data/raw_contour.RData\")\n# load(\"data/raw_contour.RData\")\n\nraw_contour%>%names\n#  [1] \"application_id\"     \"service\"           \n#  [3] \"lms_application_id\" \"dts_site_number\"   \n#  [5] \"transmitter_site\" \n\n\nconv_contour <- raw_contour |>\n  select(-last_col()) |>\n  set_names(nm = c(\n    \"application_id\", \"service\", \"lms_application_id\", \"dts_site_number\", \"transmitter_site\",\n    glue::glue(\"deg_{0:360}\")\n  ))\n\n# save(conv_contour,file= \"data/conv_contour.RData\")\n\nlng_lat <- conv_contour |>\n  separate(\n    transmitter_site, \n    into = c(\"site_lat\", \"site_long\"), \n    sep = \" ,\")\n\n# save(lng_lat,file= \"data/lng_lat.RData\")\nload(\"data/lng_lat.RData\")\n\n\nlng_lat%>%count(site_lat,site_long,sort=T)\n\n\ndf_coords <- lng_lat%>%\n  select(-dts_site_number) %>%\n  distinct() %>%\n  drop_na() %>%\n  mutate_all(trimws)%>%\n  mutate(application_id=as.numeric(application_id),\n         site_lat=as.numeric(site_lat),\n         site_long=as.numeric(site_long))\n\ndf_coords %>%count(service)\n\n\ndf_coords1 <- df_coords %>%\n  as.data.frame() %>%\n  #slice(1:30) %>%\n  arrange(service) %>%\n  filter(service==\"FM\") \n\ndf_coords1%>%head()\n\n\nlibrary(sf) # spatiotemporal\nworld <- sf::st_as_sf(maps::map(\"world\", plot = FALSE, fill = TRUE))\nstates <- sf::st_as_sf(maps::map(\"state\", plot = FALSE, fill = TRUE))\nstates\n\n\ndf_coords1 %>%\n  st_as_sf(coords=c(4,3),crs=4326)%>%\n  st_bbox()\n\n\nggplot(world) +\n  geom_sf(fill=NA) +\n  geom_point(data = df_coords1,\n             mapping = aes(site_long,site_lat),\n             shape=\".\",color=\"red\",\n             inherit.aes = F) +\n  coord_sf(xlim = c(-171.73031,-25),ylim = c(10,71.29194))+\n  theme_classic() +\n  theme(axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\ndf_coords <- lng_lat%>%\n  select(-dts_site_number) %>%\n  distinct() %>%\n  drop_na() %>%\n  mutate_all(trimws)%>%\n  mutate(application_id=as.numeric(application_id),\n         site_lat=as.numeric(site_lat),\n         site_long=as.numeric(site_long))\n\n\ndf_coords %>% count(service)\n  \ndf_coords1 <- df_coords %>%\n  as.data.frame() %>%\n  #slice(1:30) %>%\n  arrange(service) %>%\n  filter(service==\"FM\") \n\ndf_coords2 <- df_coords1 %>%\n  pivot_longer(cols = deg_0:deg_360,\n    names_to = \"angle\",\n    values_to = \"values\") \n\ndf_coords3 <- df_coords2 %>%\n  mutate(angle = str_remove(angle, \"deg_\"),\n         angle = as.integer(angle))\n\n# lms_application_id\ndf_coords3[361,]\ndf_coords3%>%\n  filter(angle==360)%>%head\n\n\n\ndf_coords4 <- df_coords3 %>%\n  separate(values,\n    into = c(\"deg_lat\", \"deg_lng\"),\n    sep = \" ,\")\n\n\ndf_coords5 <- df_coords4 %>%\n  mutate(deg_lat= ifelse(is.na(deg_lng),site_lat,deg_lat),\n         deg_lng= ifelse(is.na(deg_lng),site_long,deg_lng))\n  \n# save(df_coords5,file=\"rdata/df_coords5.RData\")\n\ndf_coords5%>%\n  DataExplorer::profile_missing()\n\n\ndf_coords5%>%dim # 4550766\ndf_coords5%>%head\n\n\ndf_coords5%>%count(application_id)\n\n\ndf_coords_750_2037197 <- df_coords5%>%\n  filter(application_id%in%c(750,2037197)) # dim # 361\n  \n\ndf_coords_750_2037197%>%count(application_id)\ndf_coords_750_2037197%>%\n  filter(application_id==750)\nst_bbox(world)\n\n  ggplot() +\n  #geom_sf(fill=NA) +\n  geom_point(data = df_coords_750_2037197,\n             mapping = aes(deg_lng,deg_lat),\n             #shape=\".\",\n             color=\"red\",\n             inherit.aes = F) \n    coord_sf(xlim = c(-180.00000,190.27084),ylim = c(-85.19218,83.59961))+\n  #coord_sf(xlim = c(-171.73031,-25),ylim = c(10,71.29194))+\n  theme_classic() \n  theme(axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\ndf_coords_selected_id <- df_coords5%>% \n  arrange(application_id) %>% \n  count(application_id) %>% \n  slice(1:10) %>%\n  select(-n) %>% \n  unlist()\n\ndf_coords5_selection <- df_coords5 %>%\n  filter(application_id%in%df_coords_selected_id) %>%\n  distinct() # dim # 361\ndf_coords5%>%dim  \ndf_coords5_selection%>%names\n\ndf_coords5_selection_sf<- df_coords5_selection%>%\n  st_as_sf(coords=c(8,7),crs=4326) \n\ndf_coords51 <- df_coords5%>%\n  st_as_sf(coords=c(8,7),crs=4326) \n\n  ggplot(world) +\n    geom_sf(fill=NA) +\n    geom_sf(data = df_coords51, \n            aes(color=application_id),\n            shape=21,stroke=0.01,\n            #shape=\".\",\n            alpha=0.2,\n            inherit.aes = F) +\n    coord_sf(xlim = c(-171.73031,-25),ylim = c(10,71.29194))+\n      theme_classic() +\n  theme(axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\ndf_coords5%>%count(application_id)\n\n\ndf_coords5_all_sf <- df_coords5 %>%\n   st_as_sf(coords=c(7,6),crs=4326) \n\nggplot(world) +\n    geom_sf(fill=NA) +\n    geom_sf(data = df_coords5_all_sf, \n            #aes(color=application_id),\n            shape=21,stroke=0.01,\n            #shape=\".\",\n            alpha=0.2,\n            inherit.aes = F) +\n    coord_sf(xlim = c(-171.73031,-25),ylim = c(10,71.29194))+\n      theme_classic() +\n  theme(axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\nmap\n\n\nstate_stations <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-08/state_stations.csv')\n\n\nstate_stations%>%names\n\n\nstate_stations1 <- state_stations%>%\n  select(call_sign,frequency,state,city,format)\n\nstate_stations1%>%head\n\n\nstate_stations%>%DataExplorer::profile_missing()\n\n\nstate_stations%>%dim\n\n\ntuesdata <- tidytuesdayR::tt_load(2022, week = 45)\nstation_info <- tuesdata$station_info\n\n\nstation_info%>%dim\nstation_info%>%DataExplorer::profile_missing()\n\n\nstation_info%>%count(service)\n\n\nstation_info1 <- station_info%>%\n  select(call_sign,facility_id) \nstation_info1%>%head\n\n\nstation_info1%>%DataExplorer::profile_missing()\n\n\ndf_coords2 <- df_coords1 %>%\n  mutate(application_id=as.numeric(application_id))# 12604\n\nstation_info1 %>% distinct() %>%dim # 2065\n\n\njoin <- state_stations1 %>% # 17186\n  inner_join(station_info1,by=\"call_sign\")\n\n\nstate_stations1 %>% # 17186\n  inner_join(station_info1,by=\"call_sign\") %>% head # left 17186 # right 2065 # inner 2037 # full 17214\n  right_join(df_coords5,by=c(\"facility_id\"=\"application_id\")) %>%DataExplorer::profile_missing()\n\n  df_coords5%>%distinct()%>%dim # 4551127\n  join %>%distinct()%>%dim # 2037\nsetdiff(df_coords5$application_id,join$facility_id)  %>%length() # 12551\nsetdiff(join$facility_id,df_coords5$application_id)  %>%length() # 2049 # 2021\n\n\nfull_join<-join %>%\n  inner_join(df_coords5,by=c(\"facility_id\"=\"application_id\"))\n  \n\nfull_join%>% # dim # 5776\n  relocate(call_sign,facility_id,lms_application_id)%>%\n  distinct()%>%dim # 5776\n  # DataExplorer::profile_missing()\n  \n  \nfull_join %>%head\n\n\nfull_join%>%names\n\n\nfull_join%>%head\n\n\nfull_join1<- full_join%>%\n  mutate(format=str_to_title(format)) # %>%\n    #filter(format==\"Alternative Rock\")\n  # count(format,sort=T)\nfull_join1%>%dim\n\n\nfull_join1%>%\n  group_by(state) %>%\n  mutate()\n\n\nfull_join_sf <- full_join1 %>%\n   st_as_sf(coords=c(13,12),crs=4326) \n\n\nfull_join_sf_centr <- full_join1 %>%\n  group_by(city,format)%>%\n  summarize(site_lat=mean(range(site_lat)),site_long=mean(range(site_long)),.groups=\"drop\")%>% \n  ungroup() %>%\n   st_as_sf(coords=c(4,3),crs=4326) \n\n\nggplot(world) +\n    geom_sf(fill=NA) +\n  geom_sf_text(data = full_join_sf_centr,\n            aes(label=format),\n            #label.padding = unit(0.01, \"lines\"),\n            size=2,\n            inherit.aes = F) +\n    geom_sf(data = full_join_sf, \n            aes(color=factor(format)),\n            shape=21,stroke=0.01,\n            #shape=\".\",\n            alpha=0.2,\n            inherit.aes = F) +\n    coord_sf(xlim = c(-171.73031,-25),ylim = c(10,71.29194))+\n      theme_classic() +\n  theme(axis.line = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank())\n\n\nggsave(\"test.png\")"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w25_juneteenth/w25_juneteenth.html",
    "href": "tidytuesday/cases2022/posts2022/w25_juneteenth/w25_juneteenth.html",
    "title": "Juneteenth",
    "section": "",
    "text": "library(tidyverse)\nlibrary(showtext)\nfont_add(family = \"Public Sans Thin\",\n         regular = \"PublicSans-Thin.ttf\")\n  \nfont_add(family=\"PublicSans-Medium\",\n         regular=\"PublicSans-Medium.ttf\")\n  \nshowtext_auto()\n  #showtext::showtext_opts(dpi=320)\n\n\n colors<- c(\"#dbcab9\", #warm-gre,\n   \"#cf2e49\", #red\n   \"#E97E7E\", #pale-red\n   \"#efb441\", #orange\n   \"#5f6faa\", #blue\n   \"#5f705d\", #dark-green\n   \"#d4c0a1\", #light-brown\n   \"#6c452f\", #dark-brown\n   \"black\")\n\n\ncensus <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-06-16/census.csv')\n\n\ndf_census<-census %>% #count(year)\n  filter(!region==\"USA Total\") %>%\n  mutate(division=ifelse(is.na(division),\"Other\",division)) %>%\n  pivot_longer(cols = c(-region,-division,-year),names_to=\"names\",values_to=\"values\") %>%\n  mutate(names = str_to_title(names),\n         names = gsub(\"_\",\" \",names)) %>%\n  filter(!values==0) %>%arrange(values) %>% \n  group_by(year)%>%\n  mutate(avg_values=mean(values)) %>%\n  ungroup() %>% \n  mutate(division=reorder(factor(division),values),\n         region=reorder(factor(region),values))  \n  \ndf_census\n\n\nblack_free<- df_census %>% \n  filter(names==\"Black free\") %>%\n  group_by(year)%>%\n  summarize(tot=sum(values)) %>%\n  ungroup() %>%\nmutate(pct=round(tot/sum(tot)*100,2),\n       year=as.factor(year)) \n\nblack_slaves<- df_census %>% #count(names)\n  filter(names==\"Black slaves\") %>%\n  group_by(year)%>%\n  summarize(tot=sum(values)) %>%\n  ungroup() %>%\nmutate(pct=round(tot/sum(tot)*100,2),\n       year=as.factor(year)) \n\nblack<- df_census %>% #count(names)\n  filter(names==\"Black\") %>%\n  group_by(year)%>%\n  summarize(tot=sum(values)) %>%\n  ungroup() %>%\nmutate(pct=round(tot/sum(tot)*100,2),\n       year=as.factor(year))\n\n\nbar_plot <- ggplot()+\n  aes(x=desc(year), y=pct, fill=pct) +\n  geom_bar(data=black_free,width = 4, stat = \"identity\",color=\"black\",fill=\"#5f705d\",position=\"identity\") +\n  geom_bar(data=black_slaves,width = 0.5, stat = \"identity\",color=\"black\",fill=\"#E97E7E\",position=\"identity\") +\n  geom_bar(data=black,width = 0.2, stat = \"identity\",color=\"black\",fill=\"#efb441\",position=\"identity\") +\n  scale_y_continuous(expand = expansion(mult=c(0,1),add=c(0,0)))+\n  #scale_x_discrete(expand = expansion(mult=c(5,0),add=c(0,0)))\n  coord_polar(\"y\", start=-89.55, clip = 'off') +\n  theme_void()+\n  theme(plot.title = element_text(hjust=0.5),\n        plot.subtitle = element_text(hjust=0.5),\n        plot.background = element_rect(fill=\"#d4c0a1\",color=\"#d4c0a1\"),\n        panel.background = element_rect(fill=\"#d4c0a1\",color=\"#d4c0a1\"))\n\nbar_plot\n\n\nlibrary(cowplot)\n ggdraw()+\n   #draw_plot(bar_plot)+\n   draw_image(\"bar_plot.png\",scale=2,x=0.1,y=-0.2)+\n   draw_label(label = \"1790 1800 1810 1820 1830 1840 1850 1860 1870\",\n              x=0.35,y=0.25,size=12)+\n   draw_label(\"NEGROE status transition\",x=0.5,y=0.9,fontfamily = \"PublicSans-Medium\")+\n   draw_label(\"ABRAHAM LINCOLN: “ON THE 1ST DAY OF JANUARY, A.D. 1863, ALL PERSONS HELD AS SLAVES WITHIN ANY STATE...\n              IN REBELLION AGAINST THE U.S. SHALL BE THEN, THENCEFORWARD AND FOREVER FREE”\",\n              x=0.1,y=0.8,hjust=0,\n              size=8)+\n   draw_label(\"How to read it:\\nInspired by #DuboisChallenge style.\\nEach bar represent a year. Each color represent a class: black slaves (dark green), black free (light red), and black (orange)\\nThe last bar (1870) clearly shows the highest percentage of free slaves, from that day on.\", x=0.1,y=0.1,hjust=0,size=7.5,fontfamily = \"Public Sans Thin\")+\n   draw_label(\"DataSource: #TidyTuesday 2022 week25 Juneteenth | US Census's Archives | DataViz: Federica Gazzelloni (@fgazzelloni)\\n\",x=0.5,y=0.01,size=7)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w21_rugby/w21_women_rugby.html",
    "href": "tidytuesday/cases2022/posts2022/w21_rugby/w21_women_rugby.html",
    "title": "Womens Rugby",
    "section": "",
    "text": "library(tidyverse)\n\n\nsevens <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-24/sevens.csv')\nfifteens <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-24/fifteens.csv')\n\n\nmy_df <- sevens%>%\n  mutate(year_month=zoo::as.yearmon(date),.after=date) %>%\n  filter(score_1==\"L\" | score_1==\"W\") %>%\n  #select(-winner,-loser) %>%\n  pivot_longer(cols = c(\"team_1\",\"team_2\"),names_to=\"teams\",values_to=\"t_country\")%>%\n  relocate(teams,t_country,winner,loser) %>%\n  distinct()%>%\n  mutate(final=ifelse(t_country==winner,\"Winner\",\"Loser\"))%>%\n  relocate(final) \n\n\nmy_df%>% # count(t_country)\n  count(t_country,teams,final)%>%\n  group_by(t_country)%>%\n  summarize(final,teams,pct=round(n/sum(n)*100))%>%\n  filter(!pct==100)\n\n\nmy_df%>% # count(t_country)\n  count(t_country,teams,final)%>%\n  group_by(t_country)%>%\n  summarize(final,teams,pct=round(n/sum(n)*100))%>%\n  filter(!pct==100)%>%\n  ungroup()%>%\npivot_wider(names_from=teams,values_from=pct)\n\n\nlibrary(extrafont)\nloadfonts()\n\n\nlibrary(ggbump)\n\n\nmy_df %>%\n  select(row_id,date,year_month,teams,t_country,final) %>%\n  mutate(t_country=case_when(t_country==\"Arabian Gulf\"~\"* Arabian Gulf\",\n                             t_country==\"Burkina Faso\"~\"* Burkina Faso\",\n                             t_country==\"Cote d'Ivorie\"~\"* Cote d'Ivorie\",\n                             t_country==\"Ghana\"~\"* Ghana\",\n                             t_country==\"Hong Kong\"~\"* Hong Kong\",\n                             t_country==\"Kazakhstan\"~\"* Kazakhstan\",\n                             TRUE~t_country))%>%\n  ggplot(aes(x=1,y=t_country,color=teams)) +\n  ggbump::geom_sigmoid(aes(x=1,y=t_country,\n                           xend=year_month+1, yend=final),\n                       key_glyph = draw_key_rect)+\n  geom_text(aes(label=t_country,x=0),\n            hjust=1,family=\"Comic Sans MS\")+\n  geom_text(aes(label=final,x=2000,y=final),family=\"Comic Sans MS\",\n            size=6,hjust=0) +#c(\"Winner\",\"Loser\")\n  xlim(-300,2200)+\n  labs(title=\"Women's Rugby - Countries without scores\",\n       subtitle = \"from December 2000 to May 2010\",\n       caption=\"\\n* 6 countries out of 21 shared a winner/loser position while being either in team 1 or team 2\\nBurkina Faso is the only one who won being in Team 2 with 67% pct, most wins are from Team 1\\nCote d'Ivorie won and lost 50%/50% pct in both teams\\n\\nDataSource: #TidyTuesday 2022 week21 - Women's Rugby - ScrumQueens\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       color=\"\")+\n  viridis::scale_color_viridis(discrete=T,option=\"inferno\",\n                                alpha = 1,begin = 0.5,end = 0.8,\n                               labels = c(\"Team 1\", \"Team 2\"), breaks = c(\"team_1\", \"team_2\"))+\n  theme_void()+\n  theme(text = element_text(family=\"Comic Sans MS\",size=23,color=\"darkorange\"),\n    legend.position = c(0.8,0.2),\n    plot.title = element_text(hjust = 0.1),\n    plot.subtitle = element_text(hjust = 0.1,size=20),\n    plot.caption = element_text(size=10,hjust=0,color=\"darkorange\"),\n    plot.background = element_rect(fill=\"beige\",color=\"beige\"),\n    panel.background = element_rect(fill=\"beige\",color=\"beige\"),\n    plot.margin = margin(5,5,5,5,unit = \"pt\"))\n\n\nggsave(\"w21_women_rugby.png\",\n       width = 8.5,\n       height = 7,\n       dpi=320)\n\n\nfifteens%>%head"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w26_paygap/w26_paygap.html",
    "href": "tidytuesday/cases2022/posts2022/w26_paygap/w26_paygap.html",
    "title": "UK Gender pay gap",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w26_paygap/w26_paygap.html#df_bonus",
    "href": "tidytuesday/cases2022/posts2022/w26_paygap/w26_paygap.html#df_bonus",
    "title": "UK Gender pay gap",
    "section": "df_bonus",
    "text": "df_bonus\n\ndf_bonus <- df%>% #DataExplorer::profile_missing()\n  select(employer_id,employer_size,contains(\"bonus\")) %>%\n  filter(!employer_size==\"Not Provided\") %>%\n  mutate(id=case_when(employer_size==\"Less than 250\"~1,\n                      employer_size==\"250 to 499\"~2,\n                      employer_size==\"500 to 999\"~3,\n                      employer_size==\"1000 to 4999\"~4,\n                      employer_size==\"5000 to 19,999\"~5,\n                      employer_size==\"20,000 or more\"~6)) %>%\n  relocate(id) %>%\n  arrange(id)\n\ndf_bonus %>% DataExplorer::profile_missing()\n\n\ndf_bonus %>%\n  #group_by(employer_size) %>%\n  #summarize(across(is.numeric,.fns = median)) %>%\n  #ungroup() %>%\n  ggplot(aes(x=male_bonus_percent,y=female_bonus_percent))+\n  geom_boxplot(aes(group=employer_size),size=0.2)+ \n  geom_point(size=0.1,aes(color=employer_id))+\n  geom_abline(intercept = max(df_bonus$male_bonus_percent),slope=-1,size=0.1,linetype=\"dashed\")+\n  geom_abline(intercept = 0,slope=1,size=0.5,linetype=\"dashed\",color=\"red\")+\n  geom_smooth(method=\"lm\")\n\n\ndf_bonus%>%\n  filter(male_bonus_percent>50,female_bonus_percent<50) %>%\n    ggplot(aes(x=male_bonus_percent,y=female_bonus_percent))+\n # geom_boxplot(aes(group=employer_size),size=0.2)+ \n  geom_point(size=0.1,aes(color=employer_id))+\n  geom_abline(intercept = max(df_bonus$male_bonus_percent),slope=-1,size=0.5,linetype=\"dashed\")+\n  geom_abline(intercept = 0,slope=1,size=0.5,linetype=\"dashed\",color=\"red\")+\n  geom_text(aes(label=employer_id),check_overlap = T,size=2)+\n  geom_smooth(method=\"lm\")\n\n\nlibrary(tidymodels)\n\n\npay_bonus_pca<- df_bonus %>%\n  select(-employer_size) %>%\n  drop_na() %>%\n  prcomp(scale = TRUE)\n\ntidy(pay_bonus_pca, matrix = \"scores\") %>%\n  filter(PC%in%c(1,2)) %>%\n  pivot_wider(names_from=PC,values_from=value)%>%\n  janitor::clean_names() %>%\n  ggplot(aes(x=x1,y=x2))+\n    geom_point()\n\n\ndf%>%count(employer_size)\n\n\ndf %>%\n  mutate(id=case_when(employer_size==\"Less than 250\"~1,\n                      employer_size==\"250 to 499\"~2,\n                      employer_size==\"500 to 999\"~3,\n                      employer_size==\"1000 to 4999\"~4,\n                      employer_size==\"5000 to 19,999\"~5,\n                      employer_size==\"20,000 or more\"~6)) %>%\n  relocate(id) %>%\n  arrange(id) \n  #DataExplorer::profile_missing()\n\nSampling\n\ndf1<-df %>%\n  mutate(id=case_when(employer_size==\"Less than 250\"~1,\n                      employer_size==\"250 to 499\"~2,\n                      employer_size==\"500 to 999\"~3,\n                      employer_size==\"1000 to 4999\"~4,\n                      employer_size==\"5000 to 19,999\"~5,\n                      employer_size==\"20,000 or more\"~6)) %>%\n  relocate(id) %>%\n  arrange(id)\ndf1\n# library(sampling)\n# strata(df1,size=300)\n\n\ndf2<-df %>% #DataExplorer::profile_missing()\n  filter(!is.na(female_lower_quartile),!employer_size==\"Not Provided\") %>%\n  select(!contains(\"bonus\")) %>%\n  mutate(id=case_when(employer_size==\"Less than 250\"~1,\n                      employer_size==\"250 to 499\"~2,\n                      employer_size==\"500 to 999\"~3,\n                      employer_size==\"1000 to 4999\"~4,\n                      employer_size==\"5000 to 19,999\"~5,\n                      employer_size==\"20,000 or more\"~6)) %>%\n  relocate(id) %>%\n  arrange(id) %>%\n  group_by(id,employer_size)%>%\n  mutate(n=n()) %>%\n  ungroup() %>%\n  mutate(pct=round(n/sqrt(sum(n))*100,5))%>%#count(pct,n) %>%\n  relocate(n,pct)%>%\n  group_by(id,employer_size)%>%\n  summarise(across(.cols = everything(),.fns = mean)) %>%\n  ungroup() %>%\n # select(-diff_mean_bonus_percent) %>%\n  #mutate(diff_mean_bonus=round(male_bonus_percent-female_bonus_percent,2)) %>%\n  mutate_if(is.numeric, round, 2)\ndf2\n\n\ndf2 %>%\n  arrange(id)%>%names\n\n\ndf2 %>%\n  arrange(id)%>%\n  ggplot(aes(x=25,y=fct_reorder(employer_size,id),label=employer_size))+\n  geom_point(color=\"grey80\",shape=\".\")+\n  geom_text(hjust=1)+\n  geom_text(aes(x=30,label=paste0(diff_mean_hourly_percent,\"%\"))) +\n  # lower\n  geomtextpath::geom_textsegment(label=\"Lower\",size=4,\n                                 aes(x=female_lower_quartile,xend=male_lower_quartile,yend=employer_size),\n               position = position_nudge(y = 0.25),\n               color=\"grey50\",size=0.5)+\n  geom_point(aes(x=female_lower_quartile,y=employer_size),\n             position = position_nudge(y = 0.25),\n             color=\"violet\",size=5)+\n  geom_point(aes(x=male_lower_quartile,y=employer_size),\n             position = position_nudge(y = 0.25),\n             color=\"navy\",size=5)+\n  # upper\n    geomtextpath::geom_textsegment(label=\"Upper\",size=4,\n                            aes(x=female_top_quartile,xend=male_top_quartile,yend=employer_size),\n                            color=\"grey50\",size=0.5)+\n  geom_point(aes(x=female_top_quartile,y=employer_size),color=\"violet\",size=5)+\n  geom_point(aes(x=male_top_quartile,y=employer_size),color=\"navy\",size=5)+\n  geom_vline(xintercept = 50,size=0.3,linetype=\"dashed\")+\n\n  #scale_x_continuous(limits = c(0,65),breaks = c(40,50,60))+\n  labs(y=\"\")+\n  ggthemes::theme_fivethirtyeight()+\n  theme(axis.text.y = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank())\n\n\ndf2 %>%\n  arrange(id)%>%\n  ggplot(aes(x=25,y=fct_reorder(employer_size,id),label=employer_size))+\n  geom_text(hjust=1,fontface=\"bold\",color=\"#003d59\",size=6)+\n  geom_text(aes(x=30,label=paste0(diff_median_hourly_percent,\"%\")),\n            fontface=\"bold\",size=4,\n            color=\"#003d59\") +\n  # lower\n  geom_segment(size=3.5,\n               aes(x=female_lower_quartile,xend=female_top_quartile,yend=employer_size),\n               position = position_nudge(y = 0.2),\n               color=\"#a8bd3a\",size=0.5)+\n  geom_point(aes(x=female_lower_quartile,y=employer_size),\n             position = position_nudge(y = 0.2),\n             shape=21,stroke=1,fill=\"violet\",\n             color=\"#a8bd3a\",size=5)+\n  geom_point(aes(x=female_top_quartile,y=employer_size),\n             position = position_nudge(y = 0.2),\n             shape=21,stroke=1,fill=\"violet\",\n             color=\"#a8bd3a\",size=5)+\n  # upper\n  geom_segment(size=3.5,\n               aes(x=male_lower_quartile,xend=male_top_quartile,yend=employer_size),\n               position = position_nudge(y = -0.2),\n               color=\"#a8bd3a\",size=0.5)+\n  geom_point(aes(x=male_lower_quartile,y=employer_size),\n             position = position_nudge(y = -0.2),\n             shape=21,stroke=1,fill=\"navy\",\n             color=\"#a8bd3a\",size=5)+\n  geom_point(aes(x=male_top_quartile,y=employer_size),\n             position = position_nudge(y = -0.2),\n             shape=21,stroke=1,fill=\"navy\",\n             color=\"#a8bd3a\",size=5)+\n  # vertical line\n  geom_vline(xintercept = c(40,50,60),size=(c(40,100,40)/100),linetype=\"dashed\",color=\"grey40\")+\n  scale_x_continuous(limits = c(10,65),breaks = c(40,50,60),labels = paste0(c(40,50,60),\"K\"))+\n  coord_cartesian(clip = \"off\",ylim = c(1,6))+\n  labs(title=\"Difference in gender PayGap by size of Employers\\n\\n\",\n       caption=\"\\nDataSource: #TidyTuesday 2022 week26 ons.gov.uk | DataViz: Federica Gazzelloni (@fgazzelloni)\")+\n   annotate(\"text\",\n            x= c(18,30,50),\n            y = c(6.8,6.8,6.8),\n           label = c(\"Employer size\", \"PayGap\", \"Gender upper/lower values \"),\n           family = \"\", fontface = 3, size=5,color=\"#a8bd3a\") +\n    ggthemes::theme_fivethirtyeight()+\n  theme(text = element_text(color=\"#a8bd3a\"),\n        plot.title = element_text(size=18),\n        plot.caption = element_text(size=8.5,family=\"\",face=3),\n        axis.text.y = element_blank(),\n        axis.text.x = element_text(size=12,face=\"bold\"),\n        panel.grid.major.y = element_line(size=14),\n        panel.grid.major.x = element_blank(),\n        plot.background = element_rect(color=\"#003d59\",fill=\"#003d59\"),\n        panel.background = element_rect(color=\"#003d59\",fill=\"#003d59\"))+\n     annotate(\"text\",\n            x= 20.8,\n            y = 0.2,\n           label = \"PayGap are median values calculated on unique employer id\\nfrom hourly pay(%) mean difference\\nPink = Female | Blue = Male\",\n           family = \"\", fontface = 3, size=2.8,color=\"white\") \n\n\nggsave(\"w26_paygap.png\",dpi=320)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w35_pell/w35_pell.html",
    "href": "tidytuesday/cases2022/posts2022/w35_pell/w35_pell.html",
    "title": "Pell Grants",
    "section": "",
    "text": "library(tidyverse)\n\n\npell <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-08-30/pell.csv')\n\n\nhead(pell)\n\n\nusdata::state_stats%>%names\n\n51 abbr\n\nabbr <- usdata::state_stats%>%\n  count(abbr) %>%\n  select(-n)\n\n59 STATES\n\npell_abbr <- pell%>%\n  count(abbr=STATE) %>%\n  select(-n)\n\n\nmissing <- setdiff(pell_abbr,abbr)%>%\n  unlist()\n\n\nyear_id <- pell%>%\n  count(YEAR) %>%\n  select(-n)%>%\n  mutate(year_id=seq(1,length(YEAR),1))\n\n\ndf <- pell%>%\n  arrange(YEAR) %>%\n  filter(STATE%in%missing)%>%\n  arrange(STATE) %>%\n  mutate(NAME=case_when(NAME==\"American Samoa Cmnty College\"~\"American Samoa Community College\",\n         TRUE~NAME)) %>%\n  mutate(NAME_long=case_when(STATE==\"PR\"~\"Puerto Rico\",\n                             STATE==\"AS\"~\"American Samoa\",\n                             STATE==\"GU\"~\"Guam\",\n                             STATE==\"MH\"~\"Marshall Islands\",\n                             STATE==\"PW\"~\"Palau\",\n                             STATE==\"VI\"~\"Virgin Islands\",\n                             STATE==\"MP\"~\"Marianas Islands\",\n                             STATE==\"FM\"~\"Micronesia\",\n                             TRUE~STATE)) %>%\n  count(STATE,NAME_long,AWARD,RECIPIENT,YEAR) %>%\n  group_by(STATE) %>%\n  mutate(n=n(),avg_single_aw=AWARD/RECIPIENT) %>%\n  ungroup() %>%\n  left_join(year_id,by=\"YEAR\")\n\ndf\n\n\np <- df %>%\n  ggplot(aes(YEAR,avg_single_aw,group=YEAR))+\n  geom_boxplot()\n\n\np\nplotly::ggplotly(p)\n\n\nlibrary(giscoR)\nworld <- gisco_get_countries()\n\n\nstates <- df %>%\n  count(STATE) %>%\n  select(-n)\n\n\nsmall_countries <-world%>%\n  filter(CNTR_ID%in%states$STATE)%>%\n  left_join(df,by=c(\"CNTR_ID\"=\"STATE\"))\n\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sf)\n\n\ncropped_world<- st_crop(world, \n        xmin = 120, xmax = 172,\n        ymin = -14, ymax = 40)\n\n\n\n\n\nsmall_countries_feat <- small_countries %>%\n  st_drop_geometry() %>%\n  #filter(CNTR_ID==\"PR\")%>%\n  group_by(YEAR,CNTR_ID,NAME_ENGL)%>%\n  summarise(avg_single_aw,\n            mean_val=mean(avg_single_aw),.groups=\"drop\")%>%\n  ungroup() %>%\n  count(YEAR,CNTR_ID,NAME_ENGL,mean_val) %>%\n  group_by(CNTR_ID)%>%\n  mutate(diff=c(0,diff(mean_val)),\n         diff_prop=paste0(round(diff/mean_val*100,2),\"%\"),\n        # diff_w=round(c(0,diff(mean_val))*1/n,2),\n         avg=round(mean(round(diff/mean_val*100,2)),2))%>%\n  ungroup()\n  \nsmall_countries_feat  \n\n\nnames <- small_countries%>%\n  count(CNTR_ID,NAME_ENGL,avg_single_aw)\n\n\nsubworld <- small_countries %>% \n  group_by(CNTR_ID) %>%\n  # Mock the data field\n  summarise(data=n())%>%\n  ungroup()%>%\n  mutate(id=seq(1,8,1))\n\ntext <- subworld %>% \n  #select(geometry) %>%\n  st_cast(\"MULTIPOLYGON\") %>%\n # st_coordinates() %>%\n  st_centroid() %>%\n  st_coordinates() %>%\n  cbind(names) %>%\n  select(-n)\n\n\ntext_full <- text %>%\n  left_join(small_countries_feat,by=c(\"CNTR_ID\",\"NAME_ENGL\")) %>%\n  count(X,Y,NAME_ENGL,avg) %>%\n  mutate(text=paste0(NAME_ENGL,\"\\n\",avg,\"%\\n\"))\n\n\nlibrary(ggforce)\n\ncircles <-\ndata.frame(\nx0 = text_full$X,\ny0 = text_full$Y,\nr = text_full$avg) #seq(min(text_full$avg), max(text_full$avg), length.out = 8))\n\n\nlibrary(extrafont)\n\n\nggplot() +\n  geom_sf(data = cropped_world, fill=\"gray\")+\n  geom_sf(data = subworld, aes(color=CNTR_ID)) +\n  geom_text(data = text_full, aes(x=X,y=Y,label=text),family = \"Roboto Condensed\") +\n  geom_circle(data = circles, aes(x0 = x0, y0 = y0, \n                                  r = r,\n                                  fill=r,\n                                  alpha=r),\n              color=\"gray\",size=0.2) +\n  scale_fill_gradient(low = \"white\",high = \"blue\")+\n  scale_alpha_continuous(range = c(0.1,0.3))+\n  coord_sf(xlim = c(120,171.8428), \n           ylim = c( -14.36381, 40.59467),\n           crs = 4326) +\n  ggthemes::theme_fivethirtyeight() +\n  theme(text=element_text(family = \"Roboto Condensed\"),\n        panel.grid = element_line(size=0.08),\n        legend.position = \"none\")\n\n\nggsave(\"map2.png\")\n\n\nlibrary(tidyverse)\nlibrary(cowplot)\nggdraw() +\n  draw_image(\"map2.png\",scale=0.99) +\n  draw_image(\"globe.png\",\n             scale=0.2,\n             x=0.409,y=0.4) +\n  draw_label(\"Pell Awards\",\n             x=0.53,y=0.95,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,\n             color=\"grey30\",\n             size=30) +\n    draw_label(\"Pell Awards\",\n             x=0.53,y=0.95,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,\n             color=\"#a5bec9\",\n             size=29.5) +\n      draw_label(\"Basic Educational Opportunity Grants\\nby the U.S. Department of Education\",\n             x=0.47,y=0.88,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,\n             color=\"#24424f\",\n             size=12) +\n        draw_label(\"Western Pacific Ocean Islands yearly variation+ (average values %) 1990-2017\",\n               x=0.03,y=0.06,angle = 90,\n             #x=0.35,y=0.78,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,\n             color=\"#24424f\",\n             size=14) +\n  \n    draw_label(\"DataSource: #TidyTuesday 2022 week35\\nU.S. Department of Education\",\n             x=0.125,y=0.06,angle = 90,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,size=8) +\n      draw_label(\"DataVisualization: Federica Gazzelloni - @fgazzelloni\",\n             x=0.6,y=0.015,angle = 0,\n             fontfamily = \"Roboto Condensed\",\n             hjust=0,size=9) \n\nggsave(\"w35_pell.png\",bg=\"#b1d2e0\") #grey65 Saving 7 x 7 in image"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w5_dogs/w5_dogs.html",
    "href": "tidytuesday/cases2022/posts2022/w5_dogs/w5_dogs.html",
    "title": "Dog breeds",
    "section": "",
    "text": "library(tidyverse)\n\nDog breeds datasets, load the data\n\nbreed_traits <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv')\ntrait_description <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/trait_description.csv')\nbreed_rank_all <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_rank.csv')\n\nMake a rank dataset to see which breed is favourite in 2020\n\nrank<-breed_rank_all%>%\n  count(Breed,`2020 Rank`,Image)%>%\n  arrange(`2020 Rank`)%>%\n  slice(1:10)%>%\n  relocate(`2020 Rank`)%>%\n  select(-n)\n\nrank\n\nSelect favourite breeds, and set the images\n\ndogs<-c(\"Bulldogs\",\"Poodles\",\"Beagles\",\"Rottweilers\",\"Dachshunds\")\n\nimages <-rank%>%filter(Breed%in%dogs)%>%select(Breed,Image)\n\nmy_df <-breed_traits%>%\n  select(-\"Coat Type\",-\"Coat Length\")%>%\n  filter(Breed%in%dogs)%>%\n  mutate(id=row_number())%>%\n  relocate(id)%>%\n  pivot_longer(cols=3:16,names_to=\"factor\",values_to=\"value\")%>%\n  inner_join(images,by=\"Breed\")\n\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\n#font_families_google()\nfont_add_google(name=\"Barlow Condensed\",family=\"dogs\")\n\nfamily = \"dogs\"\n\nTo make the plot, use:\n\nggforce::geom_ellipse to make the paws\nggimage::geom_image to add the images\n\n\ndog_prints_plot <-\n  \n  ggplot(my_df,aes(id,value,group=Breed))+\n  \n  # this is the largest part of the paw\n  ggforce::geom_ellipse(aes(x0=id,y0=value-0.2,a=0.2,b=0.25,\n                            angle=50,color=Breed),fill=\"#393d36\",size=0.5,alpha=0.7)+\n  # the following four ellipses are small extrems of the paw\n  ggforce::geom_ellipse(aes(x0=id+0.22,y0=value+0.2,a=0.1,b=0.12, \n                            angle=50,color=Breed),fill=\"#393d36\",size=0.5,alpha=0.7)+\n  ggforce::geom_ellipse(aes(x0=id-0.2,y0=value+0.15,a=0.1,b=0.12,\n                            angle=50,color=Breed),fill=\"#393d36\",size=0.5,alpha=0.7)+\n  ggforce::geom_ellipse(aes(x0=id+0.01,y0=value+0.25,a=0.1,b=0.1,\n                            angle=50,color=Breed),fill=\"#393d36\",size=0.5,alpha=0.7)+\n  ggforce::geom_ellipse(aes(x0=id-0.32,y0=value-0.15,a=0.1,b=0.1,\n                            angle=50,color=Breed),fill=\"#393d36\",size=0.5,alpha=0.7)+\n  # this is the grey part of the paw  \n  ggforce::geom_ellipse(aes(x0=id,y0=value-0.3,a=0.08,b=0.08,\n                            angle=50),color=\"grey65\",size=0.02,fill=\"grey65\",alpha=0.1) +\n  # The segment is to make the arrow up\n  geom_segment(x=0.43,xend=0.43,y=0,yend=6, size=3,color=\"grey65\",\n               arrow = arrow(length = unit(c(0, 0, 0.4, 0.4), 'cm')))+\n  \n  # description of the factors\n  geom_text(aes(label=factor),check_overlap = T, vjust=5.5, hjust=0.5, size=2.5, color=\"midnightblue\",family=family)+\n  \n  # The breed's names\n  geom_text(aes(x=id,y=6.5,label=Breed),color=\"black\",size=5.5,family=family,face=\"bold\")+\n  \n  # Images of the breeds\n  ggimage::geom_image(aes(x=id,y=-1.4,image=Image),size=0.2)+\n  \n  # expand the canvas to make the paws standing out\n  scale_y_continuous(expand = c(0,1))+\n  ylim(-1.5,7)+\n  coord_cartesian()+\n  labs(title=\"Top 5 selected Breeds: Was Goofy a dog?\", \n       caption=\"Datasource: American Kennel Club | #TidyTuesday 2022-w5 | Viz: Federica Gazzelloni\")+\n  ggthemes::theme_fivethirtyeight()+\n  theme(text = element_text(family = family,size=14),\n        plot.title = element_text(size=18,hjust=0.1),\n        plot.caption = element_text(face = \"bold\",vjust=0.5),\n        panel.grid.major.x = element_line(size=38),\n        panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_line(size=4),\n        plot.background = element_rect(color=\"white\",fill=\"white\"),\n        panel.background = element_rect(color=\"white\",fill=\"white\"),\n        legend.position = \"none\")\n\nAdd extra images and save it\n\nlibrary(cowplot)\n\nfinal <- ggdraw()+\n  draw_plot(dog_prints_plot)+\n  draw_image(\"print.png\",x=0.3,y=0.43,scale=0.16)+\n  draw_image(\"print.png\",x=0.4,y=0.43,scale=0.16)\n\nggsave(\"dog_prints_plot.png\",final)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w39_us_artists/w39_us_artists.html",
    "href": "tidytuesday/cases2022/posts2022/w39_us_artists/w39_us_artists.html",
    "title": "Artists in the USA",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w39_us_artists/w39_us_artists.html#make-a-tree-map",
    "href": "tidytuesday/cases2022/posts2022/w39_us_artists/w39_us_artists.html#make-a-tree-map",
    "title": "Artists in the USA",
    "section": "Make a tree map",
    "text": "Make a tree map\n\ndf <- artists%>%\n  group_by(state)%>%\n  summarise(tot=sum(artists_n,na.rm = TRUE))\n\n# Create data\ngroup <- df$state\nvalue <- df$tot\ndata <- data.frame(group,value)\n\n\n# install.packages(\"Polychrome\")\nlibrary(Polychrome)\n# https://colorbrewer2.org/#type=sequential&scheme=Greens&n=9\n# build-in color palette\nvalues <- createPalette(52,  c(\"#f7fcfd\", \"#9ebcda\", \"#f7fcfd\"))\n\n\n# library\nlibrary(treemap)\npng(filename=\"w39_us_artists.png\",width=1400, height=1700)\ntreemap(dtf = data,index = \"group\",vSize=\"value\",type=\"index\",\n        title = \"STATE ARTISTS\",\n        border.col = \"grey70\",\n        border.lwds = 2,\n        title.legend = \"US States\",\n        fontsize.title=80,\n        fontfamily.labels = \"Roboto Condensed\",\n        fontfamily.title = \"Roboto Condensed\",\n        force.print.labels = TRUE,\n        fontface.labels = 2,\n        fontsize.labels = data$value,\n        palette = values\n            )\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w10_erasmus/w10_erasmus.html",
    "href": "tidytuesday/cases2022/posts2022/w10_erasmus/w10_erasmus.html",
    "title": "Erasmus student mobility",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggbump)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\n\nfont_add_google(name=\"Noto Sans\",family=\"notosans\")\n\n\nlibrary(ggthemes)\n\n\nerasmus <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-08/erasmus.csv')\n\ndf <- erasmus %>%\n  group_by(academic_year) %>%\n  filter(between(x = participant_age,17,28),\n         mobility_duration>3) %>%\n  summarise(m_participants=mean(participants),\n            sending_country_code,receiving_country_code,\n            .groups=\"drop\") %>%\n  ungroup() %>%\n  distinct()%>%\n  filter(sending_country_code %in% c(\"DE\",\"ES\",\"IT\",\"RO\",\"UK\")) %>%\n  mutate(sending_country_name=case_when(sending_country_code==\"DE\" ~ \"Germany\",\n                                        sending_country_code==\"ES\" ~ \"Spain\",\n                                        sending_country_code==\"IT\" ~ \"Italy\",\n                                        sending_country_code==\"RO\" ~ \"Romania\",\n                                        TRUE~\"UK\")) %>%\n  mutate(year_id=case_when(academic_year==\"2014-2015\"~1,\n                           academic_year==\"2015-2016\"~2,\n                           academic_year==\"2016-2017\"~3,\n                           academic_year==\"2017-2018\"~4,\n                           academic_year==\"2018-2019\"~5,\n                           academic_year==\"2019-2020\"~6))%>%\n  count(year_id,academic_year,sending_country_name) %>%\n  group_by(academic_year)%>%\n  mutate(rank=rank(x=n,ties.method = \"random\"))%>%\n  ungroup()\n\n\n\ndf %>%\nggplot(mapping=aes(academic_year,rank,\n                   group=factor(sending_country_name),\n                   color=factor(sending_country_name))) +\n  geom_point(size = 7) +\n  geom_text(data = df %>% filter(year_id == min(year_id)),\n            aes(x = year_id - .1, label = sending_country_name), \n            size = 4, hjust = 1) +\n  geom_text(data = df %>% filter(year_id == max(year_id)),\n            aes(x = year_id + .1, label = sending_country_name), \n            size = 4, hjust = 0,check_overlap = T) +\n  geom_bump(size = 2, smooth = 8) +\n  labs(y = \"RANK\",\n       x = \"Academic Year\",\n       title=\"Erasmus Top 5 student exchange countries\",\n       subtitle=\"Ranks of the highest sending frequency\",\n       caption=\"DataSource: Erasmus student mobility | Data.Europa.eu | Wimdu.co\\nDataViz: Federica Gazzelloni | #TidyTuesday Week 10 Erasmus\") +\n  scale_y_reverse() +\n  scale_color_manual(values = wesanderson::wes_palette(5, name = \"Royal2\"))+\n  cowplot::theme_minimal_grid(font_size = 14, line_size = 0) +\n  theme(legend.position = \"none\",\n        panel.grid.major = element_blank(),\n        plot.title = element_text(color=\"#ffc7ba\"),\n        plot.subtitle = element_text(color=\"#ffc7ba\"),\n        plot.caption = element_text(color=\"#ffc7ba\",size=8),\n        axis.text = element_text(color=\"#ffc7ba\"),\n        axis.title = element_text(color=\"#ffc7ba\"),\n        plot.background = element_rect(color=\"black\",fill=\"black\"),\n        panel.background = element_rect(color=\"black\",fill=\"black\"))\n \n\nggsave(\"er-network_a.png\",height =6,width = 10 )"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w40_product_hunt/w40_product_hunt.html",
    "href": "tidytuesday/cases2022/posts2022/w40_product_hunt/w40_product_hunt.html",
    "title": "Product Hunt products",
    "section": "",
    "text": "library(tidyverse)\nproduct_hunt <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-04/product_hunt.csv')\n\nproduct_hunt %>% head()\n\n\nproduct_hunt %>%\n  mutate(month=zoo::as.yearmon(as.Date(release_date)))%>%  # \"%Y-%m-%d\"\n  count(month) %>%\n  ggplot(aes(month,n)) +\n  geom_point() \n\n\nproduct_hunt %>%\n  mutate(month=zoo::as.yearmon(as.Date(release_date))) %>%  # \"%Y-%m-%d\"\n  count(month) %>%\n  ggplot(aes(month,n)) +\n  geom_point() +\n  geom_smooth()\n\n\nproduct_hunt%>%\n   mutate(month=zoo::as.yearmon(as.Date(release_date)))%>%\n   count(name, month,product_ranking,upvotes) %>%\n   drop_na() %>%\n   arrange(-product_ranking,-upvotes)%>%\n   group_by(product_ranking) %>%\n  count(name)\n   filter(upvotes==max(upvotes))\n  \n\n#column_to_rownames(name)\n\n\ndf <- product_hunt%>%\n   mutate(month=zoo::as.yearmon(as.Date(release_date)))%>%\n   count(name, month,product_ranking,upvotes) %>%\n   drop_na() %>%\n   arrange(-product_ranking,-upvotes)%>%\n   group_by(product_ranking) %>%\n   filter(upvotes==max(upvotes))\n\ndf\n\n\nproduct_hunt%>%\n   #mutate(month=zoo::as.yearmon(as.Date(release_date)))%>%\n  mutate(year=lubridate::year(as.Date(release_date)))%>%\n   count(year,product_ranking,upvotes) %>%\n   drop_na() %>%\n   arrange(-product_ranking,-upvotes) %>%\n  group_by(year,product_ranking)%>%\n  summarise(avg_votes=sum(upvotes)) %>%\n  ungroup() %>%\n  mutate(year=factor(year)) \n\n\nproduct_hunt%>%\n   #mutate(month=zoo::as.yearmon(as.Date(release_date)))%>%\n  mutate(year=lubridate::year(as.Date(release_date)))%>%\n   count(year,product_ranking,upvotes) %>%\n   drop_na() %>%\n   arrange(-product_ranking,-upvotes) %>%\n  group_by(year,product_ranking)%>%\n  summarise(avg_votes=sum(upvotes)) %>%\n  ungroup() %>%\n  mutate(year=factor(year)) %>%\n  ggplot(aes(x = product_ranking, y = avg_votes,color=year,fill=year)) +\n  geom_col() \n\n\ndf <- product_hunt %>% \n  arrange(release_date) %>%\n  select(release_date,upvotes,product_ranking) %>%\n  group_by(release_date,product_ranking) %>%\n  summarise(year = year(release_date),\n            month = month(release_date, label=TRUE),\n            day = day(release_date),\n            tot_votes=scale(upvotes)) %>%\n  ungroup() %>% \n  select(release_date,day,month,year,tot_votes,product_ranking)%>%\n        fill(tot_votes,product_ranking) %>%\n  distinct() %>%\n  drop_na() \n\ndf\n\n\nggplot(df,aes(month,product_ranking,fill=tot_votes))+\n # geom_hex() +\n  geom_tile(color=\"grey40\",size=0.5) +\n  scale_fill_viridis(name=\"Votes\",option =\"E\",begin = 0.1,end = 1,direction = -1)+\n  facet_grid(vars(year)) +\n  scale_y_continuous(trans = \"reverse\", breaks = unique(df$day)) +\n  scale_x_discrete(expand = c(0,0)) +\n  labs(x=\"Month\",y=\"Product ranking\",\n       title=\"Heatmap of the products upvotes by ranking in time\",\n       subtitle=\"darker areas show a higher number of votes (scaled values)\",\n       caption=\"DataSource: #TidyTuesday week40 Product Hunt | DataViz: Federica Gazzelloni\") +\n  theme_minimal(base_size = 9,base_family = \"Roboto Condensed\")+\n  theme(text=element_text(color=\"grey90\",face=\"bold\"),\n        axis.line = element_blank(),\n        strip.switch.pad.grid = unit(2,units = \"pt\"),\n        plot.background = element_rect(color=\"grey60\",fill=\"grey60\"),\n        plot.title = element_text(size=18))\n\n\nggsave(\"w40_product_hunt.png\",\n       dpi=600,\n       width = 10,\n       height = 7)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w12_babynames/w12_babynames.html",
    "href": "tidytuesday/cases2022/posts2022/w12_babynames/w12_babynames.html",
    "title": "BBaby names",
    "section": "",
    "text": "Source: https://r-graph-gallery.com/wordcloud\n\nlibrary(tidyverse)\n\nbabynames <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-22/babynames.csv')\n\ndf <- babynames %>%\n  arrange(-n) %>%\n  select(name,n,prop) %>%\n  group_by(name) %>%\n  summarise(n=sum(n),prop=sum(prop))%>%\n  ungroup() %>%\n  arrange(-n) %>%\n  slice(1:200)\n\nlibrary(wordcloud)\nset.seed(123)\n\npar(bg=\"black\") \nwordcloud(df2$word ,size= df2$freq, \n          col=terrain.colors(length(df2$word),alpha=0.9), \n          rot.per=0.3)\n\n\n\nlibrary(wordcloud2) \n\n# install webshot\nlibrary(webshot)\nwebshot::install_phantomjs()\n\n\ndf2 <- df %>%\n  rename(word=name,freq=n)\n\n\n\n# Make the graph\nmy_graph <- wordcloud2(df2, size=1.5,\n                       backgroundColor = \"black\")\n\n\n# save it in html\nlibrary(\"htmlwidgets\")\nsaveWidget(my_graph,\"data/2022/w12_babynames/tmp.html\",selfcontained = F)\n\n# and in png or pdf\nwebshot(\"data/2022/w12_babynames/tmp.html\",\n        \"data/2022/w12_babynames/fig_1.png\", \n        delay =5, vwidth = 980, vheight=950)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w18_solar_wind/w18_solarwind.html",
    "href": "tidytuesday/cases2022/posts2022/w18_solar_wind/w18_solarwind.html",
    "title": "Solar/Wind utilities",
    "section": "",
    "text": "library(tidyverse)\n\n\nwind <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-03/wind.csv')\nsolar <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-03/solar.csv')\n\n\n\ncum_solar <- solar%>% # DataExplorer::profile_missing()\n  group_by(date)%>%\n  summarize(tot_solar_mwh=sum(solar_mwh),\n            tot_solar_capacity=sum(solar_capacity),.groups=\"drop\")%>%\n  ungroup() %>%\n  mutate(cum_solar_mwh=cumsum(tot_solar_mwh)) \n\n\ncum_wind <- wind%>% # DataExplorer::profile_missing()\n  group_by(date)%>%\n  summarize(tot_wind_mwh=sum(wind_mwh),\n            tot_wind_capacity=sum(wind_capacity),.groups=\"drop\")%>%\n  ungroup() %>%\n  mutate(cum_wind_mwh=cumsum(tot_wind_mwh)) \n\n\ncum_solar%>%#summary()\n  ggplot(aes(x=date,y=tot_solar_mwh))+\n  geomtextpath::geom_textline(aes(y=cum_solar_mwh),col=\"red\",label=\"Solar\",hjust=1,size=6,family = \"sans\") +\n  geomtextpath::geom_textline(data=cum_wind, aes(y=cum_wind_mwh),inherit.aes = T,label=\"Wind\",hjust=1,size=6,family = \"sans\")+\n  labs(title=\"Projected cumulative price\",y=\"Price ($/MWh)\",x=\"\",\n       caption=\"#TidyTuesday w18 Solar/Wind | DataSource: Berkeley Lab\\nPrices are in $/MWh from 2009 to 2021 | DataViz: Federica Gazzelloni (@fgazzelloni)\") +\n  ggthemes::theme_wsj()+\n  theme(panel.grid = element_line(size=0.3),\n        plot.caption = element_text(size=8,hjust=0))\n\nggsave(\"w18_solar_wind.png\",\n       dpi=320,\n       width = 8,\n       height = 5)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w14_digital_pub/w14_digital_publications.html",
    "href": "tidytuesday/cases2022/posts2022/w14_digital_pub/w14_digital_publications.html",
    "title": "Digital Publications",
    "section": "",
    "text": "library(tidyverse)\n\n#load data\nnews_orgs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-05/news_orgs.csv')\n\n#news_orgs %>% head(50)%>% View\n\n#news_orgs%>% count(year_founded)\n\nlibrary(extrafont)\nloadfonts()\nlibrary(showtext)\n#sysfonts::font_add_google(\"Public Sans\",\"publicsans\")\n\n  \ndf <- news_orgs %>%\n  select(publication_name,year_founded,budget_percent_editorial,budget_percent_revenue_generation) %>% \n  drop_na() %>%\n  arrange(budget_percent_editorial) %>% #count(year_founded) %>% View\n  filter(!budget_percent_editorial==budget_percent_revenue_generation,\n         year_founded==2010) \n\n\n\ndf2 <- df %>%\n  arrange(desc(budget_percent_editorial)) %>%\n  mutate(photo=gsub(\" \",\"\",publication_name),.after=publication_name,\n         photo=tolower(photo),\n         photo=paste0(\"data/2022/w14_digital_pub/\",photo,\".png\"))\n\nlibrary(hrbrthemes)\nlibrary(ggbump)\nlibrary(ggh4x)\nlibrary(ggimage)\n\n\ndf2 %>%\n  ggplot(aes(x=0,xend=1,\n             y=budget_percent_editorial,yend=budget_percent_revenue_generation,\n             group=factor(publication_name))) +\n ggrepel::geom_text_repel(aes(x=0,label=publication_name),\n                          color=\"grey80\",\n                          \n                           direction = \"y\", hjust = \"left\",\n                           min.segment.length = 0,\n                           nudge_x = 1.1,\n                           box.padding = 0.5,\n                           nudge_y = 0,\n                          segment.color=\"grey32\",\n                           segment.curvature = -0.1,\n                           segment.ncp = 3,\n                           segment.angle = 20,\n                           segment.size = 0.2)+\n  geom_image(aes(x=rev(seq(0,1.2,0.08571429)),\n                 y=seq(1,10,0.6785714),\n                 image=rev(photo)),\n             alpha=0.6,size=0.04,\n             nudge_y = 0.1,by=\"height\")+\n  geom_segment(size=1) +\n  geom_point(size=8,shape=21,stroke=3)+\n  geom_point(aes(x=1,y=budget_percent_revenue_generation),size=8,shape=21,stroke=3) +\n  labs(title=\"Publications funded in 2010: Editorial vs Revenue generation budget\",\n       subtitle=\"Report from PROJECT OASIS - Hussman School of Journalism and Media\",\n       caption=\"#TidyTuesday week14 & #30DayChartChallenge 2022 day5 - Slope\n       DataSource: Digital Publications|Project Oasis - DataViz: Federica Gazzelloni\",\n       x=\"Revenue generation budget (%)\",\n       y=\"Editorial budget (%)\") +\n  guides(y.sec = guide_axis_manual(labels = c(\"0-10\",\"11-20\",\"21-30\",\"31-40\",\"41-50\",\"51-60\",\"\",\"\",\"\",\"\")))+\n  scale_x_continuous(expand = c(0,0),limits=c(-0.1,1.3))+\n  hrbrthemes::theme_ft_rc()+\n  theme(text = element_text(),\n        axis.text.x = element_blank(),\n        plot.title = element_text(size=28),\n        plot.caption = element_text(size=11),\n        axis.title.x = element_text(size=10),\n        axis.title.y = element_text(size=10))\n\n\nggsave(\"w14_digital_publications.png\",\n       width = 12, height = 8,\n       dpi=320)\n\ndev.off()\n\n# Second version:\n\nlibrary(sigmoid)\n\nz <- rev(seq(0,1.2,0.08571429))\n\ndf2 %>%\n  ggplot(aes(x=0,xend=1,\n             y=budget_percent_editorial,yend=budget_percent_revenue_generation,\n             group=factor(publication_name))) +\n  ggrepel::geom_text_repel(aes(x=0,label=publication_name),\n                           color=\"grey80\",\n                           direction = \"y\", hjust = \"left\",\n                           min.segment.length = 0,\n                           nudge_x = 1.11,\n                           box.padding = 0.5,\n                           nudge_y = 0,\n                           segment.color=\"grey32\",\n                           segment.curvature = -0.1,\n                           segment.ncp = 3,\n                           segment.angle = 20,\n                           segment.size = 0.2)+\n  geom_image(aes(x=sigmoid(z, k=sd(z), x0=mean(z),\n                           method=\"tanh\",\n                           SoftMax = F\n                           ),\n                 y=seq(5.5,10.5,0.3571429),\n                 image=rev(photo)),\n             size=0.04,nudge_y = 0.1,by=\"height\")+\n  geom_segment(size=1,lineend = \"round\",color=\"grey32\") +\n  geom_segment(size=2,lineend = \"round\",linetype=\"dashed\") +\n  geom_point(size=8,shape=21,stroke=3,fill=\"grey80\",alpha=0.7)+\n  geom_point(aes(x=1,y=budget_percent_revenue_generation),\n             size=8,shape=21,stroke=3,fill=\"grey80\",alpha=0.7) +\n  labs(title=\"Publications funded in 2010: Editorial vs Revenue generation budget\",\n       subtitle=\"Report from PROJECT OASIS - Hussman School of Journalism and Media\",\n       caption=\"#TidyTuesday week14 & #30DayChartChallenge 2022 day5 - Slope\n       DataSource: Digital Publications|Project Oasis - DataViz: Federica Gazzelloni\",\n       x=\"Revenue generation budget (%)\",\n       y=\"Editorial budget (%)\") +\n  guides(y.sec = guide_axis_manual(labels = c(\"0-10\",\"11-20\",\"21-30\",\"31-40\",\"41-50\",\"51-60\",\"\",\"\",\"\",\"\")))+\n  scale_x_continuous(expand = c(0,0),limits=c(-0.1,1.3))+\n  hrbrthemes::theme_ft_rc()+\n  theme(text = element_text(color=\"grey40\",family=\"Impact\"),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(color=\"grey60\"),\n        plot.title = element_text(size=28),\n        plot.caption = element_text(size=11),\n        axis.title.x = element_text(size=10,color=\"grey60\"),\n        axis.title.y = element_text(size=10,color=\"grey60\"))"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w32_ferriswheels/w32_ferriswheels.html",
    "href": "tidytuesday/cases2022/posts2022/w32_ferriswheels/w32_ferriswheels.html",
    "title": "Ferris Wheels",
    "section": "",
    "text": "Data this #TidyTuesday 2022 week32 is from EmilHvitfeldt.\n\nlibrary(tidyverse)\nwheels <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-08-09/wheels.csv')\n\nThis dataset contains information about ferris wheels around the world. The objective of this visualization is to provide a visualization of the differences among ferris wheels in terms of diameter and number of cabins. There is a 48% and 15% missing values in the diameter, and number of cabins vectors, respectively. So, what we need to do is find a way to impute these missing values. There are several techniques used for imputing missing values, such as trees, KNN, SVM, mean/median, linear, and polynomial imputations. We could use {tidymodels} and provided step_functions() in order to do that, passing through the use of the recipe() function, or workout a custom way to imputation. This is when you look at the data and impute missing values based on the overall meaning. I’ll call it custom sintetic imputation.\n\n\n\nBefore to start tidying our dataset, we exclude the Nippon wheel as it is the only one without height and it is still on development, searching on the internet, it is difficult to find information about it, so we exclude it. The, a second ferris wheel which requires some attention is the Big O, it has a height which is lower than its diameter, and if you Google it: Big O you’ll find that both height and diameter are 60 mt (197 feet), so I decided to swap the values, considering the higher value as the height and the other as the diameter.\nMoscow-850 is expressed in mt so it needs to be in ft, about 240 ft. Chicago Wheel is in mt as well, so considering it in ft, it would be\n\nwheels1 <- wheels%>% \n  filter(!str_detect(name,\"Nippon\"))%>% # excluded\n  mutate(location=ifelse(is.na(location),\"Dubai\",location),\n         diameter=case_when(name==\"Moscow-850\"~240,\n                            name==\"Chicago Wheel\"~height,\n                            TRUE~diameter),\n         temp=ifelse(name==\"Big O\",height,diameter),\n         height=ifelse(name==\"Big O\",diameter,height),\n         diameter=ifelse(name==\"Big O\",temp,diameter)) \nwheels1%>%\n  select(name,country,height,diameter)%>%\n  filter(name%in%c(\"Big O\",\"Moscow-850\",\"Chicago Wheel\"))\n\nThen, another cleaning step involves the cost and tickets variables (renamed from construction_cost and ticket_cost_to_ride), these two vectors are important to be just numeric, because we are going to use them inside a model to predict suitable missing values for the number of cabins; in addition, when multiple values are provided for tickets, such as adult and children, we include just the adults ticket prices. In order to do that, we make some text customization, named regex, text regular expressions with the help of stringr::str_extract() function, as shown below. We have some missing values among those two vectors, 55% and 43% for costs and tickets, respectively. Also, these two vector will be imputed to be used in our model.\n\nwheels1%>% \n  mutate(costs=stringr::str_extract(construction_cost, \"\\\\d+\\\\.*\\\\d*\"),\n         costs=as.numeric(costs),\n         tickets=stringr::str_extract(ticket_cost_to_ride, \"\\\\d+\\\\.*\\\\d*\"),\n         tickets=as.numeric(tickets)) %>%\n  filter(!is.na(costs))%>%\n  select(name, country,costs,tickets)%>%head\n\nAs said, we suppose that height is always higher than diameter. A Ferris wheel is generally, lifted on a wheel support and the height is the height of the wheel plus its support. So that, the diameter is just the diameter of the wheel in itself. We do not have missing values on the height vector, the only missing value (Nippon wheel) has been excluded. To replace the missing values in the diameter vector, we have a look at the relationship between diameter versus height. It is about linear.\n\n\n\nMore considerations are about the ferris wheel support height, the height of the rim steel structure of the ferris wheel, this is given by the difference between the overall height and radius of the ferris wheel. Here is considered just the distance from the end of the wheel and the ground base of the support. We consider the median difference of the height minus the diameter of the all ferris wheel in the dataset, and build a sintetic_diameter vector filling missing values with the difference between height and the median difference of 33ft.\n\nmed_bs_hg=median(height-diameter,na.rm = T)\nsintetic_diameter=ifelse(is.na(diameter),height-med_bs_hg,diameter)\n\n\n\n\n\n\n\nTo adopt the median difference is quite superficial, but for now consider that as a base structure for all ferris wheel to start with. 33 ft will be the median distance of the ferris wheels from the ground, in our model.\nThen, the number of cabins vector contains 15% of missing values, and here these values are covered with some extra manipulations.\nConsider some geometry, how to calculate the circumference, the arc length, or the distance among cabins, and the angles such as theta. This apparently a redundant procedure, can lead to reduced bias, as theta is of determined range from 0 to 360 degree or \\(2\\pi\\) radiant. The number of cabins can also be of a certain range, as not more than a well specified number of cabins are allowed depending on diameter of the ferris wheel, but this is unknown and potentially be of any unspecified length. For this reason \\(\\theta\\) could be a good estimator.\nThe number of cabins are points on a circle, and for those values in the dataset which are not missing, an arc length can be calculated, as long as the central angle \\(\\theta\\). Once these values are set, the missing values can be calculated with a backwards procedure.\n\\[L=\\text{Length of an arc}\\] \\[r=\\text{Radius}\\] \\[L=\\theta\\frac{\\pi}{180}r\\] A sintetic number of cabins (sintetic_n_cab) vector is set to be filled with imputed missing values. To find these values, some other parameters are needed. The sintetic_diameter vector can be used to find the circumference, as well as the radius, the arc length among points (the arc_distance) and finally \\(\\theta\\). All these values are now filled with missing values, as are derived from the number of cabins vector.\n\ncircumference = pi*sintetic_diameter\narc_distance = circumference/number_of_cabins\ntheta = (arc_distance*180)/(pi*sintetic_diameter/2)\nsintetic_n_cab = circumference/arc_distance\n\nFinal data manipulation below shows how new features are made ready to be used in the model. For further reference Feature Engineering and Selection - Engineering Numeric Predictors, pg.122 is about expanding individual predictors into many predictors.\n\nmy_df <- wheels1%>%\n  select(-temp,-`...1`) %>%\n  mutate(med_bs_hg=median(height-diameter,na.rm = T),\n         sintetic_diameter=ifelse(is.na(diameter),height-med_bs_hg,diameter),\n         #sintetic_height=sintetic_diameter+med_bs_hg,\n         circumference=pi*sintetic_diameter,\n         arc_distance=circumference/number_of_cabins,\n         theta=(arc_distance*180)/(pi*sintetic_diameter/2),\n         sintetic_n_cab=circumference/arc_distance)%>%\n  \n  select(-construction_cost,-ticket_cost_to_ride)%>%\n  arrange(country)\n\nSo, we are left with some missing values in the number of cabins. Before going to modeling, some missing values can be filled considering the mean of the arc_distance for the group of heights, this values will be used to fill some of the missing number of cabins for those values with a common height.\n\n\n\nLooking at the distribution of \\(\\theta\\), it is clear a right skewness of the distribution. As said, the angle \\(\\theta\\), which is between (0,360), might be a good estimator to use for estimating missing number of cabins, passing through the arch length, the distance among cabins on the wheel.\n\nmy_df1%>%\n  ggplot(aes(theta))+\n  geom_histogram(bins=10,color=\"white\")+\n  ggthemes::theme_fivethirtyeight()+\n  labs(title=expression(paste(\"Distribution:\\t\",theta)))\n\nA trees based model would be the best choice for guessing these values (ct. Feature Engineering and Selection - Engineering Numeric Predictors, pg.121).\nOne more consideration is due to the dimension of the dataset:\n\nwheels%>%dim\n\nCross validation could be a solution, as it shuffles data on specified number of folds. In this case the group_vfold_cv() function is used to make the cross validation folds grouped by height while predicting theta.\nMore about how to extrapolate vfold_cv() assessment/analysis datasets here: article\n\nlibrary(tidymodels)\ntidymodels_prefer()\n\nset.seed(1234)\nfolds <- group_vfold_cv(my_df1, group = height,v = 10)\n\n\nrec <- my_df1%>%\n  recipe(theta~circumference+height+sintetic_diameter+sintetic_n_cab) %>%\n  step_corr(all_numeric()) %>% \n  step_impute_bag(theta,sintetic_n_cab)\n\nrec%>%prep()%>%bake(new_data=NULL)%>%DataExplorer::profile_missing()\n\nSet a Random forest engine randomForest with tuning parameters. mtry is for feature subset strategy, in this case just three predictors are used. min_n is the min node size, and then there is the number of trees.\n\nshow_engines(\"rand_forest\")\n\n\nshow_model_info(\"rand_forest\")\n\n\nrf_spec <-\n  rand_forest(mtry = tune(), \n              trees = tune(),\n              min_n = tune()) %>%\n  set_engine('randomForest') %>%\n  set_mode('regression')\n\nrf_wfl <- workflow() %>%\n  add_model(rf_spec) %>%\n  add_recipe(rec)\n\ndoParallel::registerDoParallel()\nset.seed(123)\nrf_res <- tune_grid(object = rf_wfl,\n                    resamples = folds,\n                    grid = 20,\n                    control = control_grid(save_pred = T,\n                                           save_workflow = T,\n                                           verbose = T,\n                                           parallel_over = \"everything\"))\n\nrf_res %>% \n  collect_metrics()%>%\n  filter(.metric==\"rmse\")%>%\n  arrange(mean)%>%\n  select(mtry,trees,min_n,mean)%>%\n  pivot_longer(cols=mtry:min_n,names_to=\"parameters\",values_to=\"values\")%>%\n  ggplot(aes(values,mean, color=parameters))+\n  geom_point(show.legend = F)+\n  facet_wrap(~parameters,scale=\"free\")\n\n\nrf_grid <- grid_regular(\n  trees(range = c(500,1000)),\n  min_n(range = c(0,5)),\n  mtry(range=c(2,2)),\n  levels = 5\n)\nrf_grid\n\nSecond tuning with a specified range of parameters.\n\nset.seed(456)\nrf_res2 <- tune_grid(object = rf_wfl,\n                    resamples = folds,\n                    grid = rf_grid,\n                    control = control_grid(save_pred = T,\n                                           save_workflow = T,\n                                           verbose = T,\n                                           parallel_over = \"everything\"))\n\n\nrf_res2 %>%\n  collect_metrics()%>%\n  filter(.metric==\"rmse\")%>%\n  arrange(mean)%>%\n  select(mtry,trees,min_n,mean) %>%\n  mutate(min_n=as.factor(min_n))%>%\n  ggplot(aes(trees,mean, color=min_n))+\n  geom_line()+\n  geom_point(show.legend = F)\n\n\nselect_best(rf_res2,\"rsq\")\n\n\nmy_df2<-my_df1%>%\n  filter(!is.na(theta))\n\ntest<- my_df1%>%\n  filter(is.na(theta))\n\n\npred_theta <- workflow()%>%\n  add_model(rf_spec)%>%\n  add_formula(formula=theta~sintetic_diameter)%>%\n  finalize_workflow(select_best(rf_res2)) %>%\n  fit(data = my_df2) %>%\n  augment(new_data=test) %>%\n  select(sintetic_n_cab,arc_distance,theta,.pred)\n\npred_theta  \n\n\n  my_df1$theta[is.na(my_df1$theta)]  <-  pred_theta$.pred\n  \n  my_imputed_df <- my_df1%>%\n    mutate(sintetic_distance=ifelse(is.na(arc_distance),\n                                    (theta*pi*sintetic_diameter)/360,arc_distance),\n           sintetic_n_cab=ifelse(is.na(number_of_cabins),\n                                 (circumference/sintetic_distance),sintetic_n_cab))%>%\n    select(name,country,height,sintetic_diameter,diameter,sintetic_n_cab)\n  \n  my_imputed_df%>%head\n\n\nmy_imputed_df1 <- my_imputed_df %>%\n  mutate(y = height-sintetic_diameter/2,\n         r = sintetic_diameter / 2) %>%\n  group_by(country) %>%\n  mutate(country_id=1,\n         name=paste0(name,\"\\n\",country),\n         tot_wheels=sum(country_id),.after=country)%>%\n  ungroup() %>%\n  mutate(country=as.character(country)) %>%\n   mutate(name=case_when(name==\"Diamond and Flower Ferris Wheel\\nJapan\"~\"Diamond and Flower\\nFerris Wheel\\nJapan\",TRUE~name))\nmy_imputed_df1%>%head\n\nThis code is from EmilHvitfeldt, who has provided the data for this #TidyTuesday 2022 week32.\n\n cabin <- my_imputed_df1 %>% \n    group_by(name) %>% # summarise(number_of_cabins)\n    summarise(cabin = seq_len(sintetic_n_cab),\n              # Get x and y for the carts\n              cabin_x = cos(cabin / sintetic_n_cab * 2 * pi),\n              cabin_y = sin(cabin / sintetic_n_cab * 2 * pi),\n              # Size them to be the right distance from the center\n              cabin_x = cabin_x * (sintetic_diameter / 2),\n              cabin_y = cabin_y * (sintetic_diameter / 2),\n              # Make sure the carts are raised enough\n              cabin_y = cabin_y + height - sintetic_diameter / 2,\n              # Lower the carts just a bit so it appears they are hanging\n              cabin_y = cabin_y - 12.5,\n              cabin_color = as.character(cabin %% 3),\n              sintetic_diameter,sintetic_n_cab,\n              .groups = \"drop\"\n    )\n\n\nmy_imputed_df1 %>%\n # filter(str_detect(name,\"Flower\"))%>%select(name)\nggplot() +\n    geom_abline(slope = 0, intercept = 0, color = \"darkgreen\") +\n    ylim(0, NA) +\n    ggforce::geom_circle(aes(x0 = 0, y0 = y, r = r),\n                         color=\"midnightblue\") +\n    # # Left leg\n    geom_segment(aes(x = -(height - sintetic_diameter / 2)/2, \n                     xend = 0,\n                     yend = height - sintetic_diameter / 2, \n                     y = 0)) +\n    # right leg\n    geom_segment(aes(x = (height - sintetic_diameter / 2)/2, \n                     xend = 0,\n                     yend = height - sintetic_diameter / 2, \n                     y = 0)) +\n    geom_point(data = cabin,\n               mapping=aes(cabin_x, cabin_y, \n                           color = cabin_color,\n                           fill = cabin_color),\n               size=0.01,\n               shape = 24) +\n    labs(title=\"Ferris Wheels: overview by dimensions\",\n         subtitle = \"Diameters and number of cabins are imputed. Ferris wheels are ordered by number of cabins.\\nOn average: distance from base ground is 33ft, sintetic diameters are 271ft and number of cabins are 42.\\n\",\n         caption = \"Data are from #TidyTuesday 2022 week 32 {ferriswheels} by @Emil_Hvitfeldt\\nDataViz: Federica Gazzelloni @fgazzelloni\")+\n    theme_void()+\n    theme(text = element_text(family=\"Roboto Condensed\", size=14),\n          plot.title = element_text(size=45),\n          plot.subtitle = element_text(size=20),\n          plot.caption = element_text(size=20,hjust = 0.5,vjust=0.5),\n          plot.background = element_rect(fill=\"gray80\",color=\"gray80\"),\n          panel.background = element_rect(fill=\"gray80\",color=\"gray80\"),\n          legend.position = \"none\")+\n    facet_wrap(~fct_reorder(name,sintetic_n_cab))\n\n\n  ggsave(\"w32_ferriswheels.png\",\n         dpi=320,\n         width = 15,\n         height = 18)\n\nJust a little check for some of the ferris wheels with out of the mean overall height.\n\nmy_imputed_df1 %>%filter(str_detect(name,\"Roue|HEP\"))%>%select(name,diameter,height,sintetic_diameter)\n\n\nmy_imputed_df1%>%select(sintetic_diameter,sintetic_n_cab)%>%map_dfr(mean)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w42_stranger_things_dialogue/w42_stranger_things_dialogue.html",
    "href": "tidytuesday/cases2022/posts2022/w42_stranger_things_dialogue/w42_stranger_things_dialogue.html",
    "title": "Stranger things dialogue",
    "section": "",
    "text": "library(tidyverse)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\nlibrary(ggridges)\nlibrary(cowplot)\n\n\n# set the fonts\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont.add(family = \"Benguiat\",regular=\"Benguiat Normal.ttf\")\n\n\n\n\n\nepisodes_raw <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-18/stranger_things_all_dialogue.csv')\n\ndf <-\n  episodes_raw %>%\n  filter(!is.na(dialogue)) %>%\n  mutate(season = paste(\"Season\", season)) %>%\n  select(season,episode,start_time,end_time,dialogue) %>%\n  mutate(time = end_time-start_time,\n         time = as.numeric(time),\n         trims = trimws(dialogue),\n         space = sapply(strsplit(trims, \" \"), length)) %>% #pull(time)%>%summary()\n  filter(time > 1) %>%\n  mutate(velocity = space/(time/60)) %>%\n  mutate(time_s=time,\n         time = time/60)\n  \n  \n\np <- df %>%\n  group_by(season,episode)%>%\n  mutate(velocity=mean(velocity))%>%\n  ungroup()%>%\n  ggplot(aes(x = velocity,y = fct_reorder(factor(episode),desc(episode)),\n             fill = 0.5 - abs(0.5 - stat(ecdf)))) +\n  ggridges::stat_density_ridges(geom = \"density_ridges_gradient\", calc_ecdf = TRUE, alpha=0.5) +\n  scale_fill_viridis_c(name = \"Speed wpm\", option = \"A\",labels = scales::percent) +\n  scale_x_continuous(expand = c(0,0)) +\n  labs(title=\"All seasons episodes\",\n       caption=\"DataSource: #TidyTuesday 2022 week 42 by Stranger things dialogue | DataViz: Federica Gazzelloni (@fgazzelloni)\",\n       x=\"Dialogue speech speed (wpm)\",y=\"Episode\")+\n  ggridges::theme_ridges()+\n  theme(text=element_text(color=\"grey90\",family=\"Benguiat\"),\n        axis.text.x = element_text(color=\"grey90\",size=9),\n        axis.text.y = element_text(color=\"grey90\",size=9),\n        plot.margin = margin(10,10,10,10,unit = \"pt\"),\n        plot.title = element_text(size=12,hjust = 0.03),\n        plot.title.position = \"panel\",\n        plot.subtitle = element_text(color=\"grey90\"),\n        plot.caption = element_text(size=10),\n        plot.caption.position = \"plot\",\n        plot.background = element_rect(color=\"grey10\",fill=\"grey10\"),\n        panel.background = element_rect(color=\"grey10\",fill=\"grey10\"),\n        strip.background = element_blank(),\n        legend.text = element_text(size=9),\n        legend.title = element_text(size=8))\n\nggsave(\"p.png\",dpi=400,width = 8,height = 4)\n\np1 <- ggplot(df, \n             aes(x = time, y = velocity,group=space)) +\n  geom_jitter(aes(color=factor(season)),\n              size=0.2,\n              alpha=0.3)+\n  geom_line(aes(color=factor(season)),\n            size=0.2,\n            alpha=0.5) +\n  scale_y_continuous(expand = c(0,0)) +\n  scale_color_viridis_d(option = \"A\")+\n  labs(title = \"Talking fast slows down as time increases\\n\",\n       y = \"Speed (wpm)\", x = \"Time in minutes\")+\n  ggridges::theme_ridges()+\n  theme(text=element_text(color=\"grey90\",size=14,family=\"Benguiat\"),\n        axis.text.x = element_text(color=\"grey90\"),\n        axis.text.y = element_text(color=\"grey90\"),\n        axis.line = element_line(color=\"grey90\",\n                                 arrow = arrow(type='closed', \n                                               length = unit(10,'pt'))),\n        panel.grid.major = element_line(color=\"grey60\",size=0.1,linetype = \"dashed\"),\n        plot.margin = margin(10,10,10,10,unit = \"pt\"),\n        plot.subtitle = element_text(color=\"grey90\"),\n        plot.caption = element_text(size=11),\n        plot.background = element_rect(color=\"grey10\",fill=\"grey10\"),\n        panel.background = element_rect(color=\"grey10\",fill=\"grey10\"),\n        strip.background = element_blank(),\n        legend.position = \"none\")\n\n\n\nggsave(\"p1.png\",dpi=300,width = 9,height = 4)\n\n\ncowplot::ggdraw()+\n  draw_image(\"p.png\",scale=0.93,x=-0.02,y=-0.22)+\n  draw_image(\"p1.png\",scale=0.7, y=0.22,x=-0.13)+\n  draw_image(\"logo.png\",scale = 0.2,y=0,x=0.4)+\n  draw_label(\"Stranger things...on dialogue's speed\", \n             fontfamily = \"Benguiat\",\n             x=0.4,y=0.95,\n             size=25,\n             color=\"grey90\")+\n  draw_label(\"wpm = word/per minutes\\n\\nWord Speed:\\nnumber of words\\ndivided by time difference\\nfrom end to start\\n\\nAvg 2.5 words per second\\n\\n\\nSlow: less than 110 wpm\\nConversational: 120 - 150 wpm\\nFast: more than 160 wpm\",\n             x=0.96,y=0.74,color=\"grey90\",\n             hjust = 1,\n             size=9,\n             lineheight = 1.5,\n             fontfamily = \"Benguiat\")+\n  theme(plot.background = element_rect(fill=\"grey10\", color = \"grey10\"))\n\n\n\nggsave(\"w42_stranger_things_dialogue.png\",\n       dpi=200,\n       width = 14,\n       height = 12)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w50_retail_sales/w50_retail_sales.html",
    "href": "tidytuesday/cases2022/posts2022/w50_retail_sales/w50_retail_sales.html",
    "title": "Monthly State Retail Sales",
    "section": "",
    "text": "Load libraries\n\nlibrary(tidyverse)\nlibrary(fuzzyjoin)\nlibrary(ggstream)\nlibrary(colorspace)\n\nSet the theme\n\ntheme_set(theme_minimal(base_family = \"Roboto Condensed\",\n                        base_size = 12))\n\n\ntheme_update(\n  plot.title = element_text(\n    size = 20,\n    face = \"bold\",\n    hjust = .5,\n    margin = margin(10, 0, 30, 0)\n  ),\n  plot.caption = element_text(\n    size = 9,\n    color = \"grey40\",\n    hjust = .5,\n    margin = margin(20, 0, 5, 0)\n  ),\n  axis.text.y = element_blank(),\n  axis.title = element_blank(),\n  plot.background = element_rect(fill = \"grey88\", color = NA),\n  panel.background = element_rect(fill = NA, color = NA),\n  panel.grid = element_blank(),\n  panel.spacing.y = unit(0, \"lines\"),\n  strip.text.y = element_text(angle = 0),\n  legend.position = \"bottom\",\n  legend.text = element_text(size = 9, color = \"grey40\"),\n  legend.box.margin = margin(t = 30),\n  legend.background = element_rect(\n    color = \"grey40\",\n    linewidth = .3,\n    fill = \"grey95\"\n  ),\n  legend.key.height = unit(.25, \"lines\"),\n  legend.key.width = unit(2.5, \"lines\"),\n  plot.margin = margin(rep(20, 4))\n)\n\nAnd the color palette\n\npal <- c(\"#FFB400\",\n         \"#C20008\",\n         \"#13AFEF\",\n         \"#8E038E\")\n\nLoad the data\n\ntuesdata <- tidytuesdayR::tt_load(2022, week = 50)\ncoverage_codes <- tuesdata$coverage_codes\nstate_retail <- tuesdata$state_retail\n\nAdd the states’ names\n\nfipcodes <- tigris::fips_codes %>%\n  select(state, state_name)\n\nJoin all sets\n\nmy_df <- state_retail %>%\n  left_join(fipcodes, by = c(\"state_abbr\" = \"state\")) %>%\n  mutate(state_name = ifelse(state_abbr == \"USA\", \"USA\", state_name)) %>%\n  distinct() %>%\n  merge(coverage_codes, by = \"coverage_code\") %>%\n  arrange()\n\nmy_df %>% head\n\nData wrangling\n\nmy_df1 <- my_df %>%\n  select(-naics) %>%\n  mutate(\n    coverage = case_when(\n      coverage == \"non-imputed coverage is greater than or equal to 10% and less than 25% of the state/NAICS total\" ~\n        \"greater than or equal 10% and less than 25% of the state/NAICS total\",\n      coverage == \"non-imputed coverage is greater than or equal to 25% and less than 50% of the state/NAICS total\" ~\n        \"greater than or equal to 25% and less than 50% of the state/NAICS total\",\n      coverage == \"non-imputed coverage is greater than or equal to 50% of the state/NAICS total.\" ~\n        \"greater than or equal to 50% of the state/NAICS total\",\n      coverage == \"non-imputed coverage is less than 10% of the state/NAICS total.\" ~\n        \"less than 10% of the state/NAICS total\",\n      TRUE ~ coverage\n    ),\n    month = as.character(month),\n    year = zoo::as.yearmon(paste0(year, \"-\", month)),\n    change_yoy = ifelse(change_yoy == \"S\", 0, change_yoy),\n    change_yoy_se = ifelse(change_yoy_se == \"S\", 0, change_yoy_se),\n    change_yoy = as.numeric(change_yoy),\n    change_yoy_se = as.numeric(change_yoy_se),\n    coverage = as.factor(coverage),\n    coverage = paste(coverage_code, \"-\", coverage)\n  ) %>%\n  filter(state_abbr %in% c(\"USA\", \"PA\", \"MD\", \"MT\")) %>%\n  filter(!coverage_code == \"S\") %>%\n  group_by(state_name, coverage, year) %>%\n  summarise_if(is.numeric, sum, na.rm = TRUE) %>%\n  mutate(change_yoy = scale(change_yoy, center = FALSE)) %>%\n  ungroup() %>%\n  mutate(year = as.POSIXct(year),\n         year = as.Date(year))\n\nMake the plot\n\nmy_df1 %>%\n  ggplot(aes(\n    x = year,\n    y = change_yoy,\n    color = coverage,\n    fill = coverage\n  )) +\n  geom_stream(\n    geom = \"contour\",\n    color = \"white\",\n    linewidth = 1.25,\n    bw = .45 # Controls smoothness\n  ) +\n  geom_stream(geom = \"polygon\",\n              bw = .45,\n              linewidth = 0.2) +\n  facet_grid(state_name ~ .,\n             scales = \"free_y\",\n             space = \"free\") +\n  scale_y_continuous(trans = scales::modulus_trans(0.1, 1)) +\n  scale_x_date(date_breaks = \"6 months\",\n               date_labels = \"%b-%Y\",\n               expand = c(0, 0)) +\n  scale_color_manual(expand = c(0, 0),\n                     values = pal,\n                     guide = \"none\") +\n  scale_fill_manual(values = pal,\n                    name = NULL) +\n  labs(title = \"Total Year-Over-Year percent change\\nin monthly retail sales value\",\n       subtitle = \"North American Industry Classification System (NAICS) top YoY states\",\n       caption = \"DataSource: #TidyTuesday 2022 Week50 | Monthly State Retail Sales | DataViz: Fgazzelloni\") +\n  theme(legend.direction = \"vertical\")\n\n\nggsave(\"w50_retail_sales.png\")"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w48_FIFA_World_Cup/w48_fifa_world_cup.html",
    "href": "tidytuesday/cases2022/posts2022/w48_FIFA_World_Cup/w48_fifa_world_cup.html",
    "title": "FIFA World Cup",
    "section": "",
    "text": "library(tidyverse)\n# set the fonts\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name=\"Roboto Condensed\",\n                family=\"Roboto Condensed\")  \nfont_add_google(name=\"Nerko One\",\n                family=\"Nerko One\")\n\n\ntuesdata <- tidytuesdayR::tt_load(2022, week = 48)\n# wcmatches <- tuesdata$wcmatches\nworldcups <- tuesdata$worldcups\n\n\nworldcups%>%names\n\n\nworldcups%>%DataExplorer::profile_missing()\n\n\nworldcups%>%head\n\n\nworldcups%>%pull(year)%>%summary()\n\n\ncountries <- worldcups%>%\n  pivot_longer(cols = 2:6,names_to = \"position\",values_to = \"countries\") %>%\n  count(countries)%>%\n  pull(countries)\n\ncountries\n\n\nworld <- rnaturalearth::ne_countries(returnclass = \"sf\")\n\na <- world%>%\n  filter(name%in%countries) %>%\n  data.frame() %>%\n  pull(name)\n\nsetdiff(countries,a)\n\n\nworld%>%\n  data.frame() %>%\n  arrange(name) %>%\n  pull(name) \n\n\nworldcups %>%\n    pivot_longer(cols = 2:6,names_to = \"position\",values_to = \"countries\")%>%\n  distinct() %>%\n  filter(countries==\"Yugoslavia\")\n\n\nworldcups_long <- worldcups %>%\n  pivot_longer(cols = 2:6,names_to = \"position\",values_to = \"countries\")%>%\n  distinct() %>%\n  mutate(countries=case_when(countries==\"Czechoslovakia\"~\"Czech Rep.\",\n                             countries==\"England\"~\"United Kingdom\",\n                             countries==\"Japan, South Korea\"~\"Japan\",\n                             countries==\"South Korea\"~\"Korea\",\n                             countries==\"Soviet Union\"~\"Russia\",\n                             countries==\"USA\"~\"United States\",\n                             countries==\"West Germany\"~\"Germany\",\n                             TRUE~countries))\n\n\nworldcups_long\n\n\nworldcups_long%>%count(year)\n\n\nlibrary(sf)\nfull_sf <- worldcups_long %>%\n  left_join(world,by=c(\"countries\"=\"name\")) %>%\n  st_as_sf() \n\nfull_sf\n\n\nggplot(world) +\n  geom_sf() +\n  geom_sf(data = full_sf,aes(fill=position))\n\n\nggplot(world) +\n  geom_sf() +\n  geom_sf(data = full_sf,aes(fill=attendance))\n\nContinuous:\n\nscale_fill_gsea\nscale_fill_material\n\n\nggplot(world%>%filter(!name==\"Antarctica\")) +\n  geom_sf(color=\"grey80\",\n          alpha=0.8,\n          linewidth=0.05,\n          fill=\"grey40\") +\n  geom_sf(data = full_sf,\n          aes(fill=goals_scored),\n          color=\"grey70\",\n          linewidth=0.2) +\n  coord_sf() +\n  ggsci::scale_fill_material(palette = c(\"cyan\"), \n                             alpha = 0.8, reverse = FALSE) +\n  guides(color=\"none\") +\n  labs(title=\"FIFA World Cup\\ntotal Goals scored since 1930\",\n       subtitle=\"\",\n       caption=\"#TidyTuesday week48 FIFA WORLD CUP\\nDataSource: FIFA World Cup | DataViz: Federica Gazzelloni\",\n       fill=\"Goals Scored\\n\\n1930-2018\") +\n  ggthemes::theme_map() +\n  theme(text=element_text(color=\"cyan\",family = \"Roboto Condensed\"),\n        plot.caption = element_text(hjust = 0.5,lineheight = 1.5),\n        legend.position = c(0,0),\n        legend.background = element_blank(),\n        plot.title = element_text(family=\"Nerko One\",size=16,hjust = 0.5),\n        plot.background = element_rect(color=\"black\",fill=\"black\"),\n        panel.background = element_rect(color=\"black\",fill=\"black\"))\n\n\nggsave(\"w48_fifa_world_cup.png\",\n       dpi=220,\n       width = 9,\n       height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w20_eurovision/w20_eurovision.html",
    "href": "tidytuesday/cases2022/posts2022/w20_eurovision/w20_eurovision.html",
    "title": "Eurovision",
    "section": "",
    "text": "# Remove everything (houskeeping)\nrm(list=ls())\n# Set the working directory (useful if you are in a .R script)\nsetwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n\n# Load the libraries\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(countrycode)\nlibrary(ggpattern)\nlibrary(cowplot)\n\n# Set the font\nshowtext_auto(enable = T)\n# sysfonts::font_families_google()\nsysfonts::font_add_google(\"Oregano\", \"Oregano\")\n\n# Read the data\neurovision <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-17/eurovision.csv')\n\n# Manipulate the data as needed\ndf <- eurovision %>%\n  group_by(host_country) %>% \n  count(year,artist,song,artist_country,running_order,total_points,rank,qualified,winner) %>%\n  ungroup() %>%   \n  filter(!is.na(song),\n         year>=1971,\n         rank<=15) %>% \n  arrange(year)%>%\n  mutate(rank_dsc=factor(desc(rank)))%>%\n  filter(!host_country%in%c(\"Serbia & Montenegro\", \"Yugoslavia\")) %>%\n  mutate(host_country=case_when(host_country==\"United Kingdom\"~\"UK\",\n                                host_country==\"Bosnia & Herzegovina\"~\"Bosnia and Herzegovina\",\n                                TRUE~host_country)) %>%\n  mutate(country_code_h = countrycode(host_country, \n                                      origin = 'country.name', \n                                      destination = 'iso2c'),\n         country_code_h=tolower(country_code_h))%>%\n  group_by(rank) %>%\n  mutate(tot=sum(total_points))%>%\n  arrange(tot)%>%\n  ungroup() %>%\n  filter(rank==1) %>%\n  group_by(host_country,country_code_h) %>%\n  summarize(tot=sum(total_points),.groups=\"drop\")%>%\n  arrange(tot) %>%\n  ungroup() \n\n# Add the flags' image\n# Source for flags' image https://github.com/lipis/flag-icons\n\n# Take the vector with the countries for setting the flags' image vector\nmy_codes<-df$country_code_h\n# Set the vector with flags' image\nflags <- paste0(\"https://raw.githubusercontent.com/lipis/flag-icons/main/flags/1x1/\",my_codes,\".svg\")\n\n# Add the image vector to the df\nmydf <- cbind(df,image=flags)\n\n# Adjust the order of the host country total points and create an id vector for the angles\nmydf1 <- mydf%>%\n  mutate(host_country=fct_reorder(host_country,-tot))%>%\n  mutate(id=seq(1, nrow(mydf)))%>%\n  relocate(id) \n\n# Set the angles\nangle <- 90 - 360*(mydf2$id - 0.5)/nrow(mydf2)\n\n# Add a vector with angles  \nmydf1$angle <- ifelse(angle< -90, angle + 180, angle)\n\n# Make the circular plot\nmydf1 %>%\n  ggplot(aes(x=host_country,y=tot)) +\n  ggpattern::geom_col_pattern(aes(pattern_filename= rev(host_country)),\n                   inherit.aes = T,\n                   pattern         = 'image',\n                   width                = 1, \n                   pattern_type    = 'none',\n                   fill            = '#1e88f7', \n                   colour          = 'white',\n                   pattern_scale        = -1,\n                   pattern_aspect_ratio = 1,\n                   pattern_key_scale_factor = 1,\n                   pattern_filter  = 'box',\n                   pattern_gravity = mydf2$angle) +\n  ylim(-800,2418)+\n  coord_polar(start = 0,theta = \"x\",direction = 1) +\n  ggpattern::scale_pattern_filename_discrete(choices = flags) +\n  theme_void()+\n  theme(legend.position = \"none\",\n        plot.background = element_rect(fill=NA,color=NA),\n        panel.background = element_rect(fill=NA,color=NA))\n\n# Save the circular plot\nggsave(\"circular.png\",\n       dpi=320,\n       bg = \"black\",\n       width = 6,\n       height = 6)\n\n# Frame the plot and add annotations\nggdraw() +\n  draw_image(\"circular.png\")+\n  # add the eurovision logo\n  draw_image(\"Logo-ESC-Generico.jpeg\",scale=0.1) +\n  draw_label(\"Eurovision\",\n             color=\"white\",fontfamily = \"Oregano\",\n             x=0.25,y=0.92,size=180) +\n  draw_label(\"Host Countries\",\n             color=\"white\",fontfamily = \"Oregano\",\n             x=0.3,y=0.8,size=94) +\n  draw_label(\"The highest total points first from 1971 to 2020\\nDataSource: #TidyTueday Week20 - Eurovision TV\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n             x=0.5,y=0.1,size=41,lineheight = 0.3,\n             color=\"white\",fontfamily = \"Oregano\")\n\n# Save the final version\nggsave(\"w20_eurovision.png\",\n       dpi=320,\n       bg = \"black\",\n       width = 6,\n       height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w19_nyt/w19_nyt.html",
    "href": "tidytuesday/cases2022/posts2022/w19_nyt/w19_nyt.html",
    "title": "NYTimes best sellers",
    "section": "",
    "text": "Housekeeping: clean the space before to start and set the working dorectory to your .R file source\nrm(list=ls()) setwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n\n# load the libraries\nlibrary(tidyverse)\nlibrary(forcats)\nlibrary(ggridges)\nlibrary(showtext)\nlibrary(cowplot)\n\n# set the font\nshowtext_auto(enable = T)\nsysfonts::font_families_google()\nsysfonts::font_add_google(\"Abril Fatface\", \"Abril Fatface\")\n\n\n# load data\nnyt_titles <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')\nnyt_full <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')\n\n# look at the data\nnyt_titles%>%head\nnyt_full%>%head\n\n# a bit of wrangling\ndf <- nyt_titles %>%\n  full_join(nyt_full,by=c(\"year\",\"title\",\"author\"))\n\ndf2 <- df %>%\n  mutate(year_fct = fct_rev(as.factor(year))) %>% # \n  filter(!str_detect(author,\"Edited|edited|created|compiled|Completed|NO AUTHOR| and |Illustrated| with |translated\"))%>%\n  mutate(author=gsub(\"! by |? by |?by |\\\\?|\\\"|, Jr| Jr|\\\\.$| writing as.*\",\"\",author)) %>%\n  group_by(author) %>%\n  summarise(year_fct,\n            avg_rank=mean(rank),\n            scale=scale(rank,center = F),\n            scale_pct=scale/sum(scale),\n            avg_rank_pct=avg_rank/sum(avg_rank),\n            id=n()) %>%\n  ungroup()\n\n# set the dataset for the geom_text labels\nside_labels <- df2 %>%\n  group_by(year_fct,author)%>%\n  summarize(top=max(scale),scale_pct=mean(scale_pct))%>%\n  distinct()%>%\n  filter(top==max(top))%>%\n  mutate(lab=paste(author,\"in\",year_fct),\n         lab2=paste(author,\"ranked\",round(top),\"on avg in\",year_fct))%>%\n  ungroup() %>%\n  select(year_fct,lab,scale_pct)%>%\n  arrange(desc(year_fct))\n\n\n\n# make the plot\ndf2 %>% \n  # reorder different authors within the same year along with the percentages values\n  # this will reorder the density courves for each year \n  mutate(author=fct_reorder(author,scale_pct)) %>%\n  ggplot(aes(x=scale_pct, y=year_fct)) +\n  geom_density_ridges(aes(fill=author),\n                      show.legend = F,\n                      size=0.3,\n                      scale=1,\n                      alpha = .8, \n                      color = \"grey25\", \n                      from = 0, to = 1) +\n  geom_label(data=side_labels,\n             aes(x=0.5,y=year_fct,label=lab),\n             label.padding = unit(0.05, \"lines\"),\n             label.r = unit(0.5, \"lines\"),\n             label.size = 0,\n             family=\"Abril Fatface\",size=10,\n             inherit.aes = F,hjust=0,vjust=0)+\n  scale_y_discrete(expand = c(0, 0)) +\n  scale_x_continuous(expand = expansion(mult=c(0,-0.35),\n                                        add=c(0, -0.02))) +\n  scale_fill_grey(\n    start = 0.2,\n    end = 0.9,\n    na.value = \"red\",\n    aesthetics = \"fill\") +\n  labs(title=\"The New York Times\",\n       subtitle=\"Solo author ranks from 1931 to 2020\",\n       caption=\"DataSource: Post45 Data Collective NYT HARDCOVER FICTION BESTSELLERS\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       x=\"Rank density\",y=\"Year\") +\n  coord_cartesian(clip = \"off\") +\n  theme_ridges(grid = FALSE)+\n  theme(text = element_text(family=\"Abril Fatface\",size=45),\n        plot.title = element_text(size=90),\n        plot.caption = element_text(hjust=1),\n        axis.text.y = element_text(size=30,hjust=0),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        plot.background = element_rect(color=\"grey90\",fill=\"grey90\"),\n        panel.background = element_rect(color=\"grey90\",fill=\"grey90\"))\n\n# save first partial version\nggsave(\"partial.png\",\n       dpi=320,\n       height = 14,\n       width =  10)\n\n# frame the graphics and add a notation with {cowplot}\n# it helps reducing time when setting the text position.\nggdraw()+\n  draw_image(\"partial.png\") +\n  draw_label(\"How to read it: \nOn average, authors rank 7.6 based on weekly frequencies on NYT, \nwhich corresponds to 3.4% of the total scaled avg-ranks.\nEach year shown in the graph represents the density curve of the \nranks for the NYT's solo authors in that year.\nThe density curves are ordered by total percentage of scaled ranks.\nOn the right is the author with the avg-weekly highest rank for the year.\",\n             lineheight = 0.25,hjust=0,\n              x=0.04,y=0.05,fontfamily=\"Abril Fatface\",size=25)\n\n# save the final version\nggsave(\"w19_nyt.png\",\n       dpi=320,\n       height = 12,\n       width =  9)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w38_hydro_wastewater/w38_hydro_wastewater.html",
    "href": "tidytuesday/cases2022/posts2022/w38_hydro_wastewater/w38_hydro_wastewater.html",
    "title": "Hydro Wastewater plants",
    "section": "",
    "text": "library(tidyverse)\n\n\nHydroWASTE_v10 <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-20/HydroWASTE_v10.csv')\n\nHydroWASTE_v10%>%names\n\n\nHydroWASTE_v10%>%DataExplorer::profile_missing()\n\n\n# HydroWASTE_v10%>%View()\n\n\ndf <- HydroWASTE_v10%>%\n  janitor::clean_names()%>%\n  count(country,lat_wwtp,lon_wwtp,source,\n        qual_loc,qual_pop,qual_waste,qual_level,qual_cap)\n\n\n# source: https://stackoverflow.com/questions/68278789/how-to-rotate-world-map-using-mollweide-projection-with-sf-rnaturalearth-ggplot\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(sf)\n\ntarget_crs <- st_crs(\"+proj=moll +x_0=0 +y_0=0 +lat_0=0 +lon_0=133\")\n\nworldrn <- ne_countries(scale = \"medium\", returnclass = \"sf\") %>%\n  st_make_valid()\n\n\n# define a long & slim polygon that overlaps the meridian line & set its CRS \n# Centered in lon 133\noffset <- 180 - 133\n\n# build a polygon\npolygon <- st_polygon(x = list(rbind(\n  c(-0.0001 - offset, 90),\n  c(0 - offset, 90),\n  c(0 - offset, -90),\n  c(-0.0001 - offset, -90),\n  c(-0.0001 - offset, 90)))) %>%\n  st_sfc() %>%\n  st_set_crs(4326)\n\n\n# set the polygons\nworld2 <- worldrn %>% \n  st_difference(polygon) %>% \n  st_transform(crs = target_crs)\n\nSet the values for hydro waste to the new target crs.\n\ncoords <- df %>% \n  rename(lat=lat_wwtp,lon=lon_wwtp) %>%\n  sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326) %>% \n  sf::st_transform(crs = target_crs) \n\nSet the colors.\n\nlibrary(RColorBrewer)\nmy_palette <- RColorBrewer::brewer.pal(12,\"Set3\")\n\nmy_values <- c(\"1\"=\"#8DD3C7\", \n               \"2\"=\"#FFFFB3\",\n               \"3\"=\"#BEBADA\", \n               \"4\"=\"#FB8072\",\n               \"5\"=\"#80B1D3\", \n               \"6\"=\"#FDB462\",\n               \"7\"=\"#B3DE69\",   \n               \"8\"=\"#FCCDE5\",\n               \"9\"=\"#D9D9D9\",\n               \"10\"=\"#BC80BD\",\n               \"11\"=\"#CCEBC5\", \n               \"12\"=\"#FFED6F\")\n\nmy_labels<-c(\"Europe\", \"United States\",\n             \"Brazil\", \"Mexico\",\n             \"China\", \"Canada\",\n             \"Australia\",   \"South Africa\",\n             \"India\", \"New Zealand\",\n             \"Peru\", \"Remaining Countries\")\n\nMake the mollweide, more info on how to set the projections here: https://epsg.io/54009\n\nggplot() + \n  geom_sf(data = world3, aes(group = admin), \n          fill = \"#f5f5f5\") + \n  geom_sf(data = coords,\n          mapping = aes(color=factor(source)),\n          key_glyph = draw_key_rect,\n          size=0.1) + \n  scale_color_manual(labels=my_labels,values=my_values)+\n  labs(title=\"Wastewater Plants\",\n       subtitle=\"Concentrated point sources of residual contaminant loads into surface waters\",\n       caption=\"DataSource: #TidyTuesday 2022 week38 Hydro Wastewater | DataViz: Federica Gazzelloni @fgazzelloni\",\n       color=\"Source of\\nwaterwaste\")+\n  coord_sf()+\n  ggthemes::theme_map() +\n  theme(plot.title = element_text(size=14,face=\"bold\"),\n        plot.subtitle = element_text(size=12,face=\"bold\"),\n        text=element_text(family=\"Roboto Condensed\",color=\"#89a5b9\"),\n        panel.grid = element_line(color=\"#bfd0dd\"),\n        plot.background = element_rect(fill=\"#275477\",color=\"#275477\"),\n        panel.background = element_rect(fill=\"#275477\",color=\"#275477\"),\n        legend.background = element_blank(),\n        legend.position = c(-0.05,0.05),\n        legend.key = element_rect(size=4))\n\nSave it.\n\nggsave(\"w38_hydro_waterwaste.png\",\n       dpi=320,\n       width = 10,\n       height = 5)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w28_european_flights/w28_european_flights.html",
    "href": "tidytuesday/cases2022/posts2022/w28_european_flights/w28_european_flights.html",
    "title": "European flights",
    "section": "",
    "text": "This #TidyTuesday week 28 is all about European flights. I was looking for a visualization that would represent the differences among countries in terms of the number of airports versus number of flights. I looked on the internet for getting some inspiration and then landed on Pintarest, where I found exactly what I was hoping for: a Sankey! First of all, What is a Sankey? The answer is clearer after you make one of your own. In short, it is a network graph connecting diffent groups with a ribbon. A few things that made me think about a lot were the requirenment for the type of data to combine, the consequent label results, and the grouping.\nSo, let’s have a go in making a Sankey.\nHave a quick look at the data for European flights:\nLoad the {tidyverse} and the data from: #TidyTuesday GitHub repo\n\nflights <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-12/flights.csv')\n\nJus a little cleaning for this type of data with janitor::clean_names() function, and it’s ready to use.\n\nflights <- flights%>%\n  janitor::clean_names()\n\nThe best way is to select a subgroup among the list of the European countries in the data set, and represent the diversity in aerial traffic.\nAs an example I choose Ukraine airports, and found that there is only one airoprt for Ukraine in the dataset. But, the interesting thing is that it covers on average almost the same aerial traffic of other European countries such as Italy which is provided with a far larger number of airports, in this dataset.\n\nflights %>%\n  filter(state_name == \"Ukraine\") %>%\n  count(state_name,apt_name)\n\nCompare Italy median of the total number of flights by airports with the only available airport aerial traffic in Ukraine:\n\nflights %>%\n  filter(state_name %in% c(\"Ukraine\",\"Italy\")) %>%\n  count(state_name,pivot_label,flt_tot_1) %>%\n  group_by(state_name) %>%\n  summarize(total_median = median(flt_tot_1)) \n\nThe results of this preliminary data exploration arise a question:"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w28_european_flights/w28_european_flights.html#does-the-number-of-airports-influence-countries-aerial-traffic",
    "href": "tidytuesday/cases2022/posts2022/w28_european_flights/w28_european_flights.html#does-the-number-of-airports-influence-countries-aerial-traffic",
    "title": "European flights",
    "section": "Does the number of airports influence countries’ aerial traffic?",
    "text": "Does the number of airports influence countries’ aerial traffic?\n\n\nWaffle\nMake the first part of the visualization as a series of waffle, one for each selected country to show the diferences in number of airports.\nSelected are 6 countries with a varied number of airports and flights, this is done to give the idea of the differences.\n\ndf <- flights%>%\n  filter(state_name %in% c(\"Ukraine\",\"Belgium\",\"France\",\"Italy\",\"Spain\",\"United Kingdom\")) %>%\n  group_by(state_name) %>%\n  count(apt_name,sort=T) %>%\n  mutate(apt_id = seq(1,length(state_name),1)) %>%\n  summarise(tot = max(apt_id)) %>%\n  arrange(-tot)\n\ndf\n\nLoad both libraries {waffle} and {ggsankey} to use a feature in the waffle which is provided by the ggsankey package.\n\nlibrary(waffle)\nlibrary(ggsankey)\n\nThe waffles shows the number of airports for the selected countries on a total of 100. To make the waffle we can safetly use the geom_waffle() layer\n\nwaffle <- df %>%\n  mutate(rr = 100 - tot) %>% # this is the remaining part of the 100 set of cubes in the waffle\n  pivot_longer(cols = c(tot,rr),names_to = \"values_name\",values_to = \"values\") %>% \n  arrange(state_name) %>%\n  ggplot(aes(fill = values_name, values = values)) +\n  geom_waffle(n_rows = 10, \n              size = 0.33, \n              make_proportional = F,\n              colour = \"white\", \n              flip = TRUE,\n              show.legend = F) +\n  facet_wrap(~ state_name,nrow = 1)+\n  coord_equal() +\n  scale_fill_manual(values=c(\"grey60\",\"#8E0152\"))+\n  theme_sankey(base_size = 16) +\n  theme_enhance_waffle() +\n  theme(strip.text = element_blank(),\n        plot.background = element_blank(),\n        panel.background = element_blank())\n\nwaffle\n\n\nSankey\nThe purpose of this sankey is to show the differences among selected countries on number of airports and number of flights, from 2016 to 2022 for 6 selected countries.\nThe {ggsankey} package uses an interesting function make_long() which transform provided object into a longer data frame, with vectors named as:\n\nx, next_x, node, and next_node\n\nready to be used inside the geom_sankey.\n\nsankey <- df %>%\n  left_join(flights %>% select(state_name,flt_tot_1), by = \"state_name\") %>%\n  group_by(state_name,tot) %>%\n  summarize(total_med = median(flt_tot_1),.groups = \"drop\") %>%\n  ungroup() %>%\n  mutate(class = cut(tot,\n                     breaks = c(0,1,5,50,65)), #) %>% pull(tot) %>% summary()\n         tot_class = cut(total_med,\n                         breaks = c(0,10,30,65,120,700))) %>% #count(tot_class)\n  mutate(class_id = case_when(class == \"(0,1]\" ~ \"one\",\n                              class == \"(1,5]\" ~ \"up to 5\",\n                              class == \"(5,50]\" ~ \"up to 50\",\n                              TRUE ~ \"up to 65\"),\n         tot_class_id = case_when(tot_class == \"(0,10]\" ~ \"one\",\n                              tot_class == \"(10,30]\" ~ \"up to 30\",\n                              tot_class == \"(30,65]\" ~ \"up to 65\",\n                              tot_class == \"(65,120]\" ~ \"up to 120\",\n                              TRUE ~ \"up to 700\")) %>%\n  mutate(state_name= ifelse(state_name==\"United Kingdom\",\"UK\",state_name)) %>%\n  # function to make the object ready to be used in the geom_sankey\n  make_long(tot_class_id,class_id,state_name) %>% \n  ggplot(aes(x = x, \n             label= node,\n             next_x = next_x, \n             node = node, \n             next_node = (next_node),\n             fill = factor(node))) +\n  geom_sankey(flow.alpha = 0.8, \n              node.color = 1,\n              show.legend = FALSE) +\n  geom_sankey_text(angle=0,family = \"Roboto Condensed\", size = 3)+\n  scale_fill_manual(values = colorRampPalette(RColorBrewer::brewer.pal(11, \"PiYG\"))(13))+\n  theme_sankey(base_size = 16) +\n  coord_flip(expand = F) +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank(),\n        plot.background = element_blank(),\n        panel.background = element_blank())\n  \nsankey\n\n\n\nEuropean Map\nThe map has been saved as map.png and sourced in the main visualization. The code can be found in a separate file named “eu_coords.R”.\n\n\n\n\nUse {cowplot} for assembling the plots, adding notes, the map and the logo as images.\n\nlibrary(cowplot)\n\n\n combo <- ggdraw() +\n  draw_image(\"map.png\",\n             scale=0.5,\n             x=0.3,y=0.4)+\n  draw_plot(waffle,\n            scale=1,\n            x=0,y=0.2) +\n  draw_plot(sankey, \n            scale=0.7,\n            width = 1.4,\n            height = 0.85,\n            x=-0.2, y=-0.093) +\n  draw_label(\"Countries such as France and Spain have the highest number of airports while this\\nseems reasonable, other countries such as Ukraine with just one airport record\\namong the countries with the highest total number of flights. Data are released\\nwithin a range of 7 years from 2016 to 2022.\",\n             x=0.02,y=0.90,size=9,hjust=0, \n             fontfamily=\"Roboto Condensed\") +\n  draw_label(\"N. of airports\", x=0.1,y=0.4,\n             fontfamily=\"Roboto Condensed\") +\n  draw_label(\"N. of flights\\n(median values)\", x=0.1,y=0.16,\n             fontfamily=\"Roboto Condensed\") +\n  draw_image(\"eurocontrol_logo.png\",\n             scale=0.1,\n             x=-0.45,y=-0.52) +\n  draw_label(\"Eurocontrol aviation intelligence\\n(ansperformance.eu)\",\n             x=0.22,y=-0.02,size=9,fontfamily=\"Roboto Condensed\")\n\n\ncombo\n\nUse {ggpubr} for arranging the grid of the main visualization, so it can be annotate with annotate_figure() to making it a bit more standing out with spaces around the plot and top and bottmo annotations already at the right distance/position.\n\nlibrary(ggpubr)\n\nggpubr::annotate_figure() provides a framework for annotating the plot on the four sides top, bottom, left and right. It comes a handy function when you’d like to position notes or even rich text at specified positions. To use it, it requires an object from ggpubr::ggarrange().\n\nplot <- ggpubr::ggarrange(combo) \n\n  ggpubr::annotate_figure(plot,\n               top = text_grob(\"Does the number of airports influence countries' aerial traffic?\", \n                               color = c(\"#8E0152\"), face = \"bold\", family = \"Roboto Condensed\", \n                               size = 18, vjust = 1.4),\n               bottom = text_grob(\"DataSource:TidyTuesday 2022 week28 European flights\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n                                  color = \"#8E0152\",\n                                  hjust = 1, x = 1, face = \"italic\",  family = \"Roboto Condensed\", \n                                  size = 10),\n               left = text_grob(\"\", color = c(\"#7FBC41\"), rot = 90, size=10),\n               right = text_grob(bquote(\"\"), color=c(\"#DE77AE\"), rot = 90, size=10),\n                fig.lab = \"European flights\", fig.lab.face = \"bold\")\n\nThen finally, save it as .png file with ggsave() function. I specified a height a little bit more than the default values provided as I needed more space.\nThe other arguments, dpi and bg are to set the pixels and the background color.\n\nggsave(\"waffle_sankey.png\",\n       dpi=320,\n       bg = \"grey95\",\n       height = 7.2)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w1_your_own_data/w1_your_own_data.html",
    "href": "tidytuesday/cases2022/posts2022/w1_your_own_data/w1_your_own_data.html",
    "title": "Bring your own data from 2022!",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)\neu_data <- read_csv(\"/Users/federica/Documents/R/GBD/Comunicable_diseases/Covid19/variants/data.csv\")\neu_data2 <- read_csv(\"/Users/federica/Documents/R/GBD/Comunicable_diseases/Covid19/variants/data2.csv\")\n\n\neu_data%>%\n  select(country,variant)%>%\n  filter(str_detect(variant,\"B.1.1.\"))%>% #variant B.1.1.529\n  count(variant)\n\n\ncountrySubmissionCount <- read_csv(\"/Users/federica/Documents/R/GBD/Comunicable_diseases/Covid19/variants/countrySubmissionCount.csv\")\ncountrySubmissionCount2 <- read_csv(\"/Users/federica/Documents/R/GBD/Comunicable_diseases/Covid19/variants/countrySubmissionCount2.csv\")\n\n# map data\nlibrary(sf)\nworld <- rnaturalearth::ne_countries(scale=110,returnclass = \"sf\")\nworld<-filter(world,!continent==\"Antarctica\")\n\n\n# December 2021 data\nnew_data<- countrySubmissionCount%>%\n  mutate(variant=\"B.1.1.529\")%>%\n  rename(percent_variant=\"%GR/484A (B.1.1.529) in past 4 weeks\",\n         number_detections_variant=\"Total #GR/484A (B.1.1.529)\")%>%\n  mutate(year_week=\"2021-46\")%>%\n  janitor::clean_names()%>%\n  select(country,variant,percent_variant,year_week,number_detections_variant)\n\nfull_data <- eu_data%>%#count(country)%>%View()\n  full_join(new_data,by=c(\"country\",\"variant\",\"percent_variant\",\"year_week\",\"number_detections_variant\"))%>%\n  filter(str_detect(variant,\"B.1.1.5\"))%>%\n  filter(number_detections_variant>0)\n\nfull_data_geo<- full_data%>%\n  inner_join(world,by=c(\"country\"=\"name\"))\n\n# January 2022 data\nnew_data2<- countrySubmissionCount2%>%\n  mutate(variant=\"B.1.1.529\")%>%\n  rename(percent_variant=\"%Omicron GRA (B.1.1.529+BA.*) in past 4 weeks\",\n         number_detections_variant= \"Total #Omicron GRA (B.1.1.529+BA.*)\")%>%\n  mutate(percent_variant=gsub(\"%\",\"\",percent_variant),\n         percent_variant=as.double(percent_variant))%>%\n  mutate(year_week=\"2022-01\")%>%\n  janitor::clean_names()%>%\n  select(country,variant,percent_variant,year_week,number_detections_variant)\n\nfull_data2 <- eu_data2%>%#names()\n  select(country,year_week,new_cases,variant,percent_variant,number_detections_variant)%>%\n  full_join(new_data2,by=c(\"country\",\"variant\",\"percent_variant\",\"year_week\",\"number_detections_variant\"))%>%\n  filter(str_detect(variant,\"B.1.1.5\"))%>%\n  filter(number_detections_variant>0)\n\nfull_data_geo2<- full_data2%>%\n  inner_join(world,by=c(\"country\"=\"name\"))\n\n\n\ndec<-new_data%>%group_by(country)%>%summarise(median_dec=median(percent_variant))\n\njan<-new_data2%>%group_by(country)%>%summarise(median_jan=median(percent_variant))\n\nmerged<-dec%>%\n  merge(jan,by=\"country\")\n\ncountries<-merged%>%count(country)%>%select(-n)\n\n# libraries for fonts\nlibrary(ggCyberPunk)\nggCyberPunk::import_aldrich()\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=110)\nlibrary(sysfonts)\nsysfonts::font_families_google()\nfont_add_google(name =\"Texturina\" ,family = \"my_font\")\nfont_add_google(name =\"Suravaram\" ,family = \"my_font2\")\n\nfamily<-\"my_font\"\nfamily2<-\"my_font2\"\n\nlibrary(ggh4x)\nbarplot<-merged%>%\n  pivot_longer(cols = 2:3,names_to=\"names\",values_to=\"values\")%>%\n  ggplot()+\n  geom_col(aes(x=fct_reorder(country,-values),values,fill=names),\n           width = 0.5)+\n  scale_fill_cyberpunk(palette= \"laser sword\",reverse=F,\n                       labels=c(\"December\",\"January\"),\n                       name=\"\")+\n  scale_x_discrete(expand = expansion(mult = c(0,0)))+\n  # from: https://cran.r-project.org/web/packages/ggh4x/vignettes/PositionGuides.html\n  guides(y = guide_axis_manual( label_size = c(12, 9),label_hjust=1))+\n  coord_flip()+\n  theme_void()+\n  theme(text = element_text(family=family,size=14,color = \"#FFE1FF\"),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.y = element_text(family=family2,\n                                   size=8,color = \"#FFE1FF\",hjust = 0),\n        panel.grid = element_blank(),\n        plot.background = element_blank(),\n        panel.background = element_blank(),\n        legend.position = c(0.7,0.5),\n        legend.key.size = unit(0.5, 'cm'), #change legend key size\n        legend.key.height = unit(0.5, 'cm'), #change legend key height\n        legend.key.width = unit(0.5, 'cm'), #change legend key width\n        legend.text = element_text(size=10))\n\n\n\nplot <- ggplot(world)+\n  geom_sf(aes(geometry=geometry),fill=\"white\",size=0.01)+\n  geom_sf(data=full_data_geo,\n          mapping=aes(geometry=geometry,\n                      fill=percent_variant,\n                      color=percent_variant),\n          size=0.01)+\n  scale_fill_cyberpunk(palette = \"laser sword\",\n                       reverse=F,discrete=F,\n                       name=\"Percent Variant\",\n                       labels=c(\"<10%\",\"20%\",\"40%\",\"60%\"))+\n  coord_sf()+\n  labs(title=\"How fast is the New OMICRON variant spreading in the World?\")+\n  guides(color=\"none\")+\n  ggthemes::theme_map()+\n  theme(text = element_text(family=family,size=14,color = \"#FFE1FF\"),\n        plot.title = element_text(vjust=-1.5,size=12),\n        plot.title.position = \"panel\", \n        plot.caption = element_text(vjust=8),\n        legend.background = element_blank(),\n        legend.position = \"none\")\n\n\nplot2 <- ggplot(world)+\n  geom_sf(aes(geometry=geometry),fill=\"white\",size=0.01)+\n  geom_sf(data=full_data_geo2,\n          mapping=aes(geometry=geometry,\n          color=percent_variant,fill=percent_variant),size=0.1)+ \n  scale_fill_cyberpunk(palette= \"laser sword\",\n                       discrete = F,reverse = F,\n                       labels=c(\">0\",\"25%\",\"50%\",\"75%\",\"100%\"),\n                       name=\"\")+\n  coord_sf()+\n  guides(color=\"none\")+\n  ggthemes::theme_map()+\n  theme(text = element_text(family=family,size=14,color=\"#FFE1FF\"),\n        legend.direction = \"horizontal\",\n        legend.background = element_blank(),\n        legend.position =c(-0.35,0.5),\n        legend.justification = \"center\",\n        legend.text.align = 0.5,\n        legend.title = element_text(face = \"bold\",size=14),\n        legend.key.size = unit(0.5, 'cm'), #change legend key size\n        legend.key.height = unit(0.5, 'cm'), #change legend key height\n        legend.key.width = unit(0.5, 'cm'), #change legend key width\n        legend.text = element_text(size=10))\n\n\n\nlibrary(cowplot)\n\nfile<-\"data/2022/w1_your_own_data/your_own_data.png\"\nragg::agg_png(file,\n              res = 320, \n              width = 1200, \n              height = 675, \n              units = \"px\",\n              background = \"#5e3e4e\",#\"#4287f5\",\n              scaling = 0.5)\n\nggdraw()+\n  draw_label(\"Omicron genome sequences with unprecedented speed - one month of infection\",\n             x=0.5,y=0.97,fontfamily = family,size=20,\n             color=\"#eb3471\")+\n  draw_label(\"Omicron genome sequences with unprecedented speed - one month of infection\",\n             x=0.5,y=0.975,fontfamily = family,size=21,\n             color=\"#FFE1FF\")+\n  draw_plot(plot,x=0.18,y=0.2,scale=0.65)+\n  draw_plot(plot2,x=0.18,y=-0.25,scale=0.65)+\n  draw_label(\"Percent Variant (median values)\",\n             x=0.15,y=0.88,fontfamily = family,size=12,\n             color=\"#FFE1FF\")+\n  draw_plot(barplot,x=-0.28,y=0.15,scale=0.4)+\n  draw_label(\"Datasource: ECDC & GISAID | Map: Federica Gazzelloni\",\n             x=0.5,y=0.025,fontfamily = family,size=11.5,\n             color=\"#FFE1FF\")+\n  draw_label(\"Date: December 1st 2021\",x=0.98,y=0.73,size=10,angle=-90,\n             color=\"#FFE1FF\",fontfamily = family)+\n  draw_label(\"Date: January 7th 2022\",x=0.98,y=0.3,size=10,angle=-90,\n             color=\"#FFE1FF\",fontfamily = family)+\n  draw_label(\"Percent Variant\",x=0.15,y=0.33,size=12,color=\"#FFE1FF\",fontfamily = family)+\n  draw_label(\"Percent Variant values are calculated\\nconsidering the increase in\\nCovid19 new cases due\\nto the Omicron variant\",\n             x=0.15,y=0.1,size=10,color=\"#FFE1FF\",fontfamily = family) +\n  draw_image(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\",x=0.25,y=-0.45,scale=0.09)+\n  draw_image(\"data/2022/w1_your_own_data/omicron.png\",x=0.35,y=-0.45,scale=0.09)\n\ninvisible(dev.off())"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w2_bees/w2_bees.html",
    "href": "tidytuesday/cases2022/posts2022/w2_bees/w2_bees.html",
    "title": "Bee Colony losses",
    "section": "",
    "text": "library(tidyverse)\n\n\ncolony <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/colony.csv')\nstressor <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/stressor.csv')\n\n\ndf <- colony %>%\n  full_join(stressor,by=c(\"year\",\"months\",\"state\"))\n\ndf<-df%>%filter(!is.na(colony_n))\n\n\nmap <- ggplot2::map_data(\"state\")\nmap\n\nlibrary(maps)\ndata(state.fips)\nabb<-state.fips%>%select(polyname,abb)\n\nmap <-map%>%left_join(abb,by=c(\"region\"=\"polyname\"))%>%\n  mutate(abb=case_when(region==\"massachusetts\"~\"MA\",\n                       region==\"michigan\"~\"MI\",\n                       region==\"new york\"~\"NY\",\n                       region==\"north carolina\"~\"NC\",\n                       region==\"virginia\"~\"VA\",\n                       region==\"washington\"~\"WA\",\n                       TRUE ~ abb))\n\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\nfont_families_google()\nfont_add_google(name=\"Baskervville\",family=\"bees1\")\n\n\n#font_add_google(name =\"Black Han Sans\" ,family = \"my_font\")\n#font_add_google(name =\"Odibee Sans\" ,family = \"my_font1\")\n\nfamily = \"bees1\"\n\n\ntidy_df <- df%>% \n  count(state,year,colony_lost_pct,stressor,stress_pct)%>%\n  filter(year==c(2015,2020))%>%\n  mutate(state=tolower(state))%>%\n  filter(!state%in%c(\"hawaii\",\"other states\",\"united states\"))%>%\n  filter(!is.na(stress_pct))%>%\n  select(-n) %>% # \n  pivot_wider(names_from = year,values_from=stress_pct,\n              values_fill = 0.00001, values_fn={mean}) %>%\n  mutate(stress_pct_diff=round(((`2020`/`2015`) *100)-100))\n  \ntidy_df_geo <- tidy_df%>% left_join(map,by=c(\"state\"=\"region\"))\n\n\nbees_map_df <- tidy_df_geo%>%\n  group_by(state)%>%\n  mutate(lat2=median(range(lat)),\n         long2=median(range(long)))%>% # this is to positioning the numbers \n  ungroup()%>%\n  count(state,abb,long2,lat2,group,stress_pct_diff)%>%\n  group_by(state) %>%\n  mutate(m_stress_pct_diff=round(mean(stress_pct_diff)/10000000,2))%>%\n  ungroup()\n \nbees_map <-ggplot()+\n  geom_polygon(data=tidy_df_geo,\n               mapping=aes(x=long, y=lat, group = group),\n               alpha=0.2,fill=\"gold\",show.legend = F)+\n    \n  stat_summary_hex(data=tidy_df_geo,aes(x=long,y=lat,z=group),\n                   fill=\"orange\",color=\"gold\") +\n  geom_point(data=bees_map_df,mapping = aes(x=long2, y=lat2, group = group,\n                           size=m_stress_pct_diff),\n             shape=21,stroke=0.1,color=\"#299E50\") +\n  geom_text(data=bees_map_df,\n            mapping = aes(x=long2, y=lat2, group = group,\n                           label=abb),size=3,color=\"grey25\") +\n  scale_size_identity(guide=\"legend\")+\n  guides(size = guide_legend(override.aes = list(color = \"grey25\",stroke=1)))+\n  labs(title=\"US Bees colony lost and stressor\",\n       subtitle=\"(%) difference 2015 - 2020\",\n       size=\"AVG Stressor (%)\") +\n  ggthemes::theme_map()+\n  theme(text = element_text(family=family,face=\"bold\"),\n        legend.background = element_blank(),\n        legend.box.background = element_blank(),\n        legend.position = c(0.1,-0.15),\n        legend.key = element_rect(fill=\"orange\",color=\"gold\",size=2),\n        legend.text = element_blank(),\n        plot.background = element_blank(),\n        plot.title = element_text(size=25,face=\"bold\"),\n        plot.subtitle =  element_text(size=15),\n        panel.background = element_blank())\n\n# bees_map\n\n\nlibrary(ggimage)\n\nbees_fly <-df%>%\n  filter(year%in%c(2015,2020))%>%\n  select(state,stressor,stress_pct,colony_lost,year) %>% \n  mutate(stress_pct=ifelse(is.na(stress_pct),0,stress_pct)) %>% \n  #group_by(state)%>%summarize(mean=mean(stress_pct))\n  pivot_wider(names_from = year,values_from=colony_lost,\n              values_fn={mean},values_fill=0) %>%\n  mutate(diff_colony_lost=round(`2020`-`2015`)) %>%\n  #select(-`2015`,-`2020`)%>%\n  mutate(stressor=case_when(stressor==\"Other pests/parasites\"~\"Other\",\n                            stressor==\"Unknown\"~\"Other\",\n                            TRUE~stressor)) %>%\n  group_by(stressor) %>%\n  mutate(m_colony_lost=mean(diff_colony_lost))%>%\n  ungroup()%>%\n  #mutate(img = \"<img src='w2_bees/bees.png' width='12'/>\") %>%\n  mutate(img = \"bees.png\",\n         img=as.factor(img)) %>%as.data.frame()\n\n\npct_decr_lost<- bees_fly %>%\n  count(stressor,m_colony_lost=round(m_colony_lost))%>%\n  mutate(tot_loss=round(m_colony_lost*n),\n         pct=paste0(round(tot_loss/sum(tot_loss)*100),\"%\"))\n\n\nrange(bees_fly$m_colony_lost)\n\n\nbees_fly_plot<-bees_fly%>%\n  left_join(select(pct_decr_lost,stressor,pct),by=\"stressor\")%>%\n  ggplot(aes(x=fct_reorder(stressor,m_colony_lost),y=m_colony_lost))+\n  geom_line(orientation = \"x\",aes(group=1))+\n  ggimage::geom_image(aes(image=img), size=.1) +\n  geom_vline(aes(xintercept=fct_reorder(stressor,-m_colony_lost)),alpha=0.2,color=\"gold\")+\n  geom_text(aes(label=stressor),vjust=-2.5,hjust=0.65)+\n  geom_text(aes(label=pct),vjust=2.5)+\n  expand_limits(x=0,y=c(-1300 , -900))+\n  scale_y_reverse()+ #limits=rev)+\n  scale_x_discrete(limits=rev)+ #limits=rev)+\n  labs(caption=\"Datasource: USDA | DataViz: Federica Gazzelloni\")+\n  theme_void()+\n  theme(text = element_text(family=family,face=\"bold\"),\n        plot.caption=element_text(size=11,face=\"bold\"))\n\n\n# bees_fly_plot\n\n\nlibrary(cowplot)\n\nfinal <- ggdraw()+\n  draw_plot(bees_fly_plot,scale = 0.6,x=0.19,y=-0.13)+\n  draw_plot(bees_map,scale = 0.8,x=-0.1,y=0.1)+\n  draw_image(\"https://d3l4q0oih2c6yv.cloudfront.net/assets/esmis/cornell_seal_simple_b31b1b-54caf4668562db6b35fe259a44a4f9dc5db28a966230652ae2b175edcb9d56f0.svg\",\n             scale=0.1,x=0.45,y=0.43)+\n  draw_image(\"usda_logo.png\",\n             scale = 0.1, x=0.35,y=0.43)+\n  draw_image(\"bee_informed.png\",scale = 0.09,x=-0.37,y=-0.315)+\n  draw_image(\"bee_informed.png\",scale = 0.055,x=-0.37,y=-0.12)+\n  draw_label(\"The Stressors are the causes for bees colony loss\\n the (%) difference 2015-2020 shows some states are more affected then othes by\\n stressors.\",\n             x=0.38,y=0.07,fontfamily = family,size=11)+\n  draw_label(\"Low\",x=0.2,y=0.3,fontfamily = family)+\n  draw_label(\"High\",x=0.2,y=0.2,fontfamily = family)+\n  draw_label(\"Includes unknwon and parasites\",x=0.77,y=0.5,\n             fontfamily = family,size=11)+\n  draw_line(x=c(0.78,0.8),y=c(0.44,0.49),color=\"orange\")+\n  draw_label(\"Percentange of the stressor affecting the colonies\",x=0.8,y=0.2,fontfamily = family,size=10)+\n  draw_line(x=c(0.8,0.78),y=c(0.21,0.31),color=\"orange\")+\n  draw_label(\"The least contributing to bees loss\",x=0.85,y=0.66,\n             size=11,fontfamily = family)+\n  draw_line(x=c(0.89,0.9),y=c(0.56,0.65),color=\"orange\")+\n  draw_label(\"Leading parasite affecting \\nbees colony\\n named Varroa destructor\",x=0.38,y=0.2,size=11,fontfamily = family)+\n  draw_line(x=c(0.42,0.5),y=c(0.18,0.2),color=\"orange\")+\n  draw_image(\"bee_flying.png\",scale = 0.55,x=0.2,y=0.3)\n    \n    \n#final\n\n\nggsave(\n  paste0(\"bees_\", format(Sys.time(), \"%d%m%Y\"), \".png\"),\n   plot =final,\n  bg=\"white\",\n  dpi = 320,\n  width = 11,\n  height = 6\n)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w34_chips/w34_chips.html",
    "href": "tidytuesday/cases2022/posts2022/w34_chips/w34_chips.html",
    "title": "CHIP dataset",
    "section": "",
    "text": "# Load packages\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(showtext)\nshowtext_auto()\n\n# Add fonts from Google.\nfont_add_google(\"Roboto Mono\", \"Roboto Mono\")\nfont_add_google(\"Open Sans\", \"Open Sans\")\nfont_add_google(\"Special Elite\", \"Special Elite\")\n\n# Set ggplot theme\ntheme_set(theme_minimal(base_family = \"Roboto Mono\"))\ntheme_update(text=element_text(size=14),\n  plot.background = element_rect(fill = \"#fafaf5\", color = \"#fafaf5\"),\n  panel.background = element_rect(fill = NA, color = NA),\n  panel.border = element_rect(fill = NA, color = NA),\n  panel.grid.major.x = element_blank(),\n  panel.grid.minor = element_blank(),\n  axis.text.x = element_blank(),\n  axis.text.y = element_text(size = 10),\n  axis.ticks = element_blank(),\n  axis.title.y = element_text(size = 13, margin = margin(r = 10)),\n  legend.title = element_text(size = 9),\n  plot.caption = element_text(\n    family = \"Special Elite\",\n    size = 13,\n    color = \"grey60\",\n    face = \"bold\",\n    hjust = .5,\n    margin = margin(5, 0, 20, 0)\n  ),\n  plot.margin = margin(10, 25, 10, 25)\n)\n\n# Turn on showtext\nshowtext_auto()\n\nsetwd(\"~/Documents/R/R_general_resources/TidyTuesday/data/2022/w34_chips\")\ndata_raw <- read_csv(\"data_raw/chip_dataset.csv\")\n\nlibrary(slider)\n\ndata_raw_1 <- data_raw%>%\n  janitor::clean_names()%>%\n  mutate(release_date=as.Date(release_date,\"%Y-%m-%d\"),\n         year=lubridate::year(release_date),.after=release_date) %>%\n  filter(!is.na(year),\n         vendor%in%c(\"AMD\",\"Intel\")) %>%\n  select(release_date,year,type,vendor,product,transistors_million,freq_m_hz) %>%\n  group_by(year) %>%\n  mutate(transistors_million=ifelse(is.na(transistors_million),\n                                    mean(transistors_million,na.rm = T),\n                                    transistors_million)) %>%\n  ungroup() %>%\n  arrange(release_date)\n\n\nmean_transistors_million <- function(df) {\n  summarize(df, \n            date = min(release_date), \n            mean_transistors_million = mean(transistors_million), \n            n = n())\n}\n\n\ndata_cpu <- data_raw_1 %>%\n  filter(type==\"CPU\")\ndata_gpu <- data_raw_1 %>%\n  filter(type==\"GPU\")\n\n\nnew_cpu<- slide_period_dfr(data_cpu, \n                           data_cpu$release_date, \n                           .period=\"year\", \n                           .every = 3, \n                           mean_transistors_million) %>%\n  mutate(type=\"CPU\")\nnew_gpu<- slide_period_dfr(data_gpu, \n                           data_gpu$release_date, \n                           \"year\", \n                           .every = 2, \n                           mean_transistors_million) %>%\n  mutate(type=\"GPU\")\n\n\nnew_df <- rbind(new_cpu,new_gpu)\n\n\nlogo <- png::readPNG(\"logo.png\")\n\n\ntitle=\"Twenty years observation of CPU and GPU transistors\"\nsubtitle = \"Tendency to increase as stated by the Moore's law confirmed the number of transistors doubles about every two years.\nCPU is considered every 3 years while GPU every 2 years. Comparisons between vendors restrict to AMD and Intel.\"\n\n\n\np <- new_df %>%\n  mutate(year=lubridate::year(date),\n         type=ifelse(type==\"CPU\",\"CPU every 3 Years\",\"GPU every 2 Years\")) %>%\n  arrange(date) %>%\n  group_by(year) %>%\n  mutate(max= max(mean_transistors_million)) %>%\n  ggplot(aes(x = year, y = mean_transistors_million,\n             color=type)) +\n  geom_line(size = 1.5, alpha = 0.8)+\n  geom_point(aes(size=n)) +\n  scale_color_manual(\n  values = c(\"#486090\", \"#D7BFA6\"))+\n  labs(y=\"Average n.Transistors (in millions)\",\n       x=\"Year\",\n       color=\"Type\",\n       size=\"Frequency by product\",\n       title=title,\n       subtitle=subtitle,\n       caption=\"DataSource: #TidyTuesday 2022 week 34 Chips | DavaViz: Federica Gazzelloni (@fgazzelloni)\")+\n  theme(axis.text.x.bottom = element_text(),\n        plot.subtitle = element_text(),\n        plot.title = element_text(size = 25,face=\"bold\"))\n\n\nggdraw(p) +\ndraw_image(logo, x = -.35, y = -.25, scale = .12)\n\nggsave(\"w34_chips.png\",\nwidth = 15, height = 9, device = png)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w29_technology/w29_technology.html",
    "href": "tidytuesday/cases2022/posts2022/w29_technology/w29_technology.html",
    "title": "Technology Adoption",
    "section": "",
    "text": "Data contains information on the adoption of over 100 technologies in more than 150 countries since 1800. Described is technology usage primarily based on per capita measures and divide technologies into the two broad categories of production and consumption.\n\nlibrary(tidyverse)\nlibrary(knitr)\nknitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, \n                      comment = \"\",\n                      echo = TRUE, dpi = 300, cache.lazy = FALSE,\n                      tidy = \"styler\", fig.width = 8, fig.height = 5)\n\n\n# technology <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-19/technology.csv')\n\n\n# saveRDS(technology,\"technology.rds\")\ntechnology <- readRDS(\"technology.rds\")\n\ntechnology_df<-technology%>%select(-variable,-label)\n\ntechnology_df %>% count(group)\n\n\nlibrary(ggtext)\n\n\ntechnology_df %>%\n  filter(group%in%c(\"Consumption\",\"Production\")) %>%\n  filter(iso3c==\"ITA\") %>%\n  group_by(iso3c,year,group) %>%\n  summarize(Average=round(mean(value)),\n            Median=round(median(value)),.groups=\"drop\")%>%\n  ungroup() %>%\n  pivot_longer(cols = c(\"Average\",\"Median\"),names_to=\"metric\",values_to=\"values_metrics\") %>%\n  filter(values_metrics>0) %>% \n  ggplot(aes(x=factor(year), y= values_metrics)) +\n  geom_line(size=0.2,color=\"gray\")+\n  geom_line(aes(group=factor(group),\n                color=factor(group)),\n            size=0.8)+\n  geom_point(aes(color=factor(group)),shape=21,stroke=0.6,size=2)+\n  scale_y_log10(labels=scales::comma_format())+\n  scale_x_discrete(breaks=seq(1839,2020,10))+\n  ggthemes::scale_color_fivethirtyeight() +\n  ggthemes::theme_fivethirtyeight() +\n  labs(title=\"Cross-country Historical Adoption of Technology (CHAT)\",\n       subtitle=\"<span style='color:#0072B2;font-size:14pt'>Production vs Consuption</span><br><br>Data contains information on the adoption of over 100 technologies in more than 150 countries since 1800.<br>Described is technology usage primarily based on per capita measures and divide technologies into the two broad categories<br>of production and consumption. Evidences of average and median values differences explain distribution skewness and outliers.<br>The median is less affected by outliers and skewed data than the mean, and is usually the preferred measure of central tendency<br>when the distribution is not symmetrical.<br>Values are obtained grouping data by country, year and between production and consuption. \",\n       caption=\"DataSource: #TidyTuesday 2022 week29 | Technology Adoption |    data.nber.org   | www.cgdev.org\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       color=\"\")+\n  facet_wrap(~metric,scales=\"free_y\",nrow = 2) +\n  theme(plot.title = element_text(face = \"bold\",size=18),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_markdown(lineheight = 1),\n        axis.line.x = element_line(color=\"gray\",size=1),\n        axis.ticks.x = element_line(size=2))\n\n\nggsave(\"w29_technology.png\",\n       dpi=320,\n       width = 10,\n       height = 8)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w37_bigfoot/w37_bigfoot.html",
    "href": "tidytuesday/cases2022/posts2022/w37_bigfoot/w37_bigfoot.html",
    "title": "Bigfoot",
    "section": "",
    "text": "setwd(\"~/Documents/R/R_general_resources/TidyTuesday/data/2022/w37_bigfoot\")\nlibrary(tidyverse)\n# bigfoot colors: https://icolorpalette.com/color/bigfoot\n\n# load data\nbigfoot <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-13/bigfoot.csv')\ndf <- bigfoot%>%\n  select(county,\n         state,\n         latitude,\n         longitude,\n         date,\n         number,\n         precip_type,\n         visibility,\n         classification) %>%\n  filter(!is.na(latitude)) %>%\n  mutate(precip_type=ifelse(is.na(precip_type),\"unknown\",precip_type),\n         date=as.Date(date,\"%Y-%m-%d\")) %>%\n  mutate(year=lubridate::year(date),.after=\"date\",\n         visibility=ifelse(is.na(visibility),mean(visibility,na.rm = T),visibility)) %>%\n  filter(year>=1963) %>%\n  filter(longitude>-130) %>%\n  mutate(state=tolower(state),\n         classification=case_when(classification==\"Class A\"~\"clear sightings\",\n                                  classification==\"Class B\"~\"not clear view\",\n                                  classification==\"Class C\"~\"second-hand reports\")) %>%\n  rename(ID=state)\ndf%>%names\n\n\n\nlabels <- df%>%\n  group_by(ID) %>%\n  mutate(pct_view=number/sum(number)*100,.after=number)%>%\n  mutate(cent_long=mean(range(longitude)),cent_lat=mean(range(latitude)),.after=longitude)%>%\n  ungroup() %>%\n  count(ID,cent_long,cent_lat,pct_view)%>%\n  group_by(ID) %>%\n  summarize(avg_pct_view=round(mean(pct_view),2),cent_long,cent_lat,.groups=\"drop\")%>%\n  ungroup() %>%\n  distinct()\n\nlabels\n\n\nstates <- map_data(\"state\")\nworld <- map_data(\"world\") %>%\n  # set a restricted view to long = c(-122,-66) and lat = c(25,50)\n  filter(long> -125,long< -66,\n         lat> 25, lat< 60)\n\n# load BigFoot fonts\n# library(systemfonts)\n# fonts <- system_fonts()\n# fonts%>%\n#  arrange(family)%>%\n#  filter(str_detect(family,\"Big\"))%>%select(family)\n\n\nlibrary(randomcoloR)\nn <- 48\npalette <- distinctColorPalette(n)\n\nset.seed(1)\np <- ggplot() +\n  geom_polygon(data = world, mapping = aes(long, lat,\n                                           group=group),\n               fill=\"#f4d6b5\",color=\"#446471\",\n               size=0.2) +\n  geom_polygon(data = states, mapping = aes(long, lat,\n                                            group=group),\n               fill=\"#ebe2df\",color=\"#446471\",\n               size=0.2) +\n  geom_point(df, mapping = aes(x=longitude,y=latitude,\n                               color=ID),\n             alpha=0.3,\n             size=0.5,show.legend = F) +\n  ggrepel::geom_label_repel(labels, \n            mapping = aes(x=cent_long,y=cent_lat,\n                          label=avg_pct_view),\n            label.padding = unit(0.05,\"pt\"),\n            color=\"#1a2f38\",\n            family=\"Monaco\",\n            size=3,\n            max.overlaps = Inf,\n            label.size = unit(0.05,\"pt\"), \n            fill = \"grey90\"\n            )+\n  coord_map() +\n  scale_color_manual(values = palette) +\n  ggthemes::theme_map() +\n  labs(title=\"Bigfoot\",\n       subtitle = \"Avg(%) views by county from 1963\",\n       color=\"\",\n       caption=\"\\nDataSource: #TidyTuesday2022 week37 BigFoot\\nDataViz: Federica Gazzelloni\\n\") +\n  theme_void()+\n  theme(text=element_text(family=\"Monaco\",color=\"grey30\"),\n        plot.title = element_text(size=55,hjust=0.1,vjust=0.5,\n                                  family=\"Big Bloke BB\"),\n        plot.subtitle = element_text(size=9,hjust=0.1),\n        plot.caption = element_text(vjust = 0.5,hjust=0),\n        plot.title.position = \"plot\",\n        legend.key.size = unit(1,units = \"pt\"),\n        legend.background = element_rect(fill=\"white\"),\n        legend.key = element_blank(),\n        legend.box.background = element_blank(),\n        legend.direction = \"horizontal\",\n        legend.position = c(0.3,0.05),\n        plot.background = element_rect(fill=\"#fff0c6\",\n                                       color=\"#fff0c6\"))\n  \nlibrary(cowplot)\nggdraw(p)+\n  draw_image(\"bigfoot.png\",scale=0.2,\n             y=0.144,x=-0.15) +\n  draw_image(\"bigfoot.png\",scale=0.15,\n             y=0.12,x=0)+\n  draw_image(\"bigfoot.png\",scale=0.1,\n             y=0.08,x=0.1)\n\n\n\nggsave(\"w37_bigfoot.png\",\n       bg=\"#fff0c6\",\n       dpi=320,\n       width = 5.81,\n       height = 6)\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w16_crosswords/w16_crossword.html",
    "href": "tidytuesday/cases2022/posts2022/w16_crosswords/w16_crossword.html",
    "title": "Crossword Puzzles and Clues",
    "section": "",
    "text": "library(tidyverse)\n\n\nbig_dave <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-19/big_dave.csv')\ntimes <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-19/times.csv')\n\n\nbig_dave%>%glimpse\nbig_dave%>%arrange(-rowid)%>%head\n\n\nbig_dave1 <- big_dave%>% # DataExplorer::profile_missing()\n  select(answer,puzzle_date,puzzle_name) %>%\n  filter(!is.na(answer)) %>%\n  mutate(puzzle_bigdave=gsub(\"[[:punct:][:blank:]]\\\\d*\",\"\",puzzle_name))\n\n\nbig_dave1%>%count(answer)\n\n\ntimes%>%glimpse\ntimes%>%head\n\n\ntimes1 <- times%>%\n  select(answer,puzzle_date,puzzle_name) %>% #DataExplorer::profile_missing()\n  filter(!is.na(answer))%>%\n  mutate(puzzle_times=gsub(\"[[:punct:][:blank:]]\\\\d*\",\"\",puzzle_name))\n\n\ntimes1 %>%count(answer)\n\n\ndf <- big_dave1 %>%\n  inner_join(times1,by=c(\"answer\",\"puzzle_date\")) %>%\n  arrange(puzzle_date) %>% # \n  mutate(answer=as.factor(answer)) %>% #DataExplorer::profile_missing()\n  select(-puzzle_name.x,-puzzle_name.y) %>%\n  mutate(year=lubridate::year(puzzle_date),.after=answer,\n         year=as.integer(year))\n \ndf \n\n\ndf%>%\n  ggplot(aes(x=year,y=puzzle_bigdave))+\n  geom_col()\n\n\nlibrary(gganimate)\ncolors<- colorRampPalette(RColorBrewer::brewer.pal(12, \"Paired\"))(161)\nlibrary(extrafont)\nloadfonts()\n\n\nlibrary(showtext)\n# \nfont_add_google(\"Gentium Book Basic\",\"gbb\")\nfont_add_google(\"Nanum Gothic\",\"ng\")\nshowtext_auto()\n\n\np <- df %>%\n    pivot_longer(cols=c(\"puzzle_bigdave\",\"puzzle_times\"),\n               names_to=\"names\",values_to=\"values\")%>%\n  #count(year)\n  ggplot(aes(puzzle_date, fct_reorder(values,puzzle_date), color = values)) +\n  geom_jitter(show.legend = F,shape=\".\",color=\"white\")+\n  geom_text(aes(label=answer),\n            size=9,\n            check_overlap = T,family=\"gbb\")+\n  scale_color_manual(values=colors)+\n  labs(title = \"\\nSame Answers! Year: {closest_state}\\nBigDave & Times puzzles\\n\",  \n       subtitle=\"\\nwords are randomized\",\n       caption=\"#30DayChartChallenge 2022 #Day22\\n DataSource: #TidyTuesday week16 - Crossword \\n DataViz: Federica Gazzelloni\\n\\n\")+\n  theme_void() +\n  theme(text = element_text(family = \"ng\", face=\"bold\",color=\"#F0F8FF\"),\n        plot.title = element_text(size=28),\n        plot.subtitle = element_text(size=18),\n        plot.caption = element_text(size=14,vjust=2,hjust=0.5),\n        plot.background = element_rect(fill=\"grey10\",color=\"grey20\"),\n        panel.background = element_rect(fill=\"grey10\",color=\"grey20\"),\n    legend.position = \"none\")+\n   coord_polar(theta = \"x\") +\n  transition_states(year, \n                    transition_length = 2,\n                    state_length = 1,\n                    wrap = F) +\n  shadow_wake(wake_length = 0.5,wrap=F)\n\n\nanim_save(animate(p,res=100,\n                  renderer = gifski_renderer(\"animation3.gif\"),\n                  height = 710, width = 610))\n\n\ndf %>%\n  pivot_longer(cols=c(\"puzzle_bigdave\",\"puzzle_times\"),\n               names_to=\"names\",values_to=\"values\")%>%\nggplot(aes(year, fct_reorder(values,year), fill = values)) +\n  geom_col() +\n  scale_fill_viridis_d() +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n    panel.grid = element_blank(),\n    panel.grid.major.y = element_line(color = \"white\"),\n    panel.ontop = TRUE\n  )+\n  coord_polar()+\n  facet_wrap(vars(names))+\n  transition_states(year, wrap = FALSE) +\n  shadow_mark()+\n  enter_grow() +\n  enter_fade()\n\n\ndf%>%\n  group_by(puzzle_times)%>%\n  count(year,sort=T)\n\n\nbd_id <- df%>%\n  arrange(puzzle_date)%>%\n  count(puzzle_bigdave)%>%\n  mutate(bd_id=row_number())#%>%\n  #select(-n)\n\ntm_id <- df%>%\n  arrange(puzzle_date)%>%\n  count(puzzle_times)%>%\n  mutate(tm_id=row_number())#%>%\n  #select(-n)\n\ndf1 <- df %>%\n  left_join(bd_id,by=c(\"puzzle_bigdave\"))%>%\n  left_join(tm_id,by=\"puzzle_times\")\ndf1\n\n\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(patchwork)\nlibrary(hrbrthemes)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(colormap)\n\n\nlinks <-df1%>%\n  mutate(label=paste0(puzzle_bigdave,\"-\",puzzle_times))%>%\n  rename(source=bd_id,target=tm_id)\n\n\nlibrary(ggbump)\n\n\nggplot(links,aes(x=source-2,xend=source+5 ,y=target,yend=target+5,\n                 group=label)) +\n  ggbump::geom_sigmoid(aes(color=puzzle_bigdave),show.legend = F)+\n  geom_text(aes(x=source-2,label=puzzle_bigdave),size=3,\n            vjust=\"bottom\",hjust=\"right\",check_overlap = T,show.legend = F)+\n  geom_text(aes(x=source+5,y=target+5,label=puzzle_times),size=3,\n            vjust=\"bottom\",hjust=\"left\",check_overlap = T,show.legend = F)+\n  geom_text(aes(label=answer,color=answer),size=3,\n            vjust=\"bottom\",hjust=\"left\",check_overlap = T,show.legend = F)\n    coord_flip()\n\n\nlot(df, aes(x=year, y= fct_reorder(puzzle_bigdave,year)))+\n  geom_col()+\n  #scale_x_continuous(breaks=seq(2014,2021,1))\n  labs(title=\"Big Dave\")\n\nggplot(df, aes(x=puzzle_date, y= puzzle_times))+\n  geom_col()+\n  labs(title=\"Times\")"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w41_yarn/w41_yarn.html",
    "href": "tidytuesday/cases2022/posts2022/w41_yarn/w41_yarn.html",
    "title": "Ravelry data",
    "section": "",
    "text": "# load the libraries\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(RColorBrewer)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\n\n# set the fonts\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name=\"Pangolin\",family=\"pangolin\")\n\n# read the data\nyarn <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-11/yarn.csv')\n\n# tidy textures\ndf <- yarn%>%\n  mutate(texture_clean=case_when(str_detect(texture_clean,\"merino\")~\"merino\",\n                                 str_detect(texture_clean,\"ply|plied|play|plies\")~\"ply\",\n                                 str_detect(texture_clean,\"acrylique|acrylic|polyacryl|acrilyc|acryt\")~\"acrylic\",#TRUE~texture_clean))%>%count(texture_clean)%>%filter(str_detect(texture_clean,\"acr|ply\"))\n                                 str_detect(texture_clean,\"nylon\")~\"nylon\",\n                                 str_detect(texture_clean,\"cotton\")~\"cotton\",\n                                 str_detect(texture_clean,\"wool\")~\"wool\",\n                                 str_detect(texture_clean,\"polyamide|polyamid\")~\"polyamid\",\n                                 str_detect(texture_clean,\"angora\")~\"angora\",\n                                 str_detect(texture_clean,\"cashmere\")~\"cashmere\",\n                                 str_detect(texture_clean,\"aran\")~\"aran\",\n                                 str_detect(texture_clean,\"silk\")~\"silk\",\n                                 str_detect(texture_clean,\"jersey\")~\"jersey\",\n                                 TRUE~texture_clean))%>%#count(texture_clean)\n  filter(str_detect(texture_clean,\n                    c(\"merino|ply|acrylic|nylon|cotton|wool|angora|cashmere|aran|silk|jersey\")))%>%\n  count(texture_clean,yarn_weight_name,yardage,grams) %>%\n  mutate(yarn_weight_name=case_when(yarn_weight_name==\"Aran / Worsted\"~\"Aran\",\n                                    yarn_weight_name==\"DK / Sport\"~\"DK\",\n                                    yarn_weight_name==\"Light Fingering\"~\"Fingering\",\n                                    yarn_weight_name==\"Super Bulky\"~\"Bulky\",\n                                    TRUE~yarn_weight_name))%>%\n  filter(!yarn_weight_name==\"No weight specified\",!is.na(yarn_weight_name))%>%\n  filter(!is.na(yardage),!is.na(grams))%>%\n  select(-n)%>%\n  group_by(yarn_weight_name,texture_clean)%>%\n  summarise_all(.funs=mean)%>%\n  select(yarn_weight_name,texture_clean,yardage)\n\n\n# build the data ready for the graph\nd1<- df%>%\n  mutate(from=\"YARN\")%>%\n  relocate(from)%>%\n  rename(to=yarn_weight_name)%>%\n  select(-texture_clean,-yardage)%>%distinct()\nd2 <- df%>%\n  rename(from=yarn_weight_name, \n         to=texture_clean)%>%\n  select(-yardage)%>%distinct()\n\nhierarchy <- rbind(d1, d2)\nvertices <- data.frame(name = unique(c(as.character(hierarchy$from), \n                                       as.character(hierarchy$to))) ) \n\n\n# make the graph_from_data_frame\nmygraph <- graph_from_data_frame(hierarchy, vertices=vertices )\n\n# see the elements of the graph\ndf1 <- create_layout(mygraph, layout = 'dendrogram')\n\n\n# make a function for node angle adj\n# node_angle(df1$x,df1$y,degrees = T)\nnode_ang_adj <- function(x,y) {\n  ifelse(node_angle(x,y) > 90 & node_angle(x,y) < 270 , \n         node_angle(x,y) + 180, node_angle(x,y))\n  }\n\n# make a function for hjust\nnode_hjust_adj <- function(x,y) {\n  ifelse(node_angle(x,y) > 90 & node_angle(x,y) < 270 , 1,0)\n}\n\n# make the graph\nggraph(mygraph, layout = 'dendrogram', circular = TRUE) + \n  geom_edge_diagonal(aes(color=factor(x)),\n                     alpha=0.9,\n                     show.legend = F) +\n  geom_node_point(aes(color=factor(x)),\n                  size=10,\n                  show.legend = F)+\n  geom_node_point(aes(color=factor(x)),\n                  size=10,\n                  shape=8,\n                  show.legend = F)+\n  geom_node_label(aes(filter=!leaf,label=name,color=factor(x)),\n                  label.padding = unit(0.1, \"lines\"),\n                  label.r = unit(0.1, \"lines\"),\n                  label.size = 0.1,\n                  family = \"pangolin\",\n                  fontface=\"bold\",\n                  show.legend = F,\n                  size=4, \n                  alpha=1)+\n  geom_node_text(aes(x = x*1.1, \n                     y=y*1.1, \n                     hjust = node_hjust_adj(x,y),\n                     angle=node_ang_adj(x,y),\n                     filter = leaf, \n                     label=name,\n                     color=factor(x)),\n                 family = \"pangolin\",\n                 fontface=\"bold\",\n                 show.legend = F,\n                 size=4, \n                 alpha=1)+\n  scale_color_manual(values = rep(RColorBrewer::brewer.pal(10,\"Paired\"),10))+\n  scale_x_discrete(expand = c(0,0.3))+\n  scale_y_discrete(expand = c(0,0.3))+\n  coord_fixed()+\n  labs(caption=\"What's inside your YARN?\\ntextures for each type\\n\\nDataSource: #TidyTuesday 2022 week41 Ravelry data\\nDataViz: Federica Gazzelloni (FG) Twitter: @fgazzelloni\\n\",\n       alt=\"Infographics\") +\n  theme_graph()+\n  theme(plot.margin = margin(5,5,5,5,unit = \"pt\"),\n        plot.caption = element_text(face=\"bold\",family=\"pangolin\"))\n\n\n\n#  ggsave(\"w41_yarn.png\",\n#        dpi=280,\n#        bg=\"white\",\n#        width = 9,height = 9)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w27_rentals/w27_rentals.html",
    "href": "tidytuesday/cases2022/posts2022/w27_rentals/w27_rentals.html",
    "title": "San Francisco Rentals",
    "section": "",
    "text": "library(tidyverse)\nrent<-readRDS(\"rent.rds\")\nrent\n\n\nmax<-rent%>%\n  mutate(city=str_to_title(city))%>%\n  filter(year>2000)%>%\n  group_by(year,city)%>%\n  mutate(avg=median(price))%>%\n  ungroup()%>%\n  count(year,city,avg) %>%\n    arrange(year,-avg) %>%\n  slice_max(order_by=c(avg),n=10) %>%\n  count(city) %>%\n  select(-n) %>%\n  unlist()\n\nmax\n\n\navg_df<- rent%>%\n  mutate(city=str_to_title(city))%>%\n  filter(year>2000)%>%\n  group_by(year,city)%>%\n  mutate(avg=median(price))%>%\n  ungroup() %>%\n  count(year,city,avg) %>%\n  mutate(pct=round(n/sum(n)*100,2)) %>%\n  arrange(year,-avg)\n\n\navg_group<-avg_df%>%\n  filter(!city%in%max) %>%\n  group_by(year)%>%\n  summarise(avg_group=median(avg)) %>%\n  ungroup()\n\n\nsummary(avg_df$avg)\n\n\ntext prices\n\ntext_max<-rent%>%\n  mutate(city=str_to_title(city))%>%\n  filter(year>2000)%>%\n  group_by(year,city)%>%\n  mutate(avg=median(price))%>%\n  ungroup()%>%\n  count(year,city,avg) %>%\n    arrange(year,-avg) %>%\n  slice_max(order_by=c(avg),n=5) %>%\n  mutate(avg_comma=formatC(avg, format=\"d\", big.mark=\",\"))%>%\n  mutate(avg_text=paste0(\"$\",avg_comma,\" \",city))\n\ntext_max\n\n\n main<- avg_df %>%\n    ggplot(aes(x=factor(year),y=avg,group=factor(city),color=city))+\n    geom_line(size=0.2,show.legend = F,color=\"grey80\",alpha=0.2) +\n    geom_line(data= subset(avg_df, city%in%max),\n              inherit.aes = T,key_glyph = \"timeseries\")+\n    geom_line(data=avg_group,\n            aes(x=factor(year),y=avg_group,group=1),\n              inherit.aes = F,size=1)+\n  geom_text(data= text_max, aes(x=factor(year),y=avg,label=avg_text),\n            inherit.aes = F,family=\"Roboto Condensed\",face=\"bold\",\n            vjust=1,hjust=1)+\n  scale_color_viridis_d()+\n  guides(color=guide_legend(nrow = 2))+\n  scale_x_discrete(expand = c(0,0.09),breaks=seq(2000,2018,2))+\n  scale_y_log10(expand = c(0,0),breaks=5)+\n  labs(title=\"San Francisco Bay Area Craigslist rental prices\",\n       subtitle=\"top 10 high-rent cities & expected global trend (2001-2018)\",\n       caption=\"DataSource: #TidyTuesday2022 week27 San Francisco Rentals on Craigslist\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       color=\"City\",\n       x=\"Year\",y=\"Median values - log transf ($525 to $11,140)\")+\n    ggdark::dark_theme_classic()+\n  theme(text=element_text(family=\"Roboto Condensed\",color=\"grey90\"),\n        axis.text = element_text(20),\n        legend.position = c(0.75,-0.1),\n        legend.background = element_blank(),\n        legend.text = element_text(size=6),\n        legend.margin = margin(5,5,5,5,\"pt\"),\n        legend.direction = \"horizontal\",\n        panel.grid.major.x = element_line(size=0.2),\n        plot.margin = margin(10,10,10,10,\"pt\"),\n        plot.title = element_text(size=22),\n        plot.caption = element_text(hjust=0),\n        axis.line.y = element_line(size=0.2),\n        axis.line.x = element_line(size=1),\n        axis.ticks = element_line(size=2))\nmain\n\n\nlibrary(showtext)\nshowtext.auto()\nshowtext.opts(dpi=320)\nlibrary(extrafont)\n#loadfonts()\n\n\ninsect<-rent%>%\n  group_by(year)%>%\n  summarize(avg=median(price))%>%\n  ungroup()%>%\n  ggplot(aes(x=factor(year),y=avg,group=1))+\n  geom_point()+\n  geom_line()+\n  scale_x_discrete(expand = c(0,0.09),breaks=seq(2000,2018,4))+\n  labs(title=\"Global SFB rental prices from 2000 to 2018\",\n       subtitle=\"Median values\",\n        x=\"\",y=\"\")+\n   ggdark::dark_theme_classic()+\n  theme(text=element_text(family=\"Roboto Condensed\",color=\"grey90\",size = 18),\n        panel.grid.major.x = element_line(size=0.2),\n        axis.text = element_text(size=20),\n        plot.title = element_text(size=25),\n        plot.title.position = \"plot\",\n        plot.margin = margin(10,10,10,10,\"pt\"),\n        plot.caption = element_text(hjust=0),\n        axis.line.y = element_line(size=0.2),\n        axis.line.x = element_line(size=1),\n        axis.ticks = element_line(size=2))\ninsect\n\n\nggsave(\"insect.png\",\n       dpi=300,\n       width = 8,\n       height = 6)\n\n\nlibrary(cowplot)\n\nggdraw(main)+\n  draw_image(\"insect.png\",scale=0.25,\n             x=-0.35,y=0.25)\n\n\nggsave(\"w27_rentals.png\",\n       dpi=320,\n       width = 9,\n       height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w8_wfi/w8_wfi.html",
    "href": "tidytuesday/cases2022/posts2022/w8_wfi/w8_wfi.html",
    "title": "World Freedom index",
    "section": "",
    "text": "library(tidyverse)\nfreedom <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-22/freedom.csv')\nhead(freedom);names(freedom)\n\n\nfreedom1 <- freedom %>% \n  mutate(country=case_when(country==\"Bolivia (Plurinational State of)\"~\"Bolivia\",\n                           country==\"CÃƒÂ´te dÃ¢â‚¬â„¢Ivoire\"~\"Ivory Coast\",\n                           country==\"United Kingdom of Great Britain and Northern Ireland\"~\"United Kingdom\",\n                           country==\"Congo\"~\"Republic of Congo\",\n                           country==\"Russian Federation\"~\"Russia\",\n                           country==\"Brunei Darussalam\"~\"Brunei\",\n                           country==\"Venezuela (Bolivarian Republic of)\"~\"Venezuela\",\n                           country==\"Lao People's Democratic Republic\"~\"Laos\",\n                           country==\"Viet Nam\"~\"Vietnam\",\n                           country==\"Bahamas\"~\"The Bahamas\",\n                           country==\"Guinea-Bissau\"~\"Guinea Bissau\",\n                           country==\"Serbia\"~\"Republic of Serbia\",\n                           country==\"North Macedonia\"~\"Macedonia\",\n                           country==\"Czechia\"~\"Czech Republic\",\n                           country==\"Timor-Leste\"~\"East Timor\",\n                           country==\"Syrian Arab Republic\"~\"Syria\",\n                           country==\"Iran (Islamic Republic of)\"~\"Iran\",\n                           country==\"Republic of Moldova\"~\"Moldova\",\n                           country==\"Democratic People's Republic of Korea\"~\"North Korea\",\n                           country==\"Republic of Korea\"~\"South Korea\",\n                           TRUE ~ country))\n\n\nworld <- rnaturalearth::ne_countries(type=\"countries\")\n\n\nw_countries <- world%>%\n  as.data.frame()%>%\n  count(sovereignt)%>%\n  select(-n)%>%\n  unlist()\n\nmy_countries <- freedom1%>%\n  count(country)%>%\n  select(-n)%>%\n  unlist()\n\n\nsetdiff(w_countries,my_countries)\n\n\nlibrary(rnaturalearth)\nlibrary(sf)\nworld1 <- ne_countries(scale=110,type=\"countries\",\n            returnclass=\"sf\")\n\nworld12 <- world1%>%\n  as.data.frame()%>%\n  select(country=sovereignt,geometry)%>%\n  filter(!country==\"Antarctica\")\n\nfreedom12 <- freedom1%>%\n  left_join(world12,by=\"country\")\n\n\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\nsysfonts::font_families_google()\nsysfonts::font_add_google(\"Junge\",\"Junge\")\n\n\nlast_plot <- ggplot()+\n  geom_sf(data = world12,mapping=aes(geometry=geometry),size=0.05)+\n  geom_sf(data=freedom12,mapping=aes(geometry=geometry,fill=factor(Status)),size=0.1)+\n  scale_fill_viridis_d(labels=c(\"Free\",\"Not Free\",\"Partially Free\")) +\n  labs(fill=\"Status\",title=\"Freedom in the World 1995-2020\",\n       caption=\"Freedom House and the United Nations by way of Arthur Cheib | Viz: Federica Gazzelloni\\n #TidyTuesday 2022/08\")+\n  coord_sf()+\n  facet_wrap(vars(year))+\n  ggthemes::theme_map()+\n  theme(text = element_text(family=\"Junge\"),\n        plot.title.position = \"panel\",\n        plot.title = element_text(size=14),\n        plot.caption = element_text(size=4),\n        plot.background = element_rect(fill=\"beige\",color=\"beige\"),\n        panel.background = element_rect(fill=\"beige\",color=\"beige\"),\n        legend.position = c(0.05,-0.1),\n        legend.direction = \"horizontal\",\n        legend.box.background = element_rect(fill=\"beige\",color=\"beige\"),\n        legend.background = element_rect(fill=\"beige\",color=\"beige\"),\n        legend.key.size = unit(0.2, 'cm'), #change legend key size\n        legend.key.height = unit(0.2, 'cm'), #change legend key height\n        legend.key.width = unit(0.2, 'cm'), #change legend key width\n        legend.title = element_text(size=4), #change legend title font size\n        legend.text = element_text(size=4),\n        strip.background = element_blank(),\n        strip.text = element_text(size=4))\n\n\nlibrary(cowplot)\nggdraw()+\n  draw_plot(last_plot)+\n  draw_label(\"Political rights and civil liberties around the world deteriorated to their\\n lowest point in more than a decade in 2017, extending a period characterized by emboldened\\n autocrats, beleaguered democracies, and the United States’ withdrawal from its leadership\\n role in the global struggle for human freedom. #FreedomHouse\",\n             x=0.66,y=0.225,fontfamily=\"Junge\",size=4)\n\n\nggsave(\"freedom.png\",limitsize = FALSE,\n       height = 1000,  width = 1350, \n       units = \"px\", dpi = 320)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w23_pride/w23_pride.html",
    "href": "tidytuesday/cases2022/posts2022/w23_pride/w23_pride.html",
    "title": "Pride Corporate Accountability Project",
    "section": "",
    "text": "library(tidyverse)\n\n\n\n\n# pride_aggregates <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/pride_aggregates.csv')\nfortune_aggregates <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/fortune_aggregates.csv')\n#static_list <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/static_list.csv')\n#pride_sponsors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/pride_sponsors.csv')\n#corp_by_politicians <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/corp_by_politicians.csv')\n#donors <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-07/donors.csv')\n\n\nfortune_aggregates %>% names\n\n\nnames(fortune_aggregates)<-c(\"company\",\"tot_contr\",\"n_politicians\",\"n_states\")\n\n\nfortune_aggregates%>%head\n\n\nlibrary(extrafont)\n# loadfonts()\n\n\nlibrary(ggtext)\nid=c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\")\nplot <- fortune_aggregates%>%\n  arrange(-tot_contr) %>%\n  filter(!company==\"Grand Total\" # tot_contr>=50000\n         ) %>%\n  slice_max(tot_contr,n=7)%>%\n  mutate(company=reorder(as.factor(company),tot_contr))  %>%\n  ggplot(aes(x=company, y=tot_contr)) +\n  geomtextpath::geom_textsegment(aes(xend=company,y=1,yend=tot_contr,\n                                     label=company),\n                                 family=\"Public Sans Medium\",\n                                 textcolour=rainbow(7),\n                                 size=7,linewidth=7,\n                                 lineend = \"butt\",linecolour=rainbow(7)) +\n  geom_point( color=rainbow(7), size=7) +\n  geom_point( color=rainbow(7), size=12,shape=21,stroke=2) +\n  geom_point(shape=id,color=\"black\", size=7) +\n  coord_flip()+\n  labs(title=\"Top 7 <span style='color:gold'>Anti-LGBTQ</span>\",\n       subtitle=\"contributors by Fortune500\",\n       caption=\"Viz:@fgazzelloni | DataSource: #TidyTuesday 2022 week23 -<span style='color:#4b2d8f'>Data for Progress’ Pride Corporate Accountability</span>\")+\n  xlab(\"\") +\n  ylab(\"\")+\n  theme_light() +\n  theme(text = element_text(color=\"grey80\",size=25,family=\"Public Sans Medium\"),\n        plot.title = element_markdown(size=45),\n        plot.caption = element_markdown(size=12,hjust=0),\n        plot.subtitle = element_text(hjust=0),\n    panel.grid.major.x = element_blank(),\n    panel.border = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title = element_blank(),\n    panel.grid = element_blank(),\n    plot.background = element_rect(fill=\"black\",color=\"black\"),\n    panel.background = element_rect(fill=\"black\",color=\"black\")\n  ) \n\n\nlibrary(cowplot)\n\nggdraw()+\n  draw_plot(plot)+\n  draw_label(\"Data for Progress\",\n             x=0.7,\n             y=0.35,\n             size=60,\n             alpha = 0.2,\n             fontfamily = \"Public Sans Medium\",\n             color = \"white\")+\n  draw_label(\"F500\",\n             x=0.5,\n             y=0.45,\n             size=350,\n             alpha = 0.2,\n             fontfamily = \"Public Sans Medium\",\n             color = \"white\")+\n    draw_label(\"Data for Progress has compiled a set of resources for\\nactivists, employees, community leaders, and lawmakers\\nto push back on these policies and the prejudice powering them.\",\n             x=0.7,\n             y=0.25,\n             size=15,\n             fontfamily = \"Public Sans Medium\",\n             color = \"grey90\")\n  \n\nggsave(\"w23_pride.png\",\n       dpi=320,\n       width = 12,\n       height = 7)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w17_hidden_gems/w17_hiddengems.html",
    "href": "tidytuesday/cases2022/posts2022/w17_hidden_gems/w17_hiddengems.html",
    "title": "Kaggle Hidden Gems",
    "section": "",
    "text": "library(tidyverse)\n\n\nhidden_gems <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-26/hidden_gems.csv')\n\n\ndf <- hidden_gems%>%\n  count(vol,date,title,review,author_kaggle,author_name)\n\n\ndf1 <- df %>%  #pull(date)%>%summary\n  mutate(ym=zoo::as.yearmon(date),\n         year=lubridate::year(date))%>%\n  unnest_tokens(word,review) %>%\n  anti_join(get_stopwords()) %>%\n  filter(!str_detect(word,\"kaggle|c|https|2020|2021|also|end|r\")) %>%\n  count(author_name,word,sort=T) %>%\n\n inner_join(bing) %>%\n  mutate(sentiment2=sentiment)%>%\n  spread(sentiment, n, fill = 0) %>%\n  mutate(sentiment = positive - negative) %>%\n  mutate(index=row_number())%>%\n  relocate(index) %>% #count(word,sort=T)\n  mutate(word=reorder(word,-index)) \n\n\nmy_words<-df1 %>%\n  count(word,sort=T)%>%\n  filter(n>1) %>%\n  select(-n) %>%\n  unlist()\n  \n  \ndf2 <- df1 %>%\n   filter(word %in% my_words) \n\nNotches are used to compare groups; if the notches of two boxes do not overlap, this suggests that the medians are significantly different.\n\ndf2 %>%\n  mutate(word=toupper(word))%>%\n  mutate(word=as.factor(word),\n         word=reorder(word,-index))%>% #count(index,sort=T)\n  ggplot(aes(x=index,y=fct_reorder(word,sentiment),fill=sentiment2))+ # \n  geom_boxplot(size=0.5,\n               outlier.size = 0.3,outlier.shape = 21,\n               notch = T) +\n  geom_jitter(size=0.3,shape=21,stroke=0.5)+\n  coord_cartesian(xlim = c(-1,260),ylim=c(0,35),clip=\"off\")+\n  labs(title=\"How vary are words in the Hidden Gems Reviews?\",\n       subtitle=\"Some words repeated themselves more frequently than others,\\nwith significantly different medians.\",\n       caption=\"#30DayChartChallenge 2022 #Day28 - Deviations\\nDataSource: #TidyTuesday Week17 - Hidden Gems\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       x=\"\",y=\"\",fill=\"Sentiment\")+\n  tvthemes::scale_fill_rickAndMorty()+\n  tvthemes::theme_rickAndMorty()+\n  theme(plot.background = element_rect(fill=\"grey80\"),\n        legend.background = element_rect(fill=NA),\n        legend.position = c(0.9,0.9),\n        plot.title = element_text(face=\"bold\",size=22),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_text(size=12),\n        axis.text.x = element_blank())+\n  annotate(\"text\",x=-70,y=-2.5,label=\"How to read this graph:\\n- the notches represent the median of the frequency of words\\nfound in the Hidden Gems reviews by Author\\n- the sidebars represent their deviations\",\n           hjust=0,size=3)\n\n\nggsave(\"day28_deviations.png\",\n       dpi=320,\n       width = 8,\n       height = 10)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w4_board_games/w4_board_games.html",
    "href": "tidytuesday/cases2022/posts2022/w4_board_games/w4_board_games.html",
    "title": "Board games",
    "section": "",
    "text": "I’ve chosen this graphic for my blog because it turned out to be very interesting. As you can see reading through the article, the shape of the network changes along with the change of the parameters.\nThe dataset I’ve used for making this network comes from #TidyTuesday 2022 week 4 Board games.\nThe picture below is the result of the network visualization.\n\nThe first step is to load the library needed for making the manupulations. I usually load {tidyverse} package because it contains a series of sub packages and functions that are all that is neede for thsi first part of the data wrangling. Also, it provides the pipe %>% operator, which is useful for linking different functions through subsetting the dataset.\n\nlibrary(tidyverse)\n\nThe data sets provided can be loaded from the source like this:\n\nratings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/ratings.csv')\ndetails <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/details.csv')\n\nI’ve also added few line of code for backing the original datasets by saving them as .RDS files, a light file format to store information in.\n\nsaveRDS(ratings,\"ratings.rds\")\nsaveRDS(details,\"details.rds\")\n\nAnd assigned them to new variables:\n\nrat <- readRDS(\"ratings.rds\")\ndet <- readRDS(\"details.rds\")\n\n\n\n\n\nLet’s see the variable’s names inside the sets.\n\n\nnames(rat)\n\n\nnames(det)\n\n\nBased on the variables in the data sets, I’ve started googling for some information nad/or visualizations about Board games, to see if I could find any inspiration from past submissions, and in fact found this source of inspiration: https://www.thewayir.com/blog/boardgames/. Looking through the article found the code and the type of visualization I had in mind, so started replicating the code from the article. My surprise was that data updating and my manipulation slightly changed the output of the plot.\nLet’s go a bit more in deep about that. I’ll go through the steps for replicatiing the network but then sligtly change the output to what you can see in the picture.\nAmong the required libraries found {widyr} package which was very new to me.\n\nEncapsulates the pattern of untidying data into a wide matrix, performing some processing, then turning it back into a tidy form. This is useful for several operations such as co-occurrence counts, correlations, or clustering that are mathematically convenient.\n\nAnd then the other packages such as {igraph}, {ggraph}, and {ggforce}, all packages for making networks of data, and for making extra features.\n\nrequire(widyr)\nrequire(igraph)\nrequire(ggraph)\nrequire(ggforce)\n\n\n\n\n\n\n\nWhat’s the best manipulation for making a graph?\n\nHere is the first part of the data-wrangling\n\nboard_games <- rat %>%\n  select(id,name) %>%\n  left_join(select(det,id,boardgamemechanic),by=\"id\") %>%\n  rename(mechanic=boardgamemechanic) %>%\n  tidyr::separate_rows(mechanic, sep = \",\") %>% \n  mutate(mechanic = str_remove_all(mechanic, \"[[:punct:]]\"),\n         mechanic = str_trim(mechanic),\n         mechanic = gsub(\"^and \",\"\",mechanic)) %>% \n  filter(!is.na(mechanic))\n\n\nkableExtra::kable(head(board_games))\n\nHere is the second part of the wrangling\n\nmechanic <- board_games %>% \n  count(mechanic,sort=T) %>%\n  mutate(mechanic_pct=round(n/sum(n)*100,2))%>%\n  left_join(select(board_games,name,mechanic),by=\"mechanic\") %>%\n  mutate(name=as.factor(name),mechanic=as.factor(mechanic)) %>% \n   distinct() \n\nThis part is for setting the fonts\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\n#font_families_google()\nfont_add_google(name=\"Piedra\",family=\"games\")\n\nfamily = \"games\"\n\n\nSelect the first 50 games\n\nboard_games50 <-board_games%>%\n  select(name,mechanic)%>%\n  count(name,sort=T) %>%\n  slice(1:50)\n\n\n\n\nThe interesting part is here: if we change the filtering level of the mechanic_pct and/or the widyr::pairwise_cor() from the {widyr} package we can see the graph changing along with it. More changes if the level of correlation changes to a lower value more than if set to a higher value.\n\ndf <- board_games50%>%\n  left_join(mechanic,by=\"name\") %>%\n  filter(mechanic_pct > 1) %>%\n  pairwise_cor(mechanic, name, sort = T) %>% \n  filter(correlation > .1)\n\nThe function igraph::graph_from_data_frame() transform data frames into igraph graphs. In addition the funtion igraph::tkplot() can be useful for looking at the graph under different perspectives.\nThis is the final version of the plot:\n\nplot <- df %>% \n  igraph::graph_from_data_frame() %>% \n  ggraph() +\n  geom_edge_link(linejoin = \"round\",\n                 color=\"grey5\",\n                 edge_colour=\"red\",\n                 edge_width=0.5,\n                 edge_linetype=\"solid\") +\n  geom_node_point(color=\"midnightblue\",size=40,alpha=0.4) +\n  geom_node_text(aes(label = name), \n                 repel = T,\n                 size=5,\n                 nudge_y = 0,\n                 color=\"orange\",\n                 family=family) + \n  theme_void() +\n   theme(text = element_text(family=family),\n         plot.background = element_rect(color=\"beige\",fill=\"beige\"))\n\n\n\n\n\n\n\nAdding some features and save\n\n\nlibrary(cowplot)\n\nfinal <-ggdraw()+\n  draw_plot(plot) +\n  draw_label(\"Network of game \\nmechanics\",x=0.5,y=0.85,size=55,fontfamily=family)+\n  draw_label(\"Sliced by the first 50 games by frequency, \n             filtered mechanics greater than 2% proportion of total,\n             then finally taken just the most highly correlated ones\",\n             x=0.8,y=0.12,size=11,fontfamily=family) +\n  draw_label(\"DataSource: Kaggle & Board Games Geek | Viz: Federica Gazzelloni\",\n             x=0.8,y=0.03,angle=0,size=11,alpha=0.5,fontfamily=family) +\n   draw_image(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/static/plot_logo.png\",x=0.09,y=-0.47,scale=0.05)\n\n\nggsave(\"w4_board_games.png\",\n        plot =final,\n        bg=\"white\",\n        dpi = 320,\n        width = 11,\n        height = 6\n       )\n\n\n\n\n\n\ntidygraph\nigraph\nggnet"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w36_lego/w36_lego.html",
    "href": "tidytuesday/cases2022/posts2022/w36_lego/w36_lego.html",
    "title": "LEGO database",
    "section": "",
    "text": "library(tidyverse)\n\n\ninventories <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-06/inventories.csv.gz')\ninventory_sets <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-06/inventory_sets.csv.gz')\nsets <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-09-06/sets.csv.gz')\n\nall_df <- left_join(inventories, inventory_sets, by = \"set_num\") %>%\n  left_join(sets, by = \"set_num\") \n\n\nall_df %>%\n  ggplot(aes(x = num_parts)) +\n  geom_density() +\n  scale_x_log10()\n\n\nall_df %>%\n  DataExplorer::profile_missing()\n\n\ndf <- all_df%>%\n  arrange(year) %>%\n  count(num_parts,year,version) %>%\n  mutate(version=as.factor(version)) %>% # year=as.factor(year),\n  group_by(year,version) %>%\n  summarise(pct_parts=sum(num_parts),.groups=\"drop\") %>%\n  ungroup() \n\n\n# library(systemfonts)\n# fonts <- system_fonts()\n# fonts%>%\n#   arrange(family)%>%\n#   filter(family==\"Legothick\")\n\n\nlegofont <- systemfonts::register_font(name=\"LEGothicType\",\n                                       plain=\"/Library/Fonts/Legothick.ttf\")\n\n\n\ndf %>%\n  ggplot(aes(year,factor(pct_parts),fill=version,color=version))+\n  geom_bin2d(size=0.5,bins=20,show.legend = F)+ \n  labs(title=\"\\nLEGO\")+\n  theme_void() +\n  theme(text=element_text(family=\"LEGothicType\"),\n        plot.title = element_text(size=40,hjust=0.5),\n        plot.subtitle = element_text(family=\"Roboto Condensed\"),\n        axis.text.x = element_text(color=\"grey40\",vjust=0),\n        #axis.text.y = element_text(color=\"orange\"),\n        legend.position = c(0.5,0.5),\n        legend.direction = \"horizontal\",\n        legend.text = element_text(family=\"Roboto Condensed\"),\n        legend.title = element_text(family=\"Roboto Condensed\"),\n        plot.margin = margin(5,5,5,5,unit = \"pt\"),\n        plot.background = element_rect(fill = \"red\",color = \"red\")) \n\n  \nggsave(\"w36_lego.png\",\n       dpi=320,\n       width = 8,\n       height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w46_web_page_metrics/w46_web_page_metrics.html",
    "href": "tidytuesday/cases2022/posts2022/w46_web_page_metrics/w46_web_page_metrics.html",
    "title": "Web page metrics",
    "section": "",
    "text": "library(tidyverse)\n# install.packages(\"ggsci\")\nlibrary(ggsci)\nlibrary(ggnewscale)\n# ggnewscale::new_scale_fill()\nlibrary(ggtext)\nlibrary(lubridate)\n\n# set the fonts\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name=\"Roboto Condensed\",\n                family=\"Roboto Condensed\")  \nfont_add_google(name=\"Zen Dots\",\n                family=\"Zen Dots\") \n\n\ntheme_set(theme_void(base_family = \"Roboto Condensed\", base_size = 9))\ntheme_update(\n  axis.text.x = element_text(color = \"grey60\", margin = margin(t = 4)),\n  axis.ticks.x = element_line(color = \"grey60\"),\n  axis.ticks.length.x = unit(.4, \"lines\"),\n  panel.spacing = unit(1.5, \"cm\"),\n  legend.position = \"none\",\n  panel.grid = element_blank(),\n  # t,r,b,l\n  plot.margin = margin(5, 70, 5, 20),\n  plot.background = element_rect(fill = \"grey98\", color = \"grey98\"),\n  plot.title = element_text(family = \"Zen Dots\",size=14),\n  plot.caption = element_text(family = \"Roboto Condensed\", color = \"grey60\", \n                              size = 8, margin = margin(t = 30, r = 50)),\n  strip.text = element_text(family = \"Zen Dots\")\n)\n\n\n# image_alt <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/image_alt.csv')\n# color_contrast <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/color_contrast.csv')\n# ally_scores <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/ally_scores.csv')\nbytes_total <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/bytes_total.csv')\n\nspeed_index <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-15/speed_index.csv')\n\n\nbytes_total%>%head\n\n\nspeed_index%>%head\n\n\ncenter <- function(x) {\n  (x-min(x))/(max(x)-min(x))\n}\n\n\ndf <- speed_index %>%\n  inner_join(bytes_total,by=c(\"client\",\"date\",\"timestamp\")) %>%\n  select(-timestamp,-measure.x,-measure.y) %>%\n  mutate(date= ymd(date),\n         ym=zoo::as.yearmon(date),.after=date) %>%\n  group_by(client) %>%\n  arrange(client,date) %>%\n  ungroup() %>%\n  group_by(ym) %>%\n  mutate(speed_ym=sum(p50.x),\n         bytes_ym=sum(p50.y),.after=ym) %>%\n  ungroup() %>%\n  pivot_longer(cols = c(\"p10.x\",\"p25.x\",\"p50.x\",\"p75.x\",\"p90.x\"),names_to=\"sp_quantiles\",values_to = \"speed\") %>%\n  pivot_longer(cols = c(\"p10.y\",\"p25.y\",\"p50.y\",\"p75.y\",\"p90.y\"),names_to=\"by_quantiles\",values_to = \"bytes\") %>%\n  mutate(sp_quantiles=gsub(\".x\",\"\",sp_quantiles),\n         by_quantiles=gsub(\".y\",\"\",by_quantiles)) %>%\n  distinct() %>%\n  mutate(speed_ctr=center(speed),\n         bytes_ctr=center(bytes),\n         alpha= center(speed_ym),\n         bytes_seconds=bytes/speed)\n\n\ndf\n\n\nlabels <- df %>% \n  filter(date==max(date)) %>%\n  select(client,date,by_quantiles,bytes, bytes_ctr,speed,speed_ctr) %>%\n  group_by(by_quantiles,date,client) %>%\n  summarize(avg_bytes=mean(bytes),\n         avg_speed=mean(speed),\n         avg_bytes_ctr=mean(bytes_ctr),\n         avg_speed_ctr=mean(speed_ctr),.groups = \"drop\") %>%\n  ungroup() %>%\n  distinct() %>%\n  mutate(bts_sec=round(avg_bytes/avg_speed,2),\n         by_quantiles=paste0(gsub(\"p\",\"\",by_quantiles),\"%\"))\n\nlabels\n\n\nsummary(df$alpha)\n\n\ndf %>%\n  ggplot(aes(x = date)) +\n  geom_area(aes(y = bytes_ctr,\n                group=by_quantiles,\n                alpha=speed_ctr,\n                color=by_quantiles,\n                fill=by_quantiles)) +\n  ggsci::scale_fill_futurama() +\n  ggsci::scale_color_futurama() +\n  geom_richtext(data = labels,\n                aes(x = date, y = avg_bytes_ctr, group = by_quantiles,\n                    label = glue::glue(\"<b style='font-size:7.5pt;'>{by_quantiles}</b><b style='font-size:6pt;'> {round(bts_sec, 2)} Bps<br>\"),\n                    color = by_quantiles,# nudge_x = 1,\n                    hjust = 0.05,\n                    vjust = 0.7),\n                inherit.aes = FALSE,\n                position = \"stack\",\n                family = \"Roboto Condensed\",\n                size = 2.3,\n                label.colour = NA,\n                fill = NA) +\n  facet_wrap(vars(client),\n             labeller = labeller(client=c(\"desktop\"=\"Desktop\",\"mobile\"=\"Mobile\"))) +\n  scale_alpha(range = c(.5, 0.8)) +\n  scale_x_date(date_labels = \"%Y\",\n               date_breaks = \"1 year\",\n               expand = c(0,0)) +\n  scale_y_continuous(expand = c(0,0)) +\n  coord_cartesian(clip = \"off\") +\n  guides(alpha=\"none\",color=\"none\",fill=\"none\") +\n  labs(title=\"Speed Index\\n\\n\",\n       #subtitle=\"Desktop vs Mobile Bps\",\n       caption=\"Data provides informations about median values of bytes loaded per second by type of device used\\n#TidyTuesday 2022 week 46 | Data: Web Page metrics by httparchive.org | Viz: Federica Gazzelloni\") \n\n\nggsave(\"w46_web_page_metrics.png\",\n       dpi=300,\n       width = 9,height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w44_horror_movies/w44_horror_movies.html",
    "href": "tidytuesday/cases2022/posts2022/w44_horror_movies/w44_horror_movies.html",
    "title": "Horror Movies",
    "section": "",
    "text": "library(tidyverse)\n\n\nhorror_movies <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-01/horror_movies.csv')\nhorror_movies%>%head\n\n\nhorror_movies%>%names\n\n\nhorror_movies%>%DataExplorer::profile_missing()\n\n\n# Library\nlibrary(tidyverse)\nlibrary(streamgraph)\n\n# set the fonts\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name=\"Creepster\",family=\"Creepster\")\n\n\nhorror_movies<-readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-01/horror_movies.csv')\n\nhorror_movies%>%\n  pull(revenue)%>%summary()\nhorror_movies%>%\nfilter(revenue==701842551)%>%View\n\n# Create data:\nhorror_movies%>%\n  arrange(release_date) %>%\n  filter(str_detect(genre_names,\"horror|Horror\"),\n         status==\"Released\",\n         revenue> 0) %>%\n  select(id,title,original_language,\n         release_date,\n         genre_names,\n         popularity,vote_average,\n         budget,revenue) %>% \n  mutate(title=trimws(title),\n         ymonth=zoo::as.yearmon(release_date),\n         year=lubridate::year(release_date)) %>%\n  group_by(original_language,year) %>%\n  summarize(avg_budget=round(mean(budget),2),\n            avg_revenue=round(mean(revenue),2))%>%\n  ungroup() %>%\n  arrange(-avg_budget,-avg_revenue) %>%\n  mutate(name=original_language,\n         value=avg_revenue) -> data\n\n\n\n\n# remotes::install_github(\"davidsjoberg/ggstream\")\nlibrary(ggstream)\n\nlabel<-data %>%\n  group_by(original_language)%>%\n  summarize(year=round(mean(year)),\n            value=max(value))%>%\n  ungroup()\n\ndata %>% #pull(value)%>%summary()\n  ggplot(\n    aes(\n      year, value, \n      color = original_language, \n      fill = original_language\n    )\n  ) +\n  geom_stream(\n    geom = \"polygon\",\n    bw = .45,\n    size = 0,\n    show.legend = F\n  ) +\n  geom_stream(\n    geom = \"contour\",\n    color = \"grey20\",\n    size = 0.05,\n    bw = .45, # Controls smoothness\n    show.legend = F\n  ) +\n  scale_y_log10()+\n  geom_text(data=label,\n            aes(x=year,value,\n                label=original_language),\n            family=\"Creepster\",\n            show.legend = FALSE,\n            check_overlap = FALSE)+\n  labs(title=\"Horror Movies\",\n       subtitle=\"revenue by original language\",\n       caption=\"Your fears are unleashed - IT (2017) reached the highest revenue with $701 842 551\\nDataSource: #TidyTuesday 2022 week 44: Horror Movies by The Movie Database\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       x=\"Year\",y=\"Revenue\") +\n  theme_minimal()+\n  theme(text=element_text(color=\"white\",\n                          family=\"Creepster\"),\n        plot.title = element_text(size=25),\n        axis.text.x = element_text(color=\"grey80\"),\n        plot.background = element_rect(color=\"grey5\",fill=\"grey5\"))\n\n# 7.53 x 6.03\nggsave(\"w44_horror_movies.png\",\n       dpi=300,\n       width = 7.53,\n       height = 6.03)\n# geom_stream_label(aes(label = original_language),)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w24_drought/w24_drought.html",
    "href": "tidytuesday/cases2022/posts2022/w24_drought/w24_drought.html",
    "title": "US Drought",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(geojsonio)\nlibrary(RColorBrewer)\nlibrary(rgdal)\nlibrary(rgeos)\n\n\n# Set the fonts\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name=\"Chelsea Market\",\n                family=\"Chelsea Market\")\n\n\n#tuesdata <- tidytuesdayR::tt_load('2022-06-14')\ndrought_fips <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-14/drought-fips.csv')\n\n\n\n\ndrought_fips%>%\n  group_by(State)%>%\n  summarise(drought=mean(DSCI))%>%\n  ungroup() %>%\n  ggplot(aes(x=fct_reorder(State,-drought),y=drought))+\n  geom_col()+\n  labs(x=\"\",y=\"\",\n       title=\"Avg level of drought for each state\")+\n  ggthemes::theme_economist_white()+\n  theme(axis.text.x = element_text(size=5))\n\n\ndrought_avg<- drought_fips%>%\n  group_by(State)%>%\n  summarise(drought=mean(DSCI))%>%\n  ungroup()\n\n\n\n\nsource: https://d3-graph-gallery.com/graph/hexbinmap_geo_basic.html\n\n# load json data\nmap_hex <- \n  geojson_read(\"us_states_hexgrid.geojson.json\",  what = \"sp\")\n\n# map_hex%>%class # SpatialPolygonsDataFrame\n# set the names\nmap_hex@data <-\n  map_hex@data %>%\n  mutate(google_name = gsub(\" \\\\(United States\\\\)\", \"\", google_name))\n\n\n# make a smaller sized hex \nmap_hex_buffer <- gBuffer(map_hex, width = -.15, byid = T)\n\n# tidy to dataframe\nmap_hex_tidy <- tidy(map_hex_buffer, region = \"iso3166_2\")\n\n# add drought level\nhex_drought <- \n  map_hex_tidy %>%\n  left_join(drought_avg, by = c(\"id\"=\"State\"))\n\n# make the centroids with state names\ncentr <- cbind.data.frame(data.frame(gCentroid(map_hex_buffer, byid = T), \n                                     id = map_hex@data$iso3166_2))\n\n\n\n\n\nggplot()+\ngeom_polygon(data=map_hex,\nmapping=aes(long,lat,group=group),\nfill=\"brown\",\ncolor=\"#f8bc05\")+\ngeom_polygon(data=hex_drought,\nmapping=aes(long,lat,group=group,fill=drought),\ncolor=\"white\")+\ngeom_text(data=centr,\naes(x=x, y=y, label=id),\ncolor=\"white\",size=2,fontface=\"bold\") +\nscale_fill_gradient(low = \"grey\", high = \"brown\")+\nlabs(title=\"US intense drought locations\",\ncaption=\"DataSource: #TidyTuesday 2022 week24 & Drought.gov | DataViz: @FGazzelloni\",\nfill=\"Level\")+\ncoord_map()+\nggthemes::theme_map()+\ntheme(text=element_text(color=\"white\",family=\"Chelsea Market\"),\npanel.background = element_rect(fill=\"#162e51\",color=\"#f8bc05\",size=1),\nplot.background = element_rect(fill=\"#0071bc\",color=\"#f8bc05\",size=1),\nplot.title = element_text(size=20,color=\"#f8bc05\"),\nlegend.background = element_rect(fill=\"#0071bc\",color=\"#f8bc05\",size=0.5),\nlegend.position = c(0.01,0.3))\n\n\nggsave(\"w24_drought.png\",\ndpi=320,\nwidth = 5.9,\nheight = 4)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w13_sports/w13_sports.html",
    "href": "tidytuesday/cases2022/posts2022/w13_sports/w13_sports.html",
    "title": "Collegiate Sports Budgets",
    "section": "",
    "text": "library(tidyverse)\noptions(scipen = 999)\n\nlibrary(hrbrthemes)\nlibrary(viridis)\n\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\n\nfont_add_google(name=\"Noto Sans\",family=\"notosans\")\n\nsports <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-29/sports.csv')\n\ndf <-sports%>%\n  select(year,ef_total_count,total_exp_menwomen,total_rev_menwomen,sports)%>%\n  drop_na() \n\n\nggplot(data = df,\n       aes(x=(total_exp_menwomen), y=(total_rev_menwomen), \n           size=ef_total_count, fill=sports)) +\n  geom_point(alpha=0.5, shape=21, color=\"black\") +\n  scale_size(range = c(.1, 9), name=\"Students total count\",\n             labels = scales::comma_format(scale = 1/100)) +\n  scale_fill_viridis(discrete=TRUE, guide=FALSE, option=\"B\") +\n  scale_x_log10(expand = c(0,0.2),labels = scales::dollar_format(scale = 1/100))+\n  scale_y_log10(expand = c(0,0.2),labels = scales::dollar_format(scale = 1/100))+\n  theme_ipsum() +\n  theme(text=element_text(family=\"notosans\"),\n        legend.position=\"bottom\") +\n  labs(title=\"How profitable can college sports be? - USA Facts\",\n       subtitle = \"data from 2015 to 2019 - in thousands of $\",\n       caption=\"DataSource: Equity in Athletics Data Analysis | USA Facts | DataViz: Federica Gazzelloni\")+\n  ylab(\"Total Revenue\") +\n  xlab(\"Total expenditure\") +\n  theme(legend.position = c(0.2,0.7),\n        plot.title = element_text(size=24),\n        plot.title.position = \"plot\",\n        plot.background = element_rect(color=\"grey86\",fill=\"grey86\"),\n        panel.background = element_rect(color=\"grey86\",fill=\"grey86\"))\n\n\nggsave(\"w13_sports.png\",width = 10, height = 8)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w11_vignettes/w11_vignettes.html",
    "href": "tidytuesday/cases2022/posts2022/w11_vignettes/w11_vignettes.html",
    "title": "CRAN/BIOC Vignettes",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggridges)\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\n\nfont_families_google()\n\nfont_add_google(name=\"Overpass\",family=\"overpass\")\n\nbioc <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-15/bioc.csv')\ncran <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-15/cran.csv')\n\n\nhead(bioc)\nhead(cran)\n\nbioc2 <-bioc%>%mutate(date=as.Date(date,\"%Y-%m-%d\"))\n\ncran_a <-cran%>%\n  mutate(date=format(as.Date(date,\"%a %b %d %H:%M:%S %Y\"), format=\"%Y-%m-%d\"),\n         date=as.Date(date,\"%Y-%m-%d\")) %>%\n  drop_na()\n\ncran_b <-cran%>%\n  mutate(date=as.Date(date,\"%Y-%m-%d\")) %>%\n  drop_na()\n\n\nclass(cran_a$date)\nclass(cran_b$date)\n\ncran2 <- rbind(cran_a,cran_b) %>%\n  select(-version)\n\ncran2%>%DataExplorer::profile_missing()\n\nhead(cran2)\nhead(bioc2)\n\ncran2 <- cran2 %>% \n  mutate(source = \"Cran\\n\") %>%\n  relocate(date,rnw,rmd,package,source)\n\nbioc2 <- bioc2 %>%\n  mutate(source = \"Bioconductor\\n\")\n\ndim(cran2);dim(bioc2)\n\n\ndf <- rbind(cran2,bioc2) %>%\n  distinct()\n\n\ndf %>%\n  mutate(year=lubridate::year(date)) %>%\n  distinct() %>%\n  count(year,source,sort=T) %>%\n  arrange(year) %>%\n  ggplot(aes(x=n, y=factor(year),# height = ..density..,\n             fill=factor(year))) +\n  geom_density_ridges(scale = 0.8, alpha=0.6, \n                      #rel_min_height = 0.1,\n                      stat=\"binline\", bins=30) +\n  facet_wrap(~source,scales = \"free\")+\n  labs(caption=\"DataSource: CRAN/BIOC Vignettes | Robert Flight GitHub | #TidyTuesday week 11 2022 | DataViz: Federica Gazzelloni\") +\n  theme_ridges() +\n  theme(text = element_text(family=\"overpass\",size=15),\n        plot.caption = element_text(size=8,hjust = 0.3),\n        legend.position=\"none\",\n        panel.spacing = unit(0.1, \"lines\"),\n        strip.text.x = element_text(size = 28),\n        strip.background = element_rect(fill=\"grey86\"),\n        plot.background = element_rect(color=\"grey86\",fill=\"grey86\"),\n        panel.background = element_rect(color=\"grey86\",fill=\"grey86\")) +\n  xlab(\"CRAN/BIOC Vignettes: number of releases per Year\") +\n  ylab(\"Assigned Probability (%)\")\n\n\nggsave(\"w11_vignettes.png\",width = 9.79 , height =  9.46)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w47_uk_museums/w47_uk_museums.html",
    "href": "tidytuesday/cases2022/posts2022/w47_uk_museums/w47_uk_museums.html",
    "title": "UK Museums",
    "section": "",
    "text": "library(tidyverse)\ntuesdata <- tidytuesdayR::tt_load(2022, week = 47)\nmuseums <- tuesdata$museums\nmuseums %>% head\n\n\nmuseums %>%\n  DataExplorer::profile_missing()\n\n\n# https://stackoverflow.com/questions/54560369/png-of-static-map-using-r-and-mapdeck\nlibrary(tidyverse)\ndf = read.csv(\"https://git.io/geocompr-mapdeck\")\n\ndf\n\n\nlibrary(mapdeck)\n\nset_token(\"MAPBOX_TOKEN\")\nms = mapdeck_style(\"dark\")\n\ndf <- df[!is.na(df$lat), ]\n\nmapdeck(style = ms, pitch = 45) %>%\n  add_grid(data = df, lat = \"lat\", lon = \"lng\", \n           cell_size = 1000,\n           elevation_scale = 50, \n           layer_id = \"grid_layer\",\n           colour_range = colourvalues::colour_values(1:6, palette = \"plasma\")) \n\n\nmapdeck(style = mapdeck_style('dark'),zoom = 1) %>% \n    add_grid(data = df, \n             lat = \"lat\", \n             lon = \"lng\", \n             cell_size = 1000,\n             elevation_scale = 50, \n             layer_id = \"grid_layer\",\n             colour_range = colourvalues::colour_values(1:6, palette = \"plasma\")) %>%\n  add_scatterplot(data = museums,\n                  lat = \"Latitude\",\n                  lon = \"Longitude\",\n                  radius = 0.5,\n                  legend = TRUE,\n                  fill_colour = \"Accreditation\",\n                  layer_id = \"scatter_layer\",\n                  palette = \"viridis\") \n\n\ntable <- museums %>%\nselect(museum_id,`Village,_Town_or_City`,Accreditation,Size,Subject_Matter) %>%\n  janitor::clean_names() %>%\n  group_by(accreditation) %>%\n  count(size) %>%\n  mutate(pct=round(n/sum(n)*100,2)) %>%\n   ungroup() %>%\n  pivot_wider(names_from = size,values_from = pct) %>%\n  select(-n) %>%\n  pivot_longer(cols = 2:6,names_to = \"Type\",values_to = \"pct\")%>%\n  na.omit() %>%\n  pivot_wider(names_from = accreditation,values_from = pct) %>%\n  gt::gt()\n\ntable\n\n\nlibrary(cowplot)\n\nggdraw() +\n  draw_image(\"base_map.png\") +\n  draw_image(\"table.png\",\n             scale=0.25,\n             x=-0.3,y=0)\n\n\nggplot2::ggsave(\"test.png\",\n       dpi=320)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w9_stations/w9_stations.html",
    "href": "tidytuesday/cases2022/posts2022/w9_stations/w9_stations.html",
    "title": "Alternative Fuel Stations",
    "section": "",
    "text": "Alternative fueling stations data-set is from the Bureau of transportation statistics updated at January 3, 2022. The U.S. Department of Energy collects this data in partnership with Clean Cities coalitions and their stakeholders to help fleets and consumers find alternative fueling stations.1\n\nlibrary(tidyverse)\n# library(tidytuesdayR)\n# tuesdata <- tidytuesdayR::tt_load(2022, week = 9)\n# stations <- tuesdata$stations\nstations <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-01/stations.csv')\n\nStations dataset is made of 70 variables and about 60000 observations.\nWe are interested in:\n\nOpen date\nStates and cities\nGeo codes\nFuel type code:\n\nBiodiesel (BD),\nCompressed Natural Gas (CNG),\nElectric (ELEC),\nEthanol (ethanol-gasoline blends, E85),\nHydrogen (HY),\nLiquefied Natural Gas (LNG),\nPropane (Liquefied Petroleum Gas, LPG)\n\nStatus code:\n\nAvailable (E)\nPlanned (P)\nTemporarily Unavailable (T)\n\nAccess code:\n\nPublic\nPrivate\n\n\nEach point on the map is counted as one station in the station count\n\nstations <- stations%>%\n  janitor::clean_names()\n\nstations%>%head\n\n\nstations%>%select(contains(\"ev\"))\n\n\nstations%>%names%>%sort\n\n\nstations%>%count(bd_blends,bd_blends_french)\nstations%>%count(e85_blender_pump,e85_blender_pump,e85_other_ethanol_blends)\nstations%>%count(ev_network,ev_on_site_renewable_source)\nstations%>%count(hydrogen_is_retail,hydrogen_pressures,hydrogen_standards,hydrogen_status_link)\nstations%>%count(lng_on_site_renewable_source)\nstations%>%count(cng_on_site_renewable_source)\n\nstations%>%count(facility_type)\nstations%>%count(fuel_type_code)\nstations%>%count(lpg_primary)\n\n\ndf <- stations%>%\n  #filter(between(longitude,-126,-50),latitude>23)%>%\n  mutate(fuel_type=case_when(fuel_type_code==\"BD\"~\"Biodiesel (B20 and above)\",\n                             fuel_type_code==\"CNG\"~\"Compressed Natural Gas (CNG)\",\n                             fuel_type_code==\"E85\"~\"Ethanol (E85)\",\n                             fuel_type_code==\"ELEC\"~\"Electric\",\n                             fuel_type_code==\"HY\"~\"Hydrogen\",\n                             fuel_type_code==\"LNG\"~\"Liquefied Natural Gas (LNG)\",\n                             fuel_type_code==\"LPG\"~\"Propane (LPG)\",\n                             TRUE~fuel_type_code))%>%\n  select(open_date,city,state,zip,latitude,longitude,\n         access_code,\n         facility_type,\n         fuel_type_code,\n         fuel_type,\n         cng_on_site_renewable_source,\n         lng_on_site_renewable_source,\n         ev_on_site_renewable_source)\n\n\nworld <- map_data(\"world\")%>%\n  filter(!region==\"Antarctica\")\nusa <-map_data(\"state\")\n\n\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\n\nfont_add_google(name=\"Noto Sans\",family=\"notosans\")\n\n\nplot <- ggplot() +\n  geom_polygon(data=world,aes(x=long,y=lat,group=group),\n               fill=\"grey85\",color=\"#654321\",size=0.1) +\n  geom_polygon(data = usa,\n               aes(x = long, y = lat, group = group),\n               fill=\"grey85\",color=\"#654321\",size=0.1,linetype=\"dashed\") +\n  geom_point(data=df,aes(x=longitude,y=latitude,group=state,color=fuel_type_code),\n             show.legend = T,size=0.1,#shape=\".\",\n             key_glyph = rectangle_key_glyph(fill=color)) + \n  \n  geom_point(data=subset(df,fuel_type_code==\"CNG\"),\n             aes(x=longitude,y=latitude,group=state,color=fuel_type_code),\n             show.legend = T,shape=21,stroke=0.1,\n             key_glyph = rectangle_key_glyph(fill=color)) + \n  guides(colour=guide_legend(title.position=\"top\", nrow = 1,\n                                     title.hjust =0.5))+\n  ggthemes::scale_color_tableau(name = \"Fuel type code\",\n    breaks=c(\"ELEC\", \"E85\", \"LPG\",\"CNG\",\"BD\",\"LNG\",\"HY\"))+\n  coord_map(\"ortho\", orientation = c(41.071548, -102.211644, 0)) +\n  labs(title=\"\",\n       subtile=\"\",\n       x=\"\",y=\"\") +\n  theme_void() +\n  theme(text = element_text(family=\"notosans\"),\n        legend.position =  c(0.54,0.61),\n        legend.box.spacing = unit(0,\"pt\"),\n        legend.direction = \"horizontal\",\n        legend.key.size = unit(10,\"pt\"),\n        legend.justification = \"center\",\n        plot.margin = margin(0,0,0,0,unit=\"pt\"),\n        panel.background = element_rect(fill=\"#d8ebff\",color=\"#d8ebff\"),\n        plot.background = element_rect(fill=\"#d8ebff\",color=\"#d8ebff\"))\n\nplot\n\n\nlibrary(gt)\nlibrary(gtExtras)\ntable <- df%>%\n  count(fuel_type,fuel_type_code)%>%\n  mutate(pct=round(n/sum(n)*100,2))%>%\n  arrange(-pct)%>%\n  select(-n)%>%\n  gt::gt(\n    caption=\"Bureau of Transportation Statistics\")%>%\n  gt_plt_bar(column = pct, keep_column = T)%>%\n  tab_header(\n    title = \"Fuel Alternatives\") %>%\n  cols_label(fuel_type_code=\"\",fuel_type = \"Fuel Type\",pct=\"% \")%>%\n  gt_theme_guardian()\n\ntable\n\n#class(table)\n# table %>%\n#   gtsave(filename = \"table.png\")\n\n\nfuel_font <- df%>%\n  select(contains(\"fuel\"),longitude,latitude,city) %>%\n  group_by(city)%>%\n  summarise(fuel_type_code,avg_lng=mean(range(longitude)),avg_lat=mean(range(latitude)),.groups=\"drop\")%>%\n  ungroup()%>%\n  distinct()\n\n \n\nbarplot <- df%>%\n  count(fuel_type_code,fuel_type,cng_on_site_renewable_source,lng_on_site_renewable_source,ev_on_site_renewable_source) %>%\n  pivot_longer(cols=c(\"cng_on_site_renewable_source\",\"lng_on_site_renewable_source\",\"ev_on_site_renewable_source\"),\n               names_to=\"source_name\",values_to=\"source\")%>%\n  filter(!fuel_type==\"NA\",!source==\"NONE\")%>%\n  select(-source_name)%>%\n  drop_na() %>%\n  \n  ggplot(aes(x=fuel_type,y=source))+\n  geom_col(position=\"dodge\",aes(fill=source),show.legend = F)+\n  geom_text(aes(label=source),position=position_dodge(width = 1),\n            angle=0,hjust=1,vjust=0.5,size=5)+\n  #coord_polar(theta = \"x\")+\n  coord_flip()+\n  #facet_wrap(vars(fuel_type))+\n  ggthemes::scale_fill_tableau()+\n  theme_void()+\n  theme(text = element_text(family=\"notosans\",size=12),\n        strip.placement = \"inside\",\n        axis.text.y = element_blank(),\n        plot.background = element_blank(),\n        panel.background = element_blank())\n\nbarplot\n\n\nggsave(\"barplot.png\")\n\n\nlibrary(cowplot)\nggdraw()+\n  draw_plot(plot,scale=1.6)+\n  draw_image(\"barplot.png\",scale=0.5,x=-0.3,y=0.1)+\n  draw_image(\"table.png\",scale=0.3,x=-0.32,y=-0.28)+\n  draw_image(\"NTAD_Logo_32.png\",scale=0.3,x=0.32,y=0.28)+\n  draw_image(\"eia.png\",scale = 0.2,x=0.35,y=-0.3)+\n  draw_line(x = c(0.05, 0.65),y = c(0.88, 0.88),color = \"gold\", size = 4)+\n  draw_label(\"Electric\",x=0.018,y=0.75,size=12,fontfamily = \"notosans\",fontface = \"bold\",angle=90)+\n  draw_label(\"Compr.nat.Gas\",x=0.018,y=0.49,size=12,fontfamily = \"notosans\",fontface = \"bold\",angle=90)+\n  draw_label(\"Fuel type by sources | US DOT | EIA\",x=0.12,y=0.37,size=8,\n             fontfamily = \"notosans\",angle=0)+\n  draw_label(\"US Alternative Fuel Stations\",x=0.35,y=0.9,size=30,\n             fontfamily = \"notosans\",fontface = \"bold\")+\n  draw_label(\"Although gasoline remains by far the dominant \\ntransportation fuel, a variety of alternative fuels \\nare currently in use,primarily by government \\nand private fleets.\\nThese fuels include electricity, propane,\\nhigher ethanol-gasoline blends (E85),\\nhydrogen, and natural gas.\\nIn aggregate, there are currently about 10,000\\n alternative fuel stations in the United States,\\ncompared to approximately 160,000\\n gasoline stations in the country.(EIA)\",size=8,fontfamily = \"notosans\",\n             x=0.86,y=0.47)+\n  draw_label(\"DataSource: #TidyTuesday 2022/w9 | Alternative Fuel Stations | US DOT | EIA\\nInfographics: Federica Gazzelloni\",x=0.35,y=0.05,size=10,fontfamily = \"notosans\")\n\n\nggsave(\"w9_stations.png\",width = 10)\n\n\n\n\n\nFootnotes\n\n\ndatasource↩︎"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w52_star_trek_timelines/w52_star_trek_timeline.html",
    "href": "tidytuesday/cases2022/posts2022/w52_star_trek_timelines/w52_star_trek_timeline.html",
    "title": "Star Trek Timelines",
    "section": "",
    "text": "Load the libraries\nJoin the two sets by footnote\nThe new dataset combines, year, title, … with the footnote of the Star Trek Timelines. The data comes from the {rtrek} package by Georgios Karamanis."
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w52_star_trek_timelines/w52_star_trek_timeline.html#how-to-make-a-waffle",
    "href": "tidytuesday/cases2022/posts2022/w52_star_trek_timelines/w52_star_trek_timeline.html#how-to-make-a-waffle",
    "title": "Star Trek Timelines",
    "section": "How to make a Waffle",
    "text": "How to make a Waffle\nThis is a little example from: https://r-charts.com/part-whole/waffle-chart-ggplot2/\n\n# install.packages(\"waffle\", repos = \"https://cinc.rud.is\")\nlibrary(waffle)\n\n# Vector\nx <- c(30, 25, 20, 5)\n\n# Waffle chart\nwaffle(x, rows = 8)\n\nIn this dataset there are three formats: book, episode and story\n\ndf%>%\n  count(format)%>%\n  waffle(rows=20)\n\n\nUsing ggplot2\nThis Waffle is made of 12 different colors for identifying the SSeries. Here are used many colors from the trekcolors package for coloring the series of different colors.\n\n# install.packages(\"trekcolors\")\nlibrary(trekcolors)\n# trekcolors::lcars_colors()\n\nThe fonts are from the trekfont package.\n\n# install.packages(\"trekfont\")\nlibrary(trekfont)\n# trekfont::show_trekfonts()\nlibrary(showtext)\nfont <- c(\"Khan\", \"StarNext\", \"FederationDS9Title\", \"Federation\", \"Klingon\", \"ModernVulcan\", \"TNGcast\", \"FederationStarfleet\")\npath <- system.file(paste0(\"fonts/\", font, \".ttf\"), package = \"trekfont\")\nfor(i in seq_along(font)) font_add(font[i], path[i])\nfont_families()\nshowtext_auto(enable = TRUE)\n\n\nlibrary(waffle)\ndf%>%\n  count(series)%>%\n  drop_na()%>%\n  waffle(rows = 20, size = 0.5)+\n  scale_fill_manual(values =as.character(lcars_colors())) +\n  # Waffle plot\n  #ggplot(aes(fill = series, values = n)) +\n  #geom_waffle(n_rows = 20, size = 0.5, colour = \"white\") +\n  #scale_fill_manual(values =as.character(lcars_colors())) +\n  coord_equal() +\n  scale_x_continuous(expand = c(0, 0))+\n  labs(title=\"Star Trek Timelines Series\",\n       subtitle = \"\",\n       caption=\"DataSource: #TidyTuesday 2022 week52 - Star Trek Timelines\\nDataViz: Federica Gazzelloni #30DayChartChallenge 2023 Day2 - Waffle\\n\")+\n  theme_void()+\n  theme(text = element_text(family= \"StarNext\",size=14),\n        #legend.position = \"bottom\",\n        plot.title = element_text(size=50,hjust = 0.3,vjust = 0),\n        plot.caption = element_text(size=20,hjust = 0.4,family=\"FederationDS9Title\"),\n        panel.background = element_rect(fill=\"#9977AA\",color=\"#9977AA\"),\n        plot.background = element_rect(fill=\"#9977AA\",color=\"#9977AA\"))\n\n\nggsave(\"ss.png\",\n       width = 6,height = 5.5,\n       bg=\"#9977AA\",\n       dpi=200)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w6_airforce/w6_airmen_dubois_challenge.html",
    "href": "tidytuesday/cases2022/posts2022/w6_airforce/w6_airmen_dubois_challenge.html",
    "title": "Tuskegee Airmen",
    "section": "",
    "text": "TidyTuesday week 6 2022\n\n\noriginal Dubois collection:\n\n\nhttps://www.loc.gov/collections/african-american-photographs-1900-paris-exposition/?sb=shelf-id_desc&sp=1&st=grid\n\n# load data------------\nlibrary(tidyverse)\nairmen <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-08/airmen.csv')\n\n\n# data wrangling--------\ndf <-airmen%>%\n  select(name,graduation_date,graduated_from,\n         pilot_type,\n         military_hometown_of_record,state,\n         number_of_aerial_victory_credits)%>%\n  mutate(pilot_type=str_replace_all(pilot_type,\"Liaison\",\"Liason\"))%>%\n  filter(!is.na(graduation_date),!is.na(state))%>%\n  arrange(desc(graduation_date))%>%\n  mutate(id=row_number())%>%\n  relocate(id)\n\n# 48 states abbr to be chacked\ndf%>%count(state)\n\ndf%>%mutate(year=lubridate::year(graduation_date))%>%count(year)\n\n# map data -----\nus_states_df <-\n  df%>%\n  mutate(state_name=usdata::abbr2state(state),\n         .after=state)%>% \n  filter(!is.na(state_name)) %>%   # 41 us states selected\n  mutate(state_name = tolower(state_name)) \n\nmy_states<-\n  us_states_df%>%\n  count(state_name)%>%\n  select(-n)%>%unlist()\n\n# US states coordinates \nstates<- map_data(\"state\")\n\nmy_states_coords<- \n  states%>%\n  filter(region%in%my_states)%>%\n  left_join(us_states_df,by=c(\"region\"=\"state_name\"))%>%\n  mutate(number_of_aerial_victory_credits=ifelse(number_of_aerial_victory_credits==1.5,\n                                                 2,number_of_aerial_victory_credits))\n\n# World coordinates\nworld<-map_data(map = \"world\") %>%\n  filter(!region==\"Antarctica\")\n\n\n# alabama $ french morocco\nal_frmo<-data.frame(region=c(\"french morocco\",\"alabama\"),\n                    lat=c(30.427755,32.318230),\n                    long=c(-9.598107,-86.902298))\n\n\n\n# dubois colors -------\nstates_palette<-colorRampPalette(c(\"#654321\",\"#d2b48c\",\"#ffd700\",\"#ffc0cb\",\"#dc143c\",\"#00aa00\",\"#4682b4\"))(5)\n\n# fonts---------\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\n#font_families_google()\nfont_add_google(name=\"Barlow Condensed\",family=\"dubois\")\n\n\n# make the map plots ---------------------\n\nworld_west <-\n  ggplot() +\n  geom_polygon(data=world,aes(x=long,y=lat,group=group),\n               fill=\"wheat2\",color=\"#654321\") +\n  geom_polygon(data = states,\n               aes(x = long, y = lat, group = group),\n               fill=\"wheat2\",color=\"#654321\",size=0.1) +\n    \n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==1),\n                 aes(x = long, y = lat, group = group,\n                     fill=factor(number_of_aerial_victory_credits)),\n                 color=\"#654321\",size=0.05) +\n   \n   geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==2),\n                 aes(x = long, y = lat, group = group,\n                     fill=factor(number_of_aerial_victory_credits)),\n                 color=\"#654321\",size=0.05) +\n    \n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==3),\n                 aes(x = long, y = lat, group = group,\n                     fill=factor(number_of_aerial_victory_credits)),\n                 color=\"#654321\",size=0.05)+  \n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==4),\n                 aes(x = long, y = lat, group = group,\n                     fill=factor(number_of_aerial_victory_credits)),\n                 color=\"#654321\",size=0.05)+\n  \n  geom_point(data=al_frmo,aes(x=long,y=lat),color=\"red\")+\n  \n  scale_fill_manual(values=states_palette)+\n  coord_map(\"ortho\", orientation = c(3.849945, -103.525750, 0)) +\n\n  labs(title=\" \\n \\n \",\n       subtile=\" \\n \\n \",\n       x=\"\",y=\"\",fill=\"Aerial victories\") +\n  theme_void() +\n  theme(legend.position = c(0.5,1.2),\n        legend.direction = \"horizontal\")\n\n\nworld_est <-  \n  ggplot() +\n  geom_polygon(data=world,aes(x=long,y=lat,group=group),\n               fill=\"wheat2\",color=\"#654321\") +\n  geom_polygon(data = states,\n               aes(x = long, y = lat, group = group),\n               fill=\"wheat2\",color=\"#654321\",size=0.1) +\n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==1),\n               aes(x = long, y = lat, group = group,\n                   fill=factor(number_of_aerial_victory_credits)),\n               color=\"#654321\",size=0.05)+\n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==2),\n               aes(x = long, y = lat, group = group,\n                   fill=factor(number_of_aerial_victory_credits)),\n               color=\"#654321\",size=0.05)+\n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==3),\n               aes(x = long, y = lat, group = group,\n                   fill=factor(number_of_aerial_victory_credits)),\n               color=\"#654321\",size=0.05)+  \n  geom_polygon(data = subset(my_states_coords,number_of_aerial_victory_credits==4),\n               aes(x = long, y = lat, group = group,\n                   fill=factor(number_of_aerial_victory_credits)),\n               color=\"#654321\",size=0.05) + \n\n  geom_point(data=al_frmo,aes(x=long,y=lat),color=\"red\")+\n  \n  scale_fill_manual(values=states_palette)+\n  coord_map(\"ortho\", orientation = c(10.050474, 55.740732,0)) + #9.982182, 49.595135, 0)) + \n  labs(title=\" \\n \\n \",subtile=\" \\n \\n \",x=\"\",y=\"\",color=\"\") +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n# draw curved text-----------------------\nt<-2*pi\n\ndf_text_left <- \n  data.frame(x = cos(t),\n             y = sin(t),\n             xend = cos(t + 1.8),\n             yend = sin(t + 1.8))\n\np <-ggplot(df_text_left) +\n  geomtextpath::geom_textcurve(aes(x, y, xend = xend, yend = yend),\n                               label = c(\"Afican-American pilots victory\"),\n                               curvature = 0.2, vjust = 1) +\n  coord_equal(xlim = c(-1.1, 1.1), ylim = c(-1.1, 1.2))\n\n\nq <-ggplot(df_text_left) +\n  geomtextpath::geom_textcurve(aes(-x, y, xend =- xend, yend = yend),\n                               label = c(\"Army Air Force during WWII\"),\n                               curvature = -0.2, vjust = -0) +\n  coord_equal(xlim = c(-1.1, 1.1), ylim = c(-1.1, 1.2))\n\nlibrary(patchwork)\ntext_curved <-(p+q)\ntext_curved <- text_curved & theme_void()\n\n# draw circle and a curve-----------\ng <- grid::circleGrob(gp = grid::gpar(fill = \"#baa388\",color=\"#654321\",size=0.5))\n\n\n# final touches----------\nlibrary(cowplot)\nfinal_plot<-ggdraw()+\n  draw_image(\"data/2022/w6_airforce/duboisbg.jpeg\",\n            scale = 1.6)+\n  draw_grob(g, scale=0.542,x=-0.223,y=-0.1) +\n  draw_grob(g, scale=0.542,x=0.229,y=-0.1) +\n  draw_plot(world_west,scale=0.6,x=-0.229,y=-0.07)+\n  draw_plot(world_est,scale=0.6,x=0.229,y=-0.07) +\n  draw_image(\"https://tile.loc.gov/storage-services/service/pnp/ppmsca/33800/33863r.jpg\",\n             scale=0.3,x=0.4,y=0.35) +\n  draw_label(\"Tuskegee Airmen: Aerial Victories\\nAir Force Historical Research Agency\\nGraduation 1942 - 1948\", \n             fontfamily=\"dubois\",color=\"#291c10\",\n             x=0.5,y=0.9,size=25,fontface = \"bold\")+\n  draw_label(\"DataSource: Tuskegee Airmen | Viz @fgazzelloni \\n #DuBoisChallenge | #TidyTuesday 2022/06\", \n             fontfamily=\"dubois\",color=\"#291c10\",\n             x=0.5,y=0.12,size=14,fontface = \"bold\")+\n  draw_plot(text_curved,x=0,y=0.05,scale = 0.5)+\n  draw_label(\"This paper focus on their aerial victory credits. \n             The most famous of the 332d Fighter Group commanders was Col.Benjamin O. Davis,Jr.\n             The 99th Fighter Squadron deployed from Tuskegee, Alabama, to French Morocco in April 1943.\",\n             fontfamily=\"dubois\",color=\"#291c10\",\n             x=0.5,y=0.04,size=14,fontface = \"bold\")\n  \n\n# save the plot--------\nragg::agg_png(\"data/2022/w6_airforce/w6_airforce6.png\",\n              res = 320, width = 12, height = 10, units = \"in\")\nfinal_plot\n\ndev.off()"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w15_indoor_pollution/w15_indoor_air_pollution.html",
    "href": "tidytuesday/cases2022/posts2022/w15_indoor_pollution/w15_indoor_air_pollution.html",
    "title": "Indoor Air Pollution",
    "section": "",
    "text": "rm(list=ls())\nsetwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n\n# load libraries and options\noptions(scipen = 999) # this is to avoid number truncation\nlibrary(countrycode)\nlibrary(tidyverse)\n\n# set the colors\nmycolors <- colorRampPalette(RColorBrewer::brewer.pal(n=9, name=\"Set1\"))(5)\n\n# load data\ndeath_timeseries<-read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-04-12/death_timeseries.csv\")\n\n# data wrangling\ndeath_timeseries1<-death_timeseries%>%\n  rename(Deaths=`Deaths...Cause..All.causes...Risk..Household.air.pollution.from.solid.fuels...Sex..Both...Age..All.Ages..Number.`,\n         Deaths1=`Deaths...Cause..All.causes...Risk..Household.air.pollution.from.solid.fuels...Sex..Both...Age..All.Ages..Number..1`)\n\n\ndeath_timeseries2 <- death_timeseries1%>%\n  filter(Year==1990,Year.1==2019) %>%\n  filter(!str_detect(Entity,\"World|Region|Central|Countries|European\"),\n         !str_detect(Entity,\"Western|Southern|Eastern|Northen\"),\n         !str_detect(Entity,\"North|South|Southeast\"),\n         !str_detect(Entity,\"income|High|Low\"),\n         !str_detect(Entity,\"Commonwealth\"),\n         !str_detect(Entity,\"G20|SDI\"),\n         !str_detect(Entity,\"Europe|Asia|Africa|America|Oceania\")\n         ) \n\n# add missing continents' names with countrycode() function -----------\ndeath_timeseries2$continent <- countrycode(sourcevar = death_timeseries2[, \"Entity\"],\n                                           origin = \"country.name\",\n                                           destination = \"continent\")\n\n\ndeath_timeseries3 <- death_timeseries2%>%\n  # check for some values that were not matched unambiguously ---------\n  # filter(Entity%in%c(\"Australasia\", \"Caribbean\", \n  #                    \"England\", \"Micronesia (country)\", \n  #                    \"Scotland\", \"Timor\", \"Wales\")) %>%\n  mutate(Entity=as.character(Entity), # mutate Entity back as a character to use case_when() function\n         continent=case_when(Entity%in%c(\"England\",\"Scotland\",\"Wales\")~\"Europe\", \n                          Entity==\"Australasia\"~\"Oceania\", \n                          Entity==\"Caribbean\"~\"Americas\", \n                          Entity==\"Micronesia (country)\"~\"Asia\", \n                          Entity==\"Timor\"~\"Asia\",\n                          TRUE ~ continent),\n         Entity=as.factor(Entity)) %>%\n  filter(Deaths1>=1,Deaths>=1) \n\n# make the plot\ndeath_timeseries3 %>%\n  ggplot(aes(x=Deaths1,y=Deaths))+\n  geom_jitter(size=1.7,aes(fill=continent),shape=21,alpha=0.7,color=\"grey45\")+\n  geom_smooth(method = \"lm\",se=F,color=\"grey60\",\n              linetype=\"dashed\",size=0.5)+\n  geom_text(aes(label=Entity,color=continent),\n            hjust = \"left\",\n            show.legend = F,\n            vjust=\"top\",\n            check_overlap = T,\n            size=3)+\n  scale_x_log10(breaks=c(1,10,100,1000,10000,100000),\n                expand=expansion(add=c(0,0.05)),\n                label=scales::comma_format(accuracy = NULL))+\n  scale_y_log10(breaks=c(1,10,100,1000,10000,100000),\n                expand=expansion(add=c(0,0.8)),\n                label=scales::comma_format(accuracy = NULL))+ \n  scale_fill_manual(guide=guide_legend(nrow = 1),\n                    values=mycolors)+\n  scale_color_manual(values=mycolors)+\n  labs(title=\"Deaths due to Household air pollution\\nfrom solid fuels\",\n       subtitle=\"1990 vs 2019 All Ages and Gender\",\n       caption=\"\\n#30DayChartChallenge 2022 day12 - theme day: The Economist\\nDataSource: Our World in Data | #TidyTuesday week15 - Indoor Air Pollution\\nDataViz: Federica Gazzelloni\",\n       x=\"Deaths from indoor air pollution in 2019\",\n       y=\"Deaths from indoor air pollution in 1990\",fill=\"\") +\n  ggthemes::theme_economist() +\n  theme(legend.text = element_text(size=10),\n        plot.title = element_text(size=23),\n        axis.title.x = element_text(vjust = -0.8),\n        axis.title.y = element_text(vjust = 0.8),\n        plot.caption = element_text(vjust = -1,size=9),\n        legend.position = c(0.4,0.85))\n\n#save the plot\nggsave(\"day12_the_economist.png\",\n       dpi=320,\n       width = 8,\n       height = 6)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w7_dubois/w7_dubois.html",
    "href": "tidytuesday/cases2022/posts2022/w7_dubois/w7_dubois.html",
    "title": "#DuBoisChallenge2022",
    "section": "",
    "text": "This week is all about #DuBoisChallenge2022, I choose plate number 6.\n\nlibrary(tidyverse)\n\n\nLoad #TidyTuesday 2022/07 data\n\nplate6 <- read_csv('https://raw.githubusercontent.com/ajstarks/dubois-data-portraits/master/challenge/2022/challenge06/data.csv')\n\n\n\nAdd a column with distances\n\ndf <- plate6 %>%\n  janitor::clean_names() %>%\n  mutate(x_axis=c(1860,1860-cumsum(diff(iliteracy_rate))))\ndf\n\n\n\nCreate axis lables vectors\n\niliteracy_rate<-df$iliteracy_rate\nx_axis <-df$x_axis\n\n\n\nFonts\n\nlibrary(showtext)\nfont_add(family = \"Public Sans Thin\",\n         regular = \"PublicSans-Thin.ttf\")\n\nfont_add(family = \"PublicSans-Medium\",\n         regular = \"PublicSans-Medium.ttf\")\n \nshowtext_auto()\n\n\n\nMake the plot\n\nlibrary(ggstar) # for making the triangles\n  \nnumber6 <- df %>%\n  ggplot(aes(x = x_axis, y = iliteracy_rate))+\n  \n  # add the columns\n  geom_col(width = 1.5,fill=\"black\") +\n\n  # this is one way to add the horizontal lines\n  geom_segment(aes(x = 1858, xend = x_axis+0.1,\n                   y = iliteracy_rate, yend = iliteracy_rate),\n               size = 2.5, color = \"black\") +\n  geom_segment(aes(x = 1858, xend = x_axis+0.1,\n                   y = iliteracy_rate, yend = iliteracy_rate),\n               size = 2.4, color = \"#d9ccbf\")+\n  \n  # with ggstar add the triangular shape\n  geom_star(starshape = 20, size = 0.8,angle = 90, fill = \"black\",\n            position = position_nudge(x = -0.1, y = -0.15)) +\n  \n  # add the little round corners\n  geom_curve(aes(x = x_axis - 0.1, xend = x_axis + 0.65,\n                 y = iliteracy_rate + 1.2, yend = iliteracy_rate),\n             curvature = -0.6, size = 0.1) +\n  \n  # customize the axis values\n  scale_x_continuous(breaks = x_axis,\n                     labels = c(\"99%\",\"92%\",\"81.6%\",\"67.27%\",\"(50%?)\"),\n                     expand = expansion(0.01)) +\n  scale_y_continuous(breaks = iliteracy_rate,\n                     labels = c(1860,1870,1880,1890,\"(1900?)\"),\n                     expand = expansion(0.01)) +\n  \n  # add a title and a theme\n  labs(title = \"ILLITERACY.\\n\", subtitle = \" \", caption = \"fg\")+\n  theme_void()+\n  theme(text = element_text(size = 18, family = \"Public Sans Thin\", color = \"grey25\"),\n        plot.title = element_text(size = 24, family = \"PublicSans-Medium\",face = \"bold\", hjust = 0.5),\n        plot.background = element_rect(fill = \"#d2c2b3\", color = \"#d2c2b3\"),\n        panel.background =  element_rect(fill = \"#d2c2b3\",color = \"#d2c2b3\"),\n        axis.text.x = element_text(),\n        axis.text.y = element_text(),\n        plot.margin = margin(0,25,0,25))\n\n\n\nAssemble background, plot and annotation\nWith {cowplot} add a background image as the same as the original one and the text on the left side of the x-axis\n\n\nSave the plot\n\nggsave(\"w7_Number6.png\", width = 1000, height = 1350, \n       units = \"px\", dpi = 320)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w30_BYOD/w30_BYOD.html",
    "href": "tidytuesday/cases2022/posts2022/w30_BYOD/w30_BYOD.html",
    "title": "Bring your own data",
    "section": "",
    "text": "library(tidyverse)\n\ninvestment <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-08-10/investment.csv')\n\n\ninvestment1 <- investment %>%\n  mutate(meta_cat = case_when(meta_cat==\"Total basic infrastructure\" ~ \"Basic\",\n                              TRUE~meta_cat )) %>%\n  mutate(category = case_when(\n    category==\"Private communications equipment in NAICS 515, 517, 518, and 519\"~\"Private communications equipment\",\n    category==\"Private computers in NAICS 515, 517, 518, and 519\"~\"Private computers\",\n    category==\"Office buildings, NAICS 518 and 519\"~\"Office buildings\",\n    category==\"Private software in NAICS 515, 517, 518, and 519\"~\"Private software\",\n    TRUE~category)) %>%\n  filter(gross_inv>=500) %>%\n  group_by(category) %>%\n  summarize(tot_gross_inv=round(sum(gross_inv)))%>%\n  ungroup() %>%\n  arrange(-tot_gross_inv) \n  \ninvestment1 %>%\n  ggplot(aes(x=fct_reorder(category,tot_gross_inv),y=(tot_gross_inv),group=category)) +\n  geom_histogram(aes(fill=category),stat = \"identity\", position=position_dodge(width=0.8),size=0.8,alpha=0.5,bins = 50)+ \n  geom_text(aes(label=scales::dollar(tot_gross_inv)),size=1.5,hjust=0) +\n  guides(color=\"none\",fill=\"none\") +\n  labs(title=\"US Investment categories based on total gross investments\", \n       subtitle=\"70-year period from 1947 to 2017\\n\",\n       caption=\"\\nBEA: measurement of infrastructure in the U.S. National Economic Accounts (NEAs)\\n \\nInfographic: @fgazzelloni\\n DataSource: TidyTuesday Week33: BEA Infrastructure Investment\",\n       x=\"Investment Categories\",y=\"Total Gross Investment (log10 tranformation)\") +\n  coord_flip() +\n  scale_y_log10(labels=scales::dollar,expand = expansion(mult = c(0, .3))) +\n  ggthemes::theme_economist() +\n  theme(axis.text.x = element_text(angle=0,size=8,hjust=0),\n        axis.text.y = element_text(size=5,hjust=1),\n        axis.title.y = element_text(vjust=4),\n        axis.title.x = element_text(vjust=-2),\n        axis.ticks.x = element_line(size=1,color=\"darkred\"),\n        axis.ticks.y = element_line(size=0.2,color=\"darkred\"),\n        axis.ticks.length=unit(.5, \"cm\"),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(vjust=-5,size=6),\n        plot.caption.position = \"plot\",\n        plot.subtitle = element_text(vjust=-2,hjust=0),\n        panel.grid = element_blank(),\n        panel.background = element_blank(), \n        plot.margin = margin(0.5, 1, 0.5, 1, \"cm\"),\n        plot.background = element_rect(fill = \"grey90\",colour = \"grey\",size = 2)\n  ) +\n  annotate(\"text\",label=\"The Private sector\\nshows the highest level of \\nincrease in investments \\nwithin the last 70 years.\\n Private total gross investments is \\nfollowed by S&L pensions,\\n investments in basic, \\nand social infrastructures. \\nDigital infrastructure and transports \\nare before Power, Health , \\nHighways and finally Education \\nwith about 2 000 000 millions $ total investment.\",x=25,y=100000000,size=2)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w33_psychometrics/w33_psychometrics.html",
    "href": "tidytuesday/cases2022/posts2022/w33_psychometrics/w33_psychometrics.html",
    "title": "Open Source Psychometrics",
    "section": "",
    "text": "psych_stats <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-08-16/psych_stats.csv\")\n\n\npsych_stats%>%head\n\n\nmy_df <- psych_stats%>%\n  arrange(rank)%>%\n  select(char_name,uni_name,personality,avg_rating,rank,rating_sd) %>%\n  filter(uni_name==\"Friends\")\nmy_df\n\nUse {tidytext} to select the personality variables to be used in the visualization. In this case a list of encoded variables, such as /U000.. were filtered out, to leave just words in the vector.\n\nlibrary(tidytext)\nmy_df1 <- my_df %>% \n  mutate(personality=gsub(\"[^A-z]\",\"unknown\",personality))%>%\n  filter(!personality==\"unknown\") %>%\n  #count(personality) %>%\n  unnest_tokens(word, personality) %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  distinct(char_name,word,sentiment,avg_rating) \n\nFurther wrangling activity on the dataset is done to select only the personality words which are in common and with highest avg rating values for all of the protagonists in Friends TV show.\n\nby_names <- my_df1%>%\n  group_by(word)%>%\n  summarize(char_name,avg_rating=mean(avg_rating),.groups=\"drop\")%>%\n  ungroup()%>%\n  pivot_wider(names_from=char_name,values_from=word)%>%\n  drop_na()%>%\n  pivot_longer(cols=2:7,names_to=\"names\",values_to=\"values\")%>%\n  unnest(values)%>%\n  arrange(values) %>%\n  count(values) %>%\n  group_by(values) %>%\n  filter(!n<6 & !n>6) %>%\n  ungroup() %>%\n  left_join(my_df3,by=c(\"values\"=\"word\"))%>%\n  select(-n) %>%\n  pivot_wider(names_from=char_name,values_from=values) %>%\n  pivot_longer(cols=3:8,names_to=\"names\",values_to=\"word\")%>%\n  distinct()%>%\n  drop_na()%>%\n  mutate(word=str_to_title(word)) %>%\n  mutate(id_sentiment=ifelse(sentiment==\"positive\",1,0))\n\n\nlibrary(extrafont)\n# loadfonts()\n\n\np <-by_names%>%\n  ggplot(aes(x=avg_rating,y=fct_reorder(word,-avg_rating)))+\n  geom_col(aes(fill=names), position = position_fill(),color=\"black\")+\n  ggthemes::scale_fill_tableau()+\n  guides(fill=guide_legend(nrow = 1,reverse = T,keywidth = 0))+\n  labs(fill=\"\",\n       subtitle=\"\\nordered by common high-rating personality\",\n       caption=\"DataSource: Open Source Psychometrics | #TidyTuesday 2022 week33\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       title=\"Friends: positive and negative personality ratings\")+\n  ggthemes::theme_fivethirtyeight()+\n  theme(text=element_text(color=\"grey90\",family=\"Public Sans Medium\"),\n        plot.title = element_text(size=22),\n        legend.position = \"top\",\n        legend.background = element_rect(fill=\"black\",color=\"black\"),\n        legend.text = element_text(size=12),\n        strip.background = element_blank(),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(size=12),\n        panel.grid = element_line(size=3),\n        plot.background = element_rect(fill=\"black\",color=\"black\"),\n        panel.background = element_rect(fill=\"black\",color=\"black\"))\n\n\nlibrary(cowplot)\nggdraw(p)+\n  draw_image(\"logo.png\",scale=0.25,\n             x=-0.35,\n             y=0.45)\nggsave(\"w33_psychometrics.png\",\n       dpi=320,\n       height = 7,\n       width = 9)\n\nOther visualization not to be used.\n\nby_names %>%\n  ggplot(aes(fct_reorder(word,avg_rating),avg_rating,\n             fill=sentiment,color=sentiment))+\n  geom_point()+\n  geom_text(aes(label=word),size=3)+\n  # ggimage::geom_image(x=0.2,y=0.2,image=image)+\n  geom_line(aes(group=sentiment))+\n  #geom_col()+\n  facet_wrap(~fct_reorder(names,-avg_rating),scale=\"free\")+\n  ggthemes::scale_color_tableau()"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w43_gbb/w43_gbb.html",
    "href": "tidytuesday/cases2022/posts2022/w43_gbb/w43_gbb.html",
    "title": "Great British Bakeoff",
    "section": "",
    "text": "library(tidyverse)\nbakers <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-10-25/bakers.csv')\nbakers%>%names\n\n\nbakers%>%View\n\n\n# install.packages(\"bakeoff\")\nlibrary(bakeoff)\nbakeoff::bakeoff_palette_names()\n\n\ngbb <- bakers%>%\n  select(hometown,age,occupation,percent_episodes_appeared)%>%\n  group_by(hometown,occupation)%>%\n  summarise_all(.funs=mean)%>%\n  ungroup()\ngbb\n\n\nlibrary(showtext)\nlibrary(sysfonts)\nlibrary(extrafont)\n\n# set the fonts\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nfont_add_google(name = \"Sen\",family=\"Sen\")\n\n\ngbb %>% #pull(age)%>%summary()\n   #filter(str_detect(occupation,\"student|Student\")) # %>% #count(occupation)\n  mutate(occupation=case_when(str_detect(occupation,\"Retired|retired\") ~ \"Retired\",\n                              str_detect(occupation,\"Fashion designer|Fashion Designer\") ~ \"Fashion Designer\",\n                              str_detect(occupation,\"IT Manager|IT programme manager\") ~ \"IT Manager\",\n                              str_detect(occupation,\"student|Student\") ~ \"Student\",\n                              TRUE ~ occupation)) %>% # count(occupation) %>%View\n  #filter(occupation==\"Student\") %>%\n  ggplot(aes(x=fct_reorder(occupation,age),y=age))+\n  #geom_col()+\n  geom_boxplot(aes(fill=occupation),show.legend = F)+\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_discrete(expand = c(0,0)) +\n  coord_flip(ylim=c(15,75))+\n  scale_color_manual(values = bakeoff_colors())+\n  #viridis::scale_fill_viridis(discrete = T)+\n  labs(title=\"Great British Bakeoff Occupations\",\n       subtitle=\"mean age variation\",\n       caption=\"DataSource from the bakeoff package from Alison Hill, Chester Ismay, and Richard Iannone.\\n\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n       y=\"Age\",x=\"Occupation\")+\n  theme(text=element_text(family=\"Sen\",face=\"bold\",color=\"#1a1917\"),\n        plot.title.position = \"plot\",\n        plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(size=8,hjust = 0.2),\n        plot.caption = element_text(size=6),\n        axis.text.y = element_text(size=3),\n        panel.grid.major.x = element_line(color=\"#fa7268\"),\n        panel.grid.major.y = element_line(color=\"#fa7268\",size=0.1),\n        axis.ticks.x = element_line(color=\"#fa7268\"),\n        axis.ticks.y = element_line(color=\"#fa7268\"),\n        axis.line.x = element_line(color=\"#fa7268\"))\n\n\nggsave(\"w43_gbb.png\",dpi=200)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w51_weather_forecast_accuracy/w51_weather_forecast_accuracy.html",
    "href": "tidytuesday/cases2022/posts2022/w51_weather_forecast_accuracy/w51_weather_forecast_accuracy.html",
    "title": "Weather Forecast Accuracy",
    "section": "",
    "text": "The amount of annual precipitation is closely related to the monthly temperature patterns throughout the year. This is because temperature can significantly affect precipitation, which in turn can impact the environment and the ecosystem.\nThroughout the year, different regions experience different temperature changes during each month. Generally, in areas with a cold winter season, monthly temperatures tend to be lower, while areas with a warm tropical climate can have higher temperatures year-round. As temperatures increase, the evaporation rate also increases, leading to more moisture in the atmosphere. This increased moisture can result in higher precipitation levels.\nIn summary, the relationship between annual precipitation and monthly temperatures is a part-to-whole connection because it involves the overall amount of precipitation throughout the year being impacted by the individual temperature conditions of each month. Monthly temperature patterns are a crucial component in understanding and predicting the amount of precipitation and the ecological systems that depend on it.\n\ntuesdata <- tidytuesdayR::tt_load(2022, week = 51)\n\n\nlibrary(tidyverse)\nlibrary(maps)\nlibrary(mapdata)\n\n\nweather_forecasts <- tuesdata$weather_forecasts\ncities <- tuesdata$cities\noutlook_meanings<- tuesdata$outlook_meanings\n\n\nweather_forecasts%>%names\n\n\nweather_forecasts%>%head\n\n\ndf <- weather_forecasts%>%\n  inner_join(cities,by=c(\"city\",\"state\"))\n\n\n# save(df,file=\"df.RData\")\nload(\"data/df.RData\")\n\ndf%>%names\n\n\ndf_mean <- df%>%\n  mutate(ymon=zoo::as.yearmon(date),.after=date)%>% # DataExplorer::profile_missing()\n  group_by(ymon,state)%>%\n  summarize(observed_temp=ifelse(is.na(observed_temp),mean(observed_temp,na.rm = TRUE),observed_temp),\n          forecast_temp=ifelse(is.na(forecast_temp),mean(forecast_temp,na.rm = TRUE),forecast_temp),\n          observed_precip=ifelse(is.na(observed_precip),mean(observed_precip,na.rm = TRUE),observed_precip),\n          avg_annual_precip=ifelse(is.na(avg_annual_precip),mean(avg_annual_precip,na.rm = TRUE),avg_annual_precip),\n          lon,lat,state)%>%\n  distinct() %>%\n  mutate(observed_temp=mean(observed_temp),\n         forecast_temp=mean(forecast_temp),\n         observed_precip=mean(observed_precip),\n         avg_annual_precip=mean(avg_annual_precip))%>%\n  distinct() \n\ndf_mean <- df_mean%>%\n  mutate(year=year(ymon),.after = ymon)\n\n\nstate<- map_data(\"state\")\n\nst <- state%>%\n  mutate(state_name=str_to_title(region))\nstate_name <- unique(st$state_name)\nabbr <- state.abb[match(state_name,state.name)]\n\nst_name_abb <- cbind(state_name,abbr)%>%\n  as.data.frame()%>%\n  mutate(abbr=ifelse(state_name==\"District Of Columbia\",\"DC\",abbr))\n\n\nstates_full <- st%>%\n  inner_join(st_name_abb,by=c(\"state_name\"))\n\n\ndf_mean_full <- states_full%>%\n  inner_join(df_mean,by=c(\"abbr\"=\"state\"))%>%\n  distinct()\n\n\nmap <- df_mean_full%>%\n  filter(year==2021)%>%\n  ggplot(aes(x=long,y=lat.x,group=group))+\n  geom_polygon(aes(fill=avg_annual_precip))+\n    geom_point(\n    data = df %>% count(city, lon, lat),\n    mapping = aes(lon, lat, group = city),\n    color = \"red\",\n    shape = 21,\n    stroke = 0.2,\n    inherit.aes = FALSE\n  ) +\n  geom_text(\n    data = df %>% count(city, lon, lat),\n    mapping = aes(lon, lat, label = city),\n    show.legend = FALSE,\n    color = \"black\",\n    size = 1.5,\n    check_overlap = TRUE,\n    family=\"Roboto Condensed\",\n    inherit.aes = FALSE\n  ) +\n  coord_quickmap()+\n   labs(title = \"#30DayChartChallenge 2023 Day1 - Part to whole\",\n       subtitle = \"Comparing Weather Forecasting Accuracy in the United States\",\n       caption=\"DataSource: #TidyTuesday 2022 week51|Weather Forecast Accuracy\\nDataViz: Federica Gazzelloni #30DayChartChallenge 2023 Day1\",\n       fill=\"AVG Annual Precip\") +\n  theme(panel.background = element_rect(color = \"black\", fill = \"#dedede\"),\n        axis.title = element_blank(),\n        text = element_text(color=\"navy\",family=\"Roboto Condensed\"),\n        panel.grid = element_line(linewidth=0.02,color=\"grey40\"),\n        axis.text = element_blank(),\n        axis.ticks = element_blank())\n\nmap\n\n\nshowtext.auto(enable = FALSE)\nggsave(\"map.png\",\n       width = 7,height = 5)\n\n\ndf_mean%>%\n  filter(year==2021)%>%\n  mutate(month=month(ymon,label = TRUE ),.after = year)%>%\n  mutate(max_mean_temp=mean(observed_temp))%>%\n  arrange(-max_mean_temp)\n\n\ndf_mean%>%\n  filter(state%in%c(\"VI\",\"PR\",\"HI\",\"FL\",\"LA\"),\n         ymon==\"Jan 2021\")%>%\n  arrange(-observed_temp)\n\n\np <- df_mean%>%\n  filter(year==2021)%>%\n  mutate(month=month(ymon,label = TRUE ),.after = year)%>%\n  mutate(max_temp=max(observed_temp))%>%\n  ggplot(aes(factor(month),observed_temp,group=state))+\n  geom_line(aes(color=observed_temp))+\n  geom_text(data=data.frame(month=rep(\"Jan\",5),\n                            observed_temp=c(80,77.6,75.4,66.7,60.8),\n                           label=c(\"VI\",\"PR\",\"HI\",\"FL\",\"LA\")),\n            aes(factor(month),observed_temp,label=label),\n            inherit.aes = FALSE)+\n  labs(color=\"2021 Monthly Observed Temperature by States\")+\n  ggthemes::theme_economist_white()+\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(size=9),\n        plot.background = element_blank())\n\np\n\n\nggsave(\"p.png\",\n       width = 7,height = 5)\n\n\nlibrary(cowplot)\n\nggdraw()+\n  draw_image(\"map.png\")+\n  draw_image(\"images/p.png\",\n             scale=0.35,\n            x=0.3,y=0.3)+\n  draw_label(label=\"Annual precipitation and monthly \\ntemperature are parts of the climate system. Higher annual \\nprecipitation tends to result in lower monthly temperatures \\nas more water in the air can lead to increased cloud cover \\nand less sunlight reaching the ground. Conversely, lower \\nannual precipitation usually means higher monthly \\ntemperatures as there is less water in the air to absorb and \\nreflect sunlight.\",x=0.15,y=.55,size=5,fontfamily = \"Roboto Condensed\")\n\n\nggsave(\"full.png\",width = 7,height = 5)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w49_elevators/w49_elevators.html",
    "href": "tidytuesday/cases2022/posts2022/w49_elevators/w49_elevators.html",
    "title": "Elevators",
    "section": "",
    "text": "library(tidyverse)\n\n\ntuesdata <- tidytuesdayR::tt_load('2022-12-06')\nelevators <- tuesdata$elevators\nelevators%>%names\n\n\nelevators%>%DataExplorer::profile_missing()%>%\n  mutate(pct_missing=round(pct_missing,2))%>%\n  arrange(pct_missing)\n\n\nelevators1%>%head\n\n\nelevators1 <- elevators%>%\n  janitor::clean_names()%>%\n  mutate(date=as.Date(as.character(dv_status_date), format='%Y%m%d',tz=\"UTC\")) %>%\n  select(zip_code,borough,device_type,latitude,longitude,\n         date)%>% # dim 76088     8\n  na.omit() %>% # dim 66789     8\n  mutate(zip_code=as.numeric(sub(\"\\\\D*(\\\\d{5}).*\", \"\\\\1\", zip_code)))%>%\n  arrange(date)%>%\n  filter(!zip_code==0 & !zip_code== 99999,\n         longitude> -75)\n\n\nelevators1 %>%\n  ggplot(aes(longitude,latitude)) +\n  geom_point(aes(color=factor(device_type)))+\n  coord_equal()\n\n\nlibrary(ggnewscale)\nggnewscale::new_scale_color()\n\n\nusdata::county_complete%>%names\nlibrary(zipcodeR)\nzipcodeR::zip_code_db%>%head\nelevators1%>%count(zip_code)%>%dim # 185\nzipcodeR::zip_code_db%>%\n  filter(zipcode%in%elevators1$zip_code)\nzipcodeR::geocode_zip(elevators1$zip_code) # 183\n\n\nus_county_map <- map_data(\"county\")\n\nggplot()+\n  geom_polygon(data=us_county_map,aes(x=long,y=lat,group = group),\n               fill=NA,color = \"lightblue\")\n\n\nus_county_map%>%head\n\n\nus_county_map_centroids <- us_county_map%>%\n  group_by(subregion) %>%\n  mutate(long=mean(range(long)),lat=mean(range(lat)))%>%\n  ungroup()%>%\n  select(-order,-region)%>%\n  distinct()\nus_county_map_centroids\n\n\nelevators1_centroids <- elevators1%>%\n  group_by(borough) %>%\n  mutate(long=mean(range(longitude)),lat=mean(range(latitude)))%>%\n  ungroup()%>%\n  select(borough,zip_code,long,lat)%>%\n  distinct()\n\n\nelevators1 %>%\n  ggplot(aes(longitude,latitude)) +\n   geom_polygon(data = us_county_map,\n                aes(x=long,y=lat,group = group,fill=subregion),\n                color = \"lightblue\",alpha=0.1)+\n  geom_point(aes(color=factor(borough)),\n             shape=21,stroke=0.1,size=0.5)+\n  scale_color_discrete()+\n  guides(color=guide_legend(title=\"Borough\"),fill=\"none\")+\n  ggnewscale::new_scale_color()+\n  geom_point(aes(color=zip_code),shape=\".\",alpha=0.2) +\n  scale_color_continuous(type = \"viridis\")+\n  geom_text(data = elevators1_centroids,\n             aes(x=long,y=lat,label=borough)) +\n  coord_map(xlim = range(elevators1$longitude),ylim = range(elevators1$latitude))+\n  labs(title = \"\",\n       subtitle = \"\",\n       color=c(\"zip code\",\"Borough\"))+\n  ggthemes::theme_map()+\n  theme(legend.position = c(-0.2,0),\n        legend.background = element_blank())+\n  facet_wrap(vars(device_type))\n\n\nelevators1 %>% # count(device_type)\n  filter(device_type==\"Passenger Elevator (P)\") %>%\n  ggplot(aes(longitude,latitude)) +\n   geom_polygon(data = us_county_map,\n                aes(x=long,y=lat,group = group,fill=subregion),\n                color = \"lightblue\",alpha=0.1)+\n  geom_point(aes(color=factor(borough)),\n             shape=21,stroke=0.1,size=0.5)+\n  scale_color_discrete()+\n  guides(color=guide_legend(title=\"Borough\"),fill=\"none\")+\n  ggnewscale::new_scale_color()+\n  geom_point(aes(color=zip_code),shape=\".\",alpha=0.2) +\n  scale_color_continuous(type = \"viridis\")+\n  geom_point(data = elevators1 %>% filter(device_type==\"Handicap Lift (H)\"),\n             aes(longitude,latitude),color=\"red\",size=0.3)+\n  geom_text(data = elevators1_centroids,\n             aes(x=long,y=lat,label=borough),\n            color=\"white\",family=\"Roboto Condensed\") +\n  coord_map(xlim = range(elevators1$longitude),ylim = range(elevators1$latitude))+\n  labs(title = \"New York City Handicap Lifts availability\",\n       subtitle = \"Registered Passenger Elevator devices from the Department of Buildings 2015\",\n       caption=\"DataSource: #TidyTuesday 2022 week49 Elevators by @emilhvitfeldt | Graphics: Federica Gazzelloni\",\n       color=c(\"zip code\",\"Borough\"))+\n  ggthemes::theme_map()+\n  theme(text = element_text(color=\"white\",family=\"Roboto Condensed\"),\n        plot.title = element_text(size=14),\n        plot.caption = element_text(size=10.5),\n        legend.position = \"none\", # c(-0.2,0),\n        legend.background = element_blank()) +\n  annotate(\"text\", \n           x = -74, y = 40.52, \n           label = \"How to read it:\\nPassenger Elevators are colored by borough and zip code,\\nwhile red dots indicate the presence of Handicap Lifts\",color=\"white\",size=3,family=\"Roboto Condensed\")\n\n\nggsave(\"w49_elevators.png\",bg=\"black\")"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w3_chocolate/w3_chocolate.html",
    "href": "tidytuesday/cases2022/posts2022/w3_chocolate/w3_chocolate.html",
    "title": "Chocolate Bar ratings",
    "section": "",
    "text": "Here is a short tutorial for making a flow map: https://github.com/rafapereirabr/flow-map-in-r-ggplot\n\nlibrary(tidyverse)\n\n\nchocolate <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv')\n#DataExplorer::profile_missing(chocolate)\n\n\nlibrary(maps)\nlibrary(geosphere)\n#library(rworldmap)\nlibrary(ggthemes)\n\n\n# Get World map\nworldMap <- rworldmap::getMap()\nmapworld_df <- ggplot2::fortify( worldMap )\n\nMismatching values in company_location\nMartinique would not be added in this flow map\n\nchocolate1<-chocolate%>%\n  select(company_location,country_of_bean_origin,cocoa_percent,rating)%>%\n  mutate(company_location=case_when(company_location==\"Amsterdam\"~\"Netherlands\",\n                                    company_location==\"Sao Tome\"~\"Sao Tome and Principe\",\n                                    company_location==\"Sao Tome & Principe\"~\"Sao Tome and Principe\",\n                                    company_location==\"Scotland\"~\"United Kingdom\",\n                                    company_location==\"St. Lucia\"~\"Saint Lucia\",\n                                    company_location==\"St.Vincent-Grenadines\"~\"Saint Vincent and the Grenadines\",\n                                    company_location==\"U.A.E.\"~\"United Arab Emirates\",\n                                    company_location==\"U.K.\"~\"United Kingdom\",\n                                    company_location==\"U.S.A.\"~\"United States of America\",\n                                    company_location==\"Wales\"~\"United Kingdom\",\n                                    TRUE~company_location)\n                                    )\n\nMismatching values in country_of_bean_origin - missing martinique\nMartinique and ** ** would not be added in this flow map\n\nchocolate1<- chocolate1 %>%\n  mutate(country_of_bean_origin=case_when(country_of_bean_origin==\"Blend\"~\"Indonesia\",\n                                          country_of_bean_origin==\"Burma\"~\"Myanmar\",\n                                          country_of_bean_origin==\"Congo\"~\"Republic of the Congo\",\n                                          country_of_bean_origin==\"DR Congo\"~\"Republic of the Congo\",\n                                          country_of_bean_origin==\"Principe\"~\"Sao Tome and Principe\",\n                                          country_of_bean_origin==\"Sao Tome\"~\"Sao Tome and Principe\",\n                                          country_of_bean_origin==\"Sao Tome & Principe\"~\"Sao Tome and Principe\",\n                                          country_of_bean_origin==\"St. Lucia\"~\"Saint Lucia\",\n                                          country_of_bean_origin==\"St.Vincent-Grenadines\"~\"Saint Vincent and the Grenadines\",\n                                          country_of_bean_origin==\"Sulawesi\"~\"Indonesia\",\n                                          country_of_bean_origin==\"Sumatra\"~\"Indonesia\",\n                                          country_of_bean_origin==\"Tanzania\"~\"United Republic of Tanzania\",\n                                          country_of_bean_origin==\"Tobago\"~\"Trinidad and Tobago\",\n                                          country_of_bean_origin==\"Trinidad\"~\"Trinidad and Tobago\",\n                                          country_of_bean_origin==\"U.S.A.\"~\"United States of America\",\n                                          TRUE~country_of_bean_origin)\n  )\n\n\nchocolate2<-chocolate1%>%count(company_location,country_of_bean_origin)\n\n\ncentroids_map<- mapworld_df%>%\n  group_by(id)%>%\n  mutate(long=mean(range(long)),lat=mean(range(lat)))%>%\n  ungroup()%>%\n  count(id,long,lat)\n\nDataExplorer::profile_missing(centroids_map)\n\n\nchocolate3<-chocolate2%>%\n  filter(!company_location==\"Martinique\",\n         !country_of_bean_origin==\"Martinique\",\n         !country_of_bean_origin==\"Samoa\")%>%\n  left_join(centroids_map,by=c(\"company_location\"=\"id\"))%>%\n  rename(long_loc=long,lat_loc=lat)%>%\n  left_join(centroids_map,by=c(\"country_of_bean_origin\"=\"id\"))%>%\n  rename(long_orig=long,lat_orig=lat)\n\n\ntext<-chocolate3%>%\n  pivot_longer(cols = c(company_location,country_of_bean_origin),names_to=\"names\",values_to=\"country\")%>%\n  count(country)%>%\n  left_join(centroids_map,by=c(\"country\"=\"id\"))\n\nChocolate palette: https://www.color-name.com/bitter-chocolate.color#color-palettes\n\nlibrary(extrafont)\nlibrary(showtext)\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi=320)\nlibrary(sysfonts)\n#font_families_google()\nfont_add_google(name=\"Felipa\",family=\"choco\")\n\nfamily = \"choco\"\n\n\ncircle_legend<-ggplot() +\n  ggforce::geom_circle(aes(x0 = -0.5, y0 = 0, r = 0.05),\n                       color=\"#dfc27d\",fill=\"#dfc27d\") +\n  ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = 0.05),\n                       color=\"#dfc27d\",fill=\"#dfc27d\") +\n  ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = 0.015),\n                       color=\"blue\",fill=\"blue\") +\n  ggforce::geom_circle(aes(x0 = 0.5, y0 = 0, r = 0.025),\n                       color=\"blue\",fill=\"blue\") +\n  coord_fixed(xlim=c(-0.5,1),ylim = c(-0.5,1))+\n  theme_void()+\n  theme(plot.background = element_blank(),\n        panel.background = element_blank())\n\n\nmap_plot<-ggplot() + \n    geom_polygon(data= mapworld_df%>%\n                   filter(!id==\"Antarctica\"), \n                 aes(long,lat, group=group), fill=\"#2B1A15\",color= \"#BFBAB9\",size=0.2) +\n    geom_point(data = chocolate3, \n                 aes(x = long_orig, y = lat_orig),\n                 color=\"#dfc27d\",size=3,alpha=0.3) +\n   geom_point(data = chocolate3, \n                 aes(x = long_loc, y = lat_loc),\n                 color=\"blue\",size=0.5) +\n  geom_segment(data = chocolate3, \n               aes(x = long_orig, y = lat_orig, \n                   xend = long_loc, yend = lat_loc, alpha=n.y,color=n.y),\n               size=0.05)+ # ,arrow = arrow(length = unit(0.01, \"npc\"))\n   geom_text(data=text,family=family,\n            aes(x=long,y=lat,label=country),color=\"#F07518\", #d2691e\n            vjust=\"top\",hjust=\"right\",size=3,check_overlap = T)+\n  \n  scale_colour_distiller(palette=\"BrBG\", name=\"Frequency\", guide = \"colorbar\") +\n  scale_alpha(range=c(0.8,1))+\n  guides(alpha=\"none\")+\n  labs(title=\"Cocoa's Countries of Origins and Production map\",\n       caption=\"DataSource: Flavors of Cacao | DataViz: Federica Gazzelloni\")+\n  ggthemes::theme_map()+\n  theme(text = element_text(color=\"#d2691e\",family=family),\n        plot.background = element_rect(color=\"#54504d\",fill=\"#54504d\"),# BFBAB9 #282625\n        panel.background = element_rect(color=\"#54504d\",fill=\"#54504d\"),\n        legend.background = element_blank(),\n        plot.title = element_text(hjust = 0.5,size=28),\n        plot.caption = element_text(size=10))\n\nlibrary(cowplot)\n\n\nfinal<-ggdraw()+\n  draw_plot(map_plot)+\n  draw_plot(circle_legend,scale=0.5,x=0.1,y=-0.3)+\n  draw_image(here::here(\"R_general_resources/TidyTuesday/data/2022/w3_chocolate/image1.png\"),\n             x=-0.3,y=-0.41,scale=0.23,clip = \"inherit\")+\n  draw_image(here::here(\"R_general_resources/TidyTuesday/data/2022/w3_chocolate/image2.png\"),\n             x=0.35,y=0.42,scale=0.2,clip = \"inherit\")+\n  draw_image(here::here(\"R_general_resources/TidyTuesday/data/2022/w3_chocolate/image2.png\"),\n             x=-0.35,y=0,scale=0.2,clip = \"inherit\")+\n  draw_label(\"Origin\",x=0.48,y=0.08,fontfamily = family,color=\"#F07518\",size=8)+\n  draw_label(\"Production\",x=0.65,y=0.08,fontfamily = family,color=\"#F07518\",size=8)+\n  draw_label(\"Origin & Production\",x=0.56,y=0.08,fontfamily = family,color=\"#F07518\",size=8)+\n  draw_label(\"data contains values for Martinique and Samoa not mentioned in this map\",x=0.56,y=0.05,color=\"#F07518\",size=8,fontfamily = family)\n\nggsave(\n   \"w3_chocolate.png\",\n   plot =final,\n  bg=\"white\",\n  dpi = 320,\n  width = 11,\n  height = 6\n)"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w31_frogs/w31_frogs.html",
    "href": "tidytuesday/cases2022/posts2022/w31_frogs/w31_frogs.html",
    "title": "Oregon Spotted Frog",
    "section": "",
    "text": "This is the final code for assembling all plots saved in the container images folder using {cowplot} package. In addition, some annotations and grobs are included.\nAll separate scripts are selfcontainers.\n\ng <- grid::circleGrob(gp = grid::gpar(fill = NA,color=\"gray\"))\n\n\nlibrary(cowplot)\nggdraw() +\n  draw_label(\"Oregon Spotted a Frog!\", \n             x=0.227,y=0.95,size=34,\n             fontface = \"bold\",\n             fontfamily = \"Roboto Condensed\") +\n  draw_label(label=\"Captured\",x=0.7,y=0.9,fontfamily = \"Roboto Condensed\") +\n  draw_label(label=\"Visual\",x=0.6,y=0.9,fontfamily = \"Roboto Condensed\") +\n  draw_label(label=\"Frequency\",x=0.5,y=0.9,fontfamily = \"Roboto Condensed\") +\n  draw_label(label=\"Radio-telemetry is used to study frogs (Rana pretiosa)\\nat Crane Prairie Reservoir in Oregon.\\nIndividual frog location tracking occurred roughly\\nweekly between September and late November of 2018.\",\n             fontfamily = \"Roboto Condensed\",\n             x=0.015,y=0.85,hjust=0) +\n  draw_label(label=\"On average more males are caught on radio-telemetry\\nfrequencies than females. In the map the grey circles\\nindicate the tracking location ranges based on mean\\nrange difference among frequencies in same subsite. \\n\\nDataSource: #TidyTuesday 2022 week31\\n@USGS data & @fgazzelloni | DataViz: Federica Gazzelloni\",\n             fontfamily = \"Roboto Condensed\",\n             x=0.015,y=0.08,hjust=0,size=11) +\n    draw_label(label=\"On the left is the network\\nof subsite and water type,\\nit shows more frogs are\\ncaptured in specific locations.\\n\\nOn the right is the models\\nranking among many models.\\nRandom Forest is the best\\nperforming. Results shows on\\naverage male are twice more\\nlikely to get caught than\\nfemales. More info:\\nfedericagazzelloni.netlify.app\",\n             fontfamily = \"Roboto Condensed\",\n             x=0.668,y=0.13,hjust=0,size=8) +\n  draw_image(\"container/images/globe.png\",\n             scale=0.18,\n             x=0.4,y=0.38)+\n  draw_image(\"container/images/network_plot.png\",\n             scale=0.29,\n             x=0.022,y=-0.38)+\n  draw_image(\"container/images/roc_plot.png\",\n             scale=0.245,\n             x=0.4,y=-0.38)+\n  draw_image(\"container/images/lake_map.png\",\n             scale=0.7,\n             x=0.14,y=0.01) +\n  draw_image(\"container/images/vip_plot.png\",\n             scale=0.62,\n             x=-0.3,y=-0.03)+\n  draw_image(\"container/images/frog_logo_visual.png\", \n              scale=0.2,\n             x=0.1, y=0.32) +\n  draw_image(\"container/images/frog_logo_captured.png\",\n              scale=0.2,\n             x=0.2, y=0.32) +\n  draw_grob(g, scale = 0.05,x = 0,y = 0.33)+\n  draw_grob(g, scale = 0.025,x = 0,y = 0.33)+\n  draw_grob(g, scale = 0.01,x = 0,y = 0.33)\n\n\n# ggsave(\"w31_frogs.png\",\n#        width=10,\n#        height = 8,\n#        dpi=320,\n#        bg = \"white\")"
  },
  {
    "objectID": "tidytuesday/cases2022/posts2022/w22_reputation/w22_reputation.html",
    "href": "tidytuesday/cases2022/posts2022/w22_reputation/w22_reputation.html",
    "title": "Company reputation poll",
    "section": "",
    "text": "Axios and Harris Poll to gauge the reputation of the most visible brands in America, based on 20 years of Harris Poll research. Based on a survey of 33,096 Americans in a nationally representative sample conducted March 11-April 3, 2022.\nEach company received approximately 325 ratings. An RQ score is calculated by: [ (Sum of ratings of each of the 9 attributes)/(the total number of attributes answered x 7) ] x 100.\nScore ranges: 80 & above: Excellent | 75-79: Very Good | 70-74: Good | 65-69: Fair | 55-64: Poor | 50-54: Very Poor | Below 50: Critical\n\nlibrary(tidyverse)\n\n\npoll <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-31/poll.csv')\nreputation <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-31/reputation.csv')\n\n\npoll%>%head\n\n\nreputation%>%head\n\n\nlibrary(extrafont)\n# loadfonts()\n\n\np<-reputation%>%\n  arrange(rank) %>%\n  filter(!industry==\"Other\")%>%\n  mutate(name=reorder(name,score),\n         industry=factor(industry),\n         industry=reorder(industry,-score))%>%\n  ggplot(aes(x=score,y=rank,color=name))+\n  geom_point(size=1,shape=21,stroke=0.5)+\n  geom_line(linetype=\"dashed\")+\n  scale_y_reverse(limits=c(100,1))+\n  facet_wrap(~industry, ncol = 6)+\n  ggthemes::scale_color_colorblind()+\n  guides(color=guide_legend(nrow=1,byrow=TRUE,title.position = \"left\"))+\n  coord_polar(theta = \"y\",start = 1000, direction = 1, clip = \"off\")+\nlabs(title=\"Corporate Reputation Rankings - 2022\",\n     subtitle=\"100 most visible companies grouped by 18 industries are scored in 7 categories\",\n     caption=\"\\nDataSource: #TidyTuesday 2022 week22 - Axios and Harris Poll\\nDataViz: Federica Gazzelloni (@fgazzelloni)\",\n     x=\"\",\n     y=\"Rank vs Score polarized dotted lines shows Citizenship is the dominant reputation category for all industries, followed by Ethics and Trust,\\nCulture, P&S(Product and Service), Growth, and Vision, in this order for most of the industries.\\nIndustries are ordered by the highest score received by each reputation category.\\nRetail shows a full score trend contrasting Insurance with just one rank/score for each category.\",\n     color=\"Reputation category\")+\n  theme_linedraw()+\n  theme(text=element_text(family=\"Roboto Condensed\"),\n        axis.title = element_text(size=10,hjust=0),\n        plot.title = element_text(size=30),\n        plot.subtitle = element_text(size=14),\n        legend.position = \"top\",\n        panel.grid = element_blank(),\n        axis.text = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks = element_blank(),\n        strip.background = element_rect(color=\"grey20\",fill=\"grey20\"),\n        plot.background = element_rect(color=\"grey30\"))\n\n\nggsave(\"w22_reputation2.png\",\n       dpi=320,\n       width = 9,\n       height = 7)"
  }
]